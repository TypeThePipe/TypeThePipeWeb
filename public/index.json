[{"authors":["carlos-vecina"],"categories":null,"content":"Carlos Vecina is a data scientist with experience using ML and AI to bring value to business in CRM, Marketing and energy markets environments.\n","date":1585699200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1585699200,"objectID":"7f2ce30e6e7155580a08c73da392044a","permalink":"/authors/carlos-vecina/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/carlos-vecina/","section":"authors","summary":"Carlos Vecina is a data scientist with experience using ML and AI to bring value to business in CRM, Marketing and energy markets environments.","tags":null,"title":"Carlos Vecina","type":"authors"},{"authors":["pablo-canovas"],"categories":null,"content":"Pablo Cánovas is a data scientist with experience developing machine learning models applied to electricity markets.\n","date":1579564800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1579564800,"objectID":"78b4973aee7e471f2427600fe9f47d84","permalink":"/authors/pablo-canovas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/pablo-canovas/","section":"authors","summary":"Pablo Cánovas is a data scientist with experience developing machine learning models applied to electricity markets.","tags":null,"title":"Pablo Cánovas","type":"authors"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rYesterday I was playing with the new and first of many Thomas Neitman’s CRAN package!\nIts documentation reminded me that more than a year ago we did a talk series about text mining. In one of them, we analized the reviews of the most important spanish banks’ APPs.\nOne of the plots was a lollipop chart showing the users score in the Play Store, and its deviation from the mean. I used to remember this plot cooler than it actually seems to me lol\rIt’s maybe telling us that we have improved our skills. Hope it.\nlibrary(tidyverse)\rlibrary(purrr)\r\r# Data Prep\rreviews_score \u0026lt;-fst::read_fst(\u0026quot;reviews_score.fst\u0026quot;)\rglobalMean \u0026lt;-round(mean(reviews_score$Mean),2)\rcenter_formatter \u0026lt;-function(x) {x +globalMean} # Set the mean as a center\rcustom_labs \u0026lt;-labs(title=\u0026quot;Ranking Spanish Banking APPs reviews (1 to 5 stars) \u0026quot;, \rsubtitle=paste0(\u0026quot;Filtering out reviews without comment. Last week data. The mean score is: \u0026quot;, globalMean), \rx=\u0026quot;\u0026quot;,\ry=\u0026quot;Score\u0026quot;)\r\r\rggplot(reviews_score, aes(x=Bank, y=MeanDev, label=Mean)) +\rgeom_segment(aes(x = Bank, y = 0,\ryend = MeanDev, xend = Bank,\rcol=AboveBelow),size=2)+\rgeom_point(stat=\u0026#39;identity\u0026#39;, aes(col=AboveBelow), size = 14) +\rguides(colour = guide_legend(override.aes = list(size=2))) +\rscale_color_manual(name=\u0026quot;Scoring\u0026quot;, \rlabels = c(\u0026quot;Above\u0026quot;=\u0026quot;Above the mean\u0026quot;,\r\u0026quot;Below\u0026quot;=\u0026quot;Below the mean\u0026quot;), \rvalues = c(\u0026quot;Above\u0026quot;=\u0026quot;#00ba38\u0026quot;,\r\u0026quot;Below\u0026quot;=\u0026quot;#f8766d\u0026quot;)) +\rgeom_text(color=\u0026quot;black\u0026quot;, size=5) +\rcoord_flip() +\rtheme_minimal() +\rscale_y_continuous(labels=center_formatter) +\rcustom_labs\rWell, it’s quite good if you don’t pay attention to the big circles and to the long code to write such a “standart” chart.\nHere is where ggcharts shines. And it’s only the 0.1.0 version. But having reusable plot templates but in a flexible way seems such a cool idea for me,\nSee an three-liner aprox to the above plot:\n# install.packages(\u0026quot;ggcharts\u0026quot;) :)\rlibrary(ggcharts)\r\rlollipop_chart(reviews_score, x=Bank, y=MeanDev, color=AboveBelow) +\rscale_color_manual(name=\u0026quot;Scoring\u0026quot;, \rlabels = c(\u0026quot;Above\u0026quot;=\u0026quot;Above the mean\u0026quot;,\u0026quot;Below\u0026quot;=\u0026quot;Below the mean\u0026quot;), \rvalues = c(\u0026quot;Above\u0026quot;=\u0026quot;#00ba38\u0026quot;, \u0026quot;Below\u0026quot;=\u0026quot;#f8766d\u0026quot;)) +\rscale_y_continuous(labels=center_formatter) +custom_labs \rThat was so cool and quite much cleaner.\nThere are several paths to keep improving its capabilities. So here are some enancements. Tell him yours… see you in his repo!\n\nProposed enhancements:\n\rEasy \u0026amp; Quick auto-aligned Annotations:\r\rreviews_score %\u0026gt;%\rlollipop_chart(x=Bank, y=MeanDev, limit = 25, #line_color = colours,\rhighlight = \u0026quot;BBVA\u0026quot;,point_color = \u0026quot;blue\u0026quot;) +\rscale_y_continuous(labels=center_formatter) +\rannotate(\u0026quot;segment\u0026quot;, x = 5, xend = 5.3, y = 0.55, yend = 0.7, colour = \u0026quot;black\u0026quot;) +\rannotate(\u0026quot;text\u0026quot;, x = 5.4, y = 0.75, label = \u0026quot;4.05\u0026quot;) +custom_labs\r\rEasy Image axis and plot insertion:\r\r# https://gist.github.com/jonocarroll/2f9490f1f5e7c82ef8b791a4b91fc9ca\r# https://stackoverflow.com/questions/54973129/including-images-on-axis-label-in-an-animated-ggplot2\r\rEasy non 0 centered in lolliplot and diverging lolliplot:\r\r# center parameter?\rscale_y_continuous(labels = function(x) {x +center})\r\rColor aes and highlight conflict\r\r# Counter intuitive line_color parameter when highlight\rcolours \u0026lt;-c(\u0026quot;green, green\u0026quot;, \u0026quot;green\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;red\u0026quot;)\rlollipop_chart(reviews_score, x=Bank, y=MeanDev, limit = 25, line_color = colours) # BBVA is green\rlollipop_chart(reviews_score, x=Bank, y=MeanDev, limit = 25, line_color = colours,\rhighlight = \u0026quot;BBVA\u0026quot;) # the highlighting BBVA now red\r\rdiverging_lollipop_chart(reviews_score, Bank, Mean) # not working with all positive values (linked with to center in non 0 value)\r\nEnjoy ggcharts!\n\n","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"0d6ba338eefda9f0872d393ed0c8a6ce","permalink":"/vizs-and-tips/ggcharts-lollipop-plot-in-r/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/vizs-and-tips/ggcharts-lollipop-plot-in-r/","section":"vizs-and-tips","summary":"Thomas Neitman's ggcharts","tags":[],"title":"Playing with a new R package; welcome ggcharts!","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rAre you trying to save and load your DL model or a big dataset? Here we show you a performance boost to your scripts and reduction in disk memory storage with the FST package. We are going to benchmark it with R base functions (csv and RDS extensions) and with another great package like readr:\nlibrary(tidyverse)\rbig_dataset %\u0026gt;%nrow() # 700k rows, 15 cols(8 factor, 4int, 3 logi)\rlibrary(microbenchmark)\rlibrary(readr)\rlibrary(fst)\r\rmicrobenchmark(\rwrite.csv(big_dataset, paste0(path,\u0026quot;big_dataset.csv\u0026quot;),), # utils\rwrite_csv(big_dataset, paste0(path,\u0026quot;big_dataset.csv\u0026quot;)), # readr\rwrite_csv(big_dataset, paste0(path,\u0026quot;big_dataset.csv.gz\u0026quot;),), # readr GZ\rsaveRDS(big_dataset, paste0(path,\u0026quot;big_dataset.RDS\u0026quot;)), # utils\rwrite_rds(big_dataset, paste0(path,\u0026quot;big_dataset.RDS\u0026quot;)), # readr\rwrite_fst(big_dataset, paste0(path,\u0026quot;big_dataset.fst\u0026quot;)), # fst\rtimes = 10\r)\r## Unit: milliseconds\r## min mean median max neval file_size\r##utils 10943.1161 11232.20073 11098.66610 12011.1538 10 109 MB\r##readr 3140.4450 3442.92772 3388.14280 3768.4109 10 109 MB\r##readrGZ 6993.8850 7332.31976 7260.95040 7946.9233 10 23 MB\r##base 4800.3516 5122.22345 5024.69395 5833.9807 10 15 MB\r##readr 187.0765 210.74584 211.70760 246.6369 10 46 MB\r\u0026quot;fst 60.3065 87.30611 74.94375 154.7718 10 16 MB\u0026quot;\r\nWow! That was cool! We can achieve an amazing reading and writing speed plus an incredible file size!\nWe can see a x3 and x50 performance improvements over the readr::write_rds() and base saveRDS() functions!\nAn incredible x100 performance between fst and csv writing functions, but it’s true that they are not directly comparable as they work with quite different file formats.\n\nAre you going to add FST to your projects toolbox too?\n\n\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1585526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585526400,"objectID":"0ff90810143f0dd4c66ca71c7a35c5d3","permalink":"/vizs-and-tips/speed-up-load-write-files-fst-package-r/","publishdate":"2020-03-30T00:00:00Z","relpermalink":"/vizs-and-tips/speed-up-load-write-files-fst-package-r/","section":"vizs-and-tips","summary":"Unbeaten speed and file size! It's FST! x100 faster than write.csv()","tags":[],"title":"Speed up your R scripts. A cool optimized way to load, write and store big files with FST package!","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rAre you developing an automated exploration tool? Here we propose some alternatives to drop columns with high percentage of NAs.\nIn this previous tip we talk about BaseR vs Tidy \u0026amp; Purrr counting NAs performance.\nNot leaving the pipeflow. How much does it cost?;) It depends on the NA distribution between features and its number, but not much that a few nanoseconds in small and big datasets\n# library(microbenchmark) You can benchmark them in small and big datasets\rlibrary(tidyverse)\r\rairquality %\u0026gt;%select_if(~mean(is.na(.)) \u0026lt;0.2)\r\rairquality %\u0026gt;%select(which(colMeans(is.na(.)) \u0026lt;0.2))\r\rairquality[lapply(airquality, function(x) mean(is.na(x))) \u0026lt;0.2]\r\nSoooo what’s your choice??\n\n\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1584921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584921600,"objectID":"718207551b31bdb41be4b54104d49fcb","permalink":"/vizs-and-tips/selecting-columns-based-on-nas-percentage-r-tidyverse/","publishdate":"2020-03-23T00:00:00Z","relpermalink":"/vizs-and-tips/selecting-columns-based-on-nas-percentage-r-tidyverse/","section":"vizs-and-tips","summary":"Showing up several ways","tags":[],"title":"Drop columns based on NAs percentage in R","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Post"],"content":"\r\r1. Set your main goal and check your time and resources (skills, hardware…)\r2. Choose the challenge field/industry according your interests.\r3. Build the right team. Set up tools to exchange code.\r4. Deep research about the challenge topic and environment.\r5. Excel your exploratory analysis. Remember you could use external data sources.\r6. Set your project and code structure.\r7. Run your models.\r8. Cross Validation, OOS and backtesting.\r9. Model interpretability\r10. Write down your observed strengths and weaknesses. It will be the starting point for your next proyect. \r\r\rAre you considering join a Datathon or data competition? In this post we’ll bring you 10 tips that can help you to outperform your competitors. So without further ado;\n\n1. Set your main goal and check your time and resources (skills, hardware…)\rDepending on your profile and the competition requirements, you should think about your main goal by joining a data challenge. It could be learning about a new tool, improve your coding and algorithmical skills, achieve the 1st position and therefore the prize, or just for fun. Whatever it is, that’s great.\nIt’s important to have a bright and well-defined picture of your goal, because you are going to invest so much time in the project. Having clear your personal idea of success will help you in your valley of despair.\n\n\r2. Choose the challenge field/industry according your interests.\rFollowing with the ‘you’re going to invest so much time’ idea, how are you joining a challange in a field that doesn’t inspire you? Hopefully, many organizations and platforms are launching it’s own data challanges open to the public. Kaggle is the principal one, nevertheless there are many more. We propose several options here.\n\n\r3. Build the right team. Set up tools to exchange code.\rYou should choose your teammates depending on your principal objective. It’s an unseen topic with related posts, but we consider it is sufficiently important one.\nYou better choose an inspiring teammate you feel good with and encourage you if you want to learn about a new topic or technology. If the project needs different profiles and you want to be among the prize winners, go for a multidisciplinary team. If the project doesn’t need it, choose a teammate with your skill level. If it’s possible, a little more skilled.\nThese are just a few examples. The main point here is choosing teammates to maximize invested time return by minimizing interpersonal problems and strengthen synergies.\n\n\r4. Deep research about the challenge topic and environment.\rOnce you have built the team, we propose you to start a research about the industry your challenge is on. This effort will lead you to a better understanding of the problem and the solution, avoiding useless iterations in your data science workflow. By starting with clear premises you will take apart basic concetps missunderstandings, a fact that could fool your whole solution and conclusions.\nLet’s explain this concept. Suppose your challenge consist on forecasting the conversion rate given a product portfolio, based on the online activity recorded by Google Analytics. Here, we must have clear-minded and relevant knowledge about this data source behaviour. How the bounce rate works, the customer journey recording since he open our web page and is matched with a cookie to the final conversion, leaving the web or logging as a user. Also, different behaviours of null records, bots, several cases where the default source is ‘direct’…\nWithout this kind of information it could be difficult to craft meaningful variables to increase the model performance. But worst of all, any conclusion you get is most likely to be misunderstood and impossible to get powerful and business-disruption insights.\n\n\r5. Excel your exploratory analysis. Remember you could use external data sources.\rAs any data science project, it consist of iterative phases. Since you have an industry landscape understanding, you will take a look on the data. If any doubt comes to your mind, return to the research stage.\nSo in this exploratory phase, you are focused on your data and extract information about features itself and interactions. We usually start summarizing the features by its distribution, number of NAs, categories… Features with high NAs percentage or with a minimal variance we can choose between removing or encoding it as binary variable NA/Not_NA Majoritay_Class/Not_Majoritary class. Many other encoding techniques can be applied, like these.. The full exploratory toolbox can be found on Google or Kaggle.\nFinally, as a reminder, you usually can use external data sources to enrich the provided data. Demographic data to contextualize your zip code feature. Or a past event to explain a spike in your data. Obviously, you must take into account which kind of this information you will have in your forecasting set.\n\n\r6. Set your project and code structure.\rHere we will show you our most common project structure. The directory structure of a Data Science CdU depends on the project nature, its development and production environments.\nProject:\n\rdata:\r\r1_raw:\r2_processed:\r\rmodels:\rnotebooks:\r\r1_eda:\r2_poc:\r3_modeling:\r4_evaluation:\r\rsrc:\r\r1_get_data:\r2_processing:\r3_modeling:\r4_evaluation:\r5_helpers:\r\r\rWe consider we can simplify this structure in the Datathon case, because we don’t need to automate the ETL or the assessment and validation process inside a productive workflow. In fact, the exploratory analysis and the main script are the principal points here. Our main script calls to the preprocess, train, test and evaluation modules.\nDatathon_Project:\n\rdata:\rexploratory:\rhelpers:\rlog:\rmain.R / main.py\routputs:\r\rmodels:\rpreds:\rvalidation:\r\r\rRegarding the main script structure, we usually build a custom cross validation with the objective of being flexible to train different models and stack its predictions. Our project template is as follows:\nLoading environment (packages, modules and functions)\rCrafting features\rSplit dataset and datasetOOSample\rSplit dataset into folds\rFor each fold in folds:\rTraining with the rest\rPredict in fold\rEvalutaion\r(In the last fold, stacking models training if you want it)\rOut of Sample prediction\rEvaluación (Base models and stacking comparaison)\rTest set prediction.\n\n\r7. Run your models.\rFirs of all, we advise you to focus in a model family and loss function that better fit a priori our data, response variable and evaluated metric. The first results let you to test your code and pipeline and will be the starting point for further improvements.\nYou can use Google to search about different algorithm families and loss functions according your data and objective.\rAlso, there such an amazing info in Kaggle kernels, Reddit feed and YouTube speaks.\n\n\r8. Cross Validation, OOS and backtesting.\rSpecial attention to the error metrics. One of the goals that we set in our data competitions is to know as precisely as possible the error interval (confidence or prediction) of our models before we submit predictions.\nTo know about our forecast uncertainity behind several scenarios, data subsets and synthetic data make us feel proud. Also, it could helps us to be sure about our error metrics improvements are not due to spurious behaviour or bugs.\n\n\r9. Model interpretability\rIn some data competitions, the best teams have to expose their projects in a final event. Here, in addition to talk about your data flow and research done, you probably want to talk about some insights and interpretable interactions between data and not only the model prediction.\nMany packages like SHAP or LIME integrate different modules focused on the model and predictions interpretability. These modules instead of looking for a “mean” variable importance in a global point of view, compose additionally a local feature contribution in each predicted observation.\n\n\r10. Write down your observed strengths and weaknesses. It will be the starting point for your next proyect. \rOnce you have finished the project and committed the predictions, writing down your strengths and weaknesses is a cool idea. These thoughts are such a fantastic starting point to the next competition or project.\n\nSo here is our contribution, hoping you will ace your competition! And the most important, have fun!!\n\rbody {\rtext-align: justify}\rp {\rword-spacing: 3px;\rtext-indent: 20px;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r\r","date":1583884800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583884800,"objectID":"7d24c3b54d708476d634af4418447b3d","permalink":"/post/10-tips-datathon-kaggle-data-science/","publishdate":"2020-03-11T00:00:00Z","relpermalink":"/post/10-tips-datathon-kaggle-data-science/","section":"post","summary":"Do you want to achieve your goals?","tags":[],"title":"10 Tips to ace your Kaggle, Datathon or any data competition!","type":"post"},{"authors":["Carlos Vecina"],"categories":["R","Post"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rHere you can find the R code. It’s an ‘in progress’ script. I will develop basic features like:\n\rploting/rendering code refactoring;\n\rGGanimate with the algortihm steps moving forward;\n\rand, of course, several pathfinding algorithms and evolutionary ones.\n\r\rAll these features and much more in following posts! Stay tuned! \nlibrary (shiny)\rlibrary (ggplot2)\rlibrary (tidyverse)\rsource(\u0026quot;helpers/ColourBorders.R\u0026quot;)\rsource(\u0026quot;helpers/PlotMapGrid.R\u0026quot;)\r\r\rui \u0026lt;-fluidPage(\rmainPanel(\rcolumn(12,offset = 5, \rtitlePanel(\u0026quot;Pathfinding Algorithm Visualization using R!\u0026quot;)),\rHTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\rcolumn(12,offset = 5,HTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\ractionButton(\u0026quot;go_search_actionButton\u0026quot;, \u0026quot;Go Search!\u0026quot;),\ractionButton(\u0026quot;clean_all_actionButton\u0026quot;, \u0026quot;Clean All\u0026quot;)),\rHTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\rcolumn(12,offset=5, plotOutput(\u0026quot;map_grid_plotOutput\u0026quot;,\rclick=\u0026quot;map_grid_plotOutput_click\u0026quot;))\r))\r\r\rserver \u0026lt;-function(input, output){\r\r## Initial params\rmax_steps \u0026lt;-50\rmatrix_x_size \u0026lt;-20\rmatrix_y_size \u0026lt;-20\rgrid_map_reactive \u0026lt;-matrix(ncol = matrix_x_size,\rnrow = matrix_y_size,\rdata = 0) \r\r## Colours Dict (in progress)\r# 1- Wall\r# 2- Init\r# 3- Obj\r# 4- Step done\r# 5- Goal achieved\r\r# Initialize objts\rgrid_map_reactive[4,15] \u0026lt;-3 # obj\rgrid_map_reactive[17,3] \u0026lt;-2 # init\rinitial_step \u0026lt;-which(grid_map_reactive ==2,\rarr.ind = TRUE)\rgrid_map_reactive \u0026lt;-ColourBorders(grid_map_reactive, 1) # rounding walls\rreact_df \u0026lt;-reactiveValues(df = grid_map_reactive,\rorig = grid_map_reactive,\rwalls = grid_map_reactive)\r\robserve({\rif(!is.null(input$map_grid_plotOutput_click)){\rnew_x_value \u0026lt;-trunc(input$map_grid_plotOutput_click$x)\rnew_y_value \u0026lt;-trunc(input$map_grid_plotOutput_click$y)\r\rif(between(new_x_value,2,matrix_x_size-1) \u0026amp;between(new_y_value,2,matrix_y_size-1)){\risolate(react_df$df[new_y_value,new_x_value] \u0026lt;-if_else(react_df$df[new_y_value,new_x_value]==0,\r1,0))\risolate(react_df$df[4,15] \u0026lt;-3)\risolate(react_df$df[17,3] \u0026lt;-2)\risolate(react_df$df[17,3] \u0026lt;-2)\risolate(react_df$walls \u0026lt;-react_df$df)\r\routput$map_grid_plotOutput \u0026lt;-renderPlot({\r\rPlotMapGrid(react_df$df,\rmatrix_x_size,\rmatrix_y_size)\r\r}, width=600, height=600,position=\u0026quot;center\u0026quot;)\r}}\r}) \r\r# Go search! Pseudo-random pathfinding algortihm\robserveEvent(input$go_search_actionButton,{\r\rif(nrow(which(react_df$df ==4, arr.ind = TRUE))\u0026gt;=1) react_df$df \u0026lt;-react_df$walls # click search without clean\rcurrent_step \u0026lt;-initial_step \robj \u0026lt;-which(react_df$df ==3, arr.ind = TRUE)\rprevious_steps_with_opt \u0026lt;-current_step\r\rfor(i in 1:max_steps){\rnext_step_col \u0026lt;-tribble(~row, ~col,\rcurrent_step[1]+1,current_step[2]+0,\rcurrent_step[1]+0,current_step[2]+1,\rcurrent_step[1]-1,current_step[2]+0,\rcurrent_step[1]+0,current_step[2]-1)\rnext_values \u0026lt;-NULL\r\rfor(r in 1:nrow(next_step_col)){\rnext_values \u0026lt;-c(next_values,\rreact_df$df[next_step_col[[r,1]],\rnext_step_col[[r,2]]])\r}\rif(3 %in%next_values){\r\rcurrent_step \u0026lt;-next_step_col[next_values==3,] %\u0026gt;%\ras.matrix()\r\rreact_df$df[current_step] \u0026lt;-5\r\rbreak()\r\r} else if(0 %in%next_values){\r\rif(sum(next_values==0)\u0026gt;1){\r\rprevious_steps_with_opt \u0026lt;-current_step\r\r}\r\rcurrent_step \u0026lt;-next_step_col[next_values==0,] %\u0026gt;%\rsample_n(1) %\u0026gt;%\ras.matrix()\r\rreact_df$df[current_step] \u0026lt;-4\r\r} else {\r\rcurrent_step \u0026lt;-previous_steps_with_opt\r\r}\r}\r})\r\r# Reset all\robserveEvent(input$clean_all_actionButton,{\r\rreact_df$df \u0026lt;-react_df$orig\rreact_df$walls \u0026lt;-react_df$orig\r\r})\r\r# First panel\routput$map_grid_plotOutput \u0026lt;-renderPlot({\r\rPlotMapGrid(react_df$df,\rmatrix_x_size,\rmatrix_y_size)\r\r}, width=550, height=600,position=\u0026quot;center\u0026quot;)\r\r}\r\r\rshinyApp(ui=ui, server = server)\rHere the helpers:\nColourBorders \u0026lt;-function(df, col_value){\r\r## Rounding walls \r# Params: df - Map grid\r# col_value - Colour to fill the rounding blocks\r# Return: df with the filled roundings\r\rdf[1,] \u0026lt;-col_value\rdf[,1] \u0026lt;-col_value\rdf[nrow(df),] \u0026lt;-col_value\rdf[,ncol(df)] \u0026lt;-col_value\r\rreturn(df)\r\r}\r\rPlotMapGrid \u0026lt;-function(df, matrix_x_size, matrix_y_size){\r\r## Plot the interactive grid \r# Params: df - Map grid\r# matrix_x_size - X_axis limit\r# matrix_y_size - Y_axis limit\r# Return: plot with the pathfinding\r\r\rplot \u0026lt;-rbind(\rwhich(df==1, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#623B17\u0026quot;),\rwhich(df ==2, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#13293D\u0026quot;),\rwhich(df ==3, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#ffff66\u0026quot;),\rwhich(df ==4, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#99ccff\u0026quot;),\rwhich(df ==5, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#1B998B\u0026quot;)\r\r) %\u0026gt;%\rdata.frame(stringsAsFactors = F) %\u0026gt;%\rtransmute(y = as.numeric(row), x = as.numeric(col), fill_col=fill_col) %\u0026gt;%\rggplot(aes(x+0.5,y+0.5)) +\rgeom_tile(width = 1, height = 1, fill = df$fill_col, col=\u0026quot;black\u0026quot;) +\rscale_y_reverse() +\rscale_x_continuous(breaks = seq(0, matrix_x_size, 1),\rlimits = c(0+0.5, matrix_x_size+1.5), \rminor_breaks = NULL) +\rscale_y_continuous(breaks = seq(0, matrix_y_size, 1),\rlimits = c(0+0.5, matrix_y_size+1.5),\rminor_breaks = NULL) +\rtheme_linedraw()+\rtheme(axis.title.x=element_blank(),\raxis.title.y=element_blank(),\raxis.text.x=element_blank(),\raxis.text.y=element_blank(),\raxis.ticks.x=element_blank(),\raxis.ticks.y=element_blank())\r\rreturn(plot)\r\r}\r\rbody {\rtext-align: justify}\rp {\rword-spacing: 3px;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579564800,"objectID":"3cd4ca45b606003c1f23e99028a848a4","permalink":"/post/pathfinding-algorithms-visualizer-using-r/","publishdate":"2020-01-21T00:00:00Z","relpermalink":"/post/pathfinding-algorithms-visualizer-using-r/","section":"post","summary":"Setting up the interactive grid with Shiny and ggplot! Trail with some kind of random-walker algorithm.","tags":[],"title":"Pathfinding Algorithms Visualizer using R! (I) Setting up the interactive grid","type":"post"},{"authors":["Pablo Cánovas"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rSome time ago I made one of the best discoveries I have ever made in the Tidyverse: a tool called tidylog.\rThis package is built on top of dplyr and tidyr and provides us with feedback on the results of the operations. Actually, this is a feature that already appeared in the Stata software.\nWhen performing one operation at a time, it is easy to track the changes made on a table.\rHowever things get increasingly obscure when chaining multiple functions or dealing with big data frames.\nWe all love piping operations. I often ‘play’ to perform the whole transformation without leaving the pipeflow. But the counterpart is missing the intermediate states: you can make some big mistakes and be unaware of them until it’s too late and maybe you have to undone some work or rethink your analysis.\nIn this context, some additional info is always welcome. I think this feature is specially convenient for beginners, but not only! I have myself wasted several hours debugging long pipelines and trying to understand where the problems came from.\nLet’s see a tiny bit of its behaviour with a simple example:\nlibrary(nycflights13)\rlibrary(tidyverse)\rlibrary(tidylog)\r\rflights %\u0026gt;%\rselect(year:day, hour, origin, dest, tailnum, carrier) %\u0026gt;%\rmutate(month = if_else(nchar(month) ==1, paste0(\u0026quot;0\u0026quot;,month), as.character(month)),\rday = if_else(nchar(day) ==1, paste0(\u0026quot;0\u0026quot;,day), as.character(day))) %\u0026gt;%\runite(\u0026quot;date\u0026quot;, year:day, sep = \u0026quot;/\u0026quot;, remove = T) %\u0026gt;%\rmutate(date = lubridate::ymd(date)) %\u0026gt;%\rfilter(hour \u0026gt;=8) %\u0026gt;%\ranti_join(planes, by = \u0026quot;tailnum\u0026quot;) %\u0026gt;%\rcount(tailnum, sort = TRUE) \r\r# select: dropped 11 variables (dep_time, sched_dep_time, dep_delay, arr_time, sched_arr_time, …)\r# mutate: converted \u0026#39;month\u0026#39; from integer to character (0 new NA)\r# converted \u0026#39;day\u0026#39; from integer to character (0 new NA)\r# mutate: converted \u0026#39;date\u0026#39; from character to double (0 new NA)\r# filter: removed 50,726 rows (15%), 286,050 rows remaining\r# anti_join: added no columns\r# \u0026gt; rows only in x 45,008\r# \u0026gt; rows only in y ( 39)\r# \u0026gt; matched rows (241,042)\r# \u0026gt; =========\r# \u0026gt; rows total 45,008\r# count: now 716 rows and 2 columns, ungrouped\rPretty neat! It is specially useful with joins, as it provides plenty of details and they can be a source of duplicated or missing rows.\nI decided to write this little post now to celebrate that tidylog v1.0.0 has recently been released! Check the official repo out to see more examples or show some love to @elbersb on Twitter!\nAll in all, I think this package was a missing piece in the Tidyverse ecosystem: It is incredibly useful, whereas making advantage of it is as simple as writing library(tidylog). Integrating this package into our daily R work is a no-brainer!\n\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579564800,"objectID":"0c2f957a6e20d268bf1b4b3da5a7ff2a","permalink":"/vizs-and-tips/tidylog-logging-pipelines-r/","publishdate":"2020-01-21T00:00:00Z","relpermalink":"/vizs-and-tips/tidylog-logging-pipelines-r/","section":"vizs-and-tips","summary":"Logging your pipelines","tags":[],"title":"Tidylog. Logging your pipelines","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rSupose you are analysing survey data. You are asked to get the mean in a representative way, weighting your individuals depending on the number of members of their segment.\nlibrary(tidyverse)\r\rsurvey_data \u0026lt;-tribble(\r~id, ~region1, ~region2, ~gender, ~q1, ~q2,\r1,\u0026quot;sp\u0026quot;,\u0026quot;mad\u0026quot;,\u0026quot;m\u0026quot;, 2,5,\r2,\u0026quot;it\u0026quot;, \u0026quot;bol\u0026quot;, \u0026quot;m\u0026quot;, 5, 10,\r3,\u0026quot;sp\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;f\u0026quot;, 2, 2,\r4,\u0026quot;sp\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;f\u0026quot;, 7, 7,\r5,\u0026quot;it\u0026quot;, \u0026quot;bol\u0026quot;, \u0026quot;m\u0026quot;, 2, 7) \rsurvey_data %\u0026gt;%\rgroup_by(region1, region2, gender) %\u0026gt;%\rmutate(weight = 1/n()) %\u0026gt;%\rungroup() %\u0026gt;%\rsummarise_at(vars(contains(\u0026quot;q\u0026quot;)),\rfuns(weighted_mean = sum(. *weight)/sum(weight)))\r\r\rq1_weighted_mean\r\rq2_weighted_mean\r\r\r\r\r\r3.333333\r\r6\r\r\r\r\r","date":1579132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579132800,"objectID":"d9f06b3f3736c611c9372ca8190dde00","permalink":"/vizs-and-tips/summarise_at-weighted-mean-tidyverse-r/","publishdate":"2020-01-16T00:00:00Z","relpermalink":"/vizs-and-tips/summarise_at-weighted-mean-tidyverse-r/","section":"vizs-and-tips","summary":"Survey analysis using R","tags":[],"title":"Using summarise_at(). Weighted mean Tidyverse approach","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Tips"],"content":"\rA recurrent complaint beginner users have about Jupyter Notebooks is the lack of information about the self-created environment variables. If you have this question, probably first of all you should be sure about the Jupyter Notebooks main purpose (totally different from IDEs like Spyder or Pycharm).\nBut in case a notebook is all what you need, you have few ways to display this information. The first and easiest one is to use the magic method %whos\rTwo alternative ways are nbextension and Jupyter Lab variable inspector. You can find more information here\n","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"6d23f87878690596211988dedd6c93c7","permalink":"/vizs-and-tips/magic-whos-method-jupyter-notebook/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/vizs-and-tips/magic-whos-method-jupyter-notebook/","section":"vizs-and-tips","summary":"Kind of magic","tags":[],"title":"List all the defined variables in Jupyter Notebooks","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Vizs"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\nYou can see the code below :)\nlibrary(ggplot2)\r# library(plotly)\rlibrary(tibble)\rlibrary(dplyr)\r\rskills \u0026lt;-tribble(\r~Skill, ~Hours, ~Class,\r\u0026quot;AWS\u0026quot;, 500, \u0026quot;BigData\u0026quot;,\r\u0026quot;Python\u0026quot;, 8000, \u0026quot;Language\u0026quot;,\r\u0026quot;Spark\u0026quot;, 4000, \u0026quot;BigData\u0026quot;,\r\u0026quot;R\u0026quot;, 9000, \u0026quot;Language\u0026quot;,\r\u0026quot;Git\u0026quot;, 2000, \u0026quot;Tools\u0026quot;,\r\u0026quot;Jira\u0026quot;, 2000, \u0026quot;Tools\u0026quot;,\r\u0026quot;Forecasting\u0026quot;, 5000, \u0026quot;Objetive\u0026quot;,\r\u0026quot;Segmentation\u0026quot;, 2000, \u0026quot;Objetive\u0026quot;,\r\u0026quot;Computer Vision\u0026quot;, 600, \u0026quot;Objetive\u0026quot;,\r\u0026quot;SQL\u0026quot;, 4500, \u0026quot;Language\u0026quot;,\r\u0026quot;IBM Data Stage \u0026amp; SPSS\u0026quot;, 1200, \u0026quot;Tools\u0026quot;,\r\u0026quot;Shiny R\u0026quot;, 1500, \u0026quot;Visualization\u0026quot;,\r\u0026quot;Tableau\u0026quot;, 1000, \u0026quot;Visualization\u0026quot;,\r\u0026quot;Spotfire\u0026quot;, 500, \u0026quot;Visualization\u0026quot;\r) \r# plotly(\rggplot(data=skills,aes(x=reorder(Skill,-desc(Hours)), y= Hours, fill=Class, label=paste0(Hours,\u0026quot; h\u0026quot;))) +\rgeom_bar(stat = \u0026quot;identity\u0026quot;, colour=\u0026quot;black\u0026quot;) +\rcoord_flip() +\rlabs(x=\u0026quot; \u0026quot;, y=\u0026quot;Hours\u0026quot;, fill=\u0026quot; \u0026quot;) +\rtheme_minimal() +\rscale_fill_brewer(palette = \u0026quot;YlOrBr\u0026quot;,direction = -1) +\rgeom_label(show_guide = F, aes(y=400)) # Use show_guide despite the warning\r","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578355200,"objectID":"2ba02a1580e0ba11ef62a4b5905e8cf7","permalink":"/vizs-and-tips/skills-plot-curriculum-r-ggplot/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/vizs-and-tips/skills-plot-curriculum-r-ggplot/","section":"vizs-and-tips","summary":"Skills snapshot in 6 Ggplot2 lines","tags":[],"title":"Skills chart using Gplot2 with R","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rlibrary(ggplot2)\rlibrary(gganimate)\rlibrary(tidyverse)\rdf_evolution_data \u0026lt;-data.frame(Name=rep(c(\u0026quot;Madrid\u0026quot;,\u0026quot;Barcelona\u0026quot;,\r\u0026quot;Valencia\u0026quot;,\u0026quot;Alicante\u0026quot;,\r\u0026quot;Sevilla\u0026quot;),5),\rYear = factor(sort(rep(2001:2005, 5))),\rValue = runif(25,100,1000))\rdf_evolution_data_filtered \u0026lt;-df_evolution_data %\u0026gt;%\rgroup_by(Year) %\u0026gt;%\rmutate(Rank = rank(Value)) %\u0026gt;%\rfilter(Rank \u0026gt;=2)\rggplot(df_evolution_data_filtered) +\rgeom_col(aes(x=Rank, y=Value, group=Name, fill=Name), width=0.4) +\rgeom_text(aes(x=Rank, y=0, label=Name, group=Name), hjust=1.25) +\rtheme_minimal() +ylab(\u0026#39;Value\u0026#39;) +\rtheme(axis.title.y = element_blank(),\raxis.text.y = element_blank(),\raxis.ticks.y = element_blank(),\rplot.margin = unit(c(5,5,5,5), \u0026#39;lines\u0026#39;)) +\rscale_fill_brewer(palette=\u0026quot;Dark2\u0026quot;) +\rcoord_flip(clip=\u0026#39;off\u0026#39;) +\rggtitle(\u0026#39;{closest_state}\u0026#39;) +\rtransition_states(Year, transition_length = 1, state_length = 1) +\rexit_fly(x_loc = 0, y_loc = 0) +enter_fly(x_loc = 0, y_loc = 0)\r","date":1576540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576540800,"objectID":"90ec1d6400b13e773818b1e133f3e258","permalink":"/vizs-and-tips/reorder-bars-r-ggplot-gganimate/","publishdate":"2019-12-17T00:00:00Z","relpermalink":"/vizs-and-tips/reorder-bars-r-ggplot-gganimate/","section":"vizs-and-tips","summary":"Reorder your groups over time in gganimate plot.","tags":[],"title":"Reordering bars in GGanimate visualization","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\nlibrary(tidyverse)\rhuron \u0026lt;-data.frame(year = 1875:1972, \rvalue = LakeHuron,\rstd = runif(length(LakeHuron),0,1))\r\rhuron %\u0026gt;%\rggplot(aes(year, value)) +\rgeom_ribbon(aes(ymin = value -std, ymax = value +std), fill = \u0026quot;steelblue2\u0026quot;) +\rgeom_line(color = \u0026quot;firebrick\u0026quot;, size = 1)\rFor a multi-line plot, you should include the colour and group aesthetic as follows:\nlibrary(tidyverse)\rhuron \u0026lt;-data.frame(year = rep(1875:1972,2), \rgroup = c(rep(\u0026quot;a\u0026quot;,98),rep(\u0026quot;b\u0026quot;,98)),\rvalue = c(LakeHuron, LakeHuron +5),\rstd = runif(length(LakeHuron)*2,0,1))\r\rhuron %\u0026gt;%\rggplot(aes(year, value, fill = group)) +\rgeom_ribbon(aes(ymin = value -std, ymax = value +std, group=group), fill = \u0026quot;steelblue2\u0026quot;) +\rgeom_line(color = \u0026quot;firebrick\u0026quot;, size = 1)\r","date":1574035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574035200,"objectID":"8988f7c80ec7e20f310bc9c4566f262e","permalink":"/vizs-and-tips/ggplot-geom_ribbon-shadow-confidence-interval/","publishdate":"2019-11-18T00:00:00Z","relpermalink":"/vizs-and-tips/ggplot-geom_ribbon-shadow-confidence-interval/","section":"vizs-and-tips","summary":"Plot your confidence intervals easily","tags":[],"title":"Shadowing your ggplot lines. Forecasting confidence interval use case.","type":"vizs-and-tips"},{"authors":["Pablo Cánovas"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rHow could we apply certain functions conditionally without leaving the pipeflow?\rThis way:\ndf %\u0026gt;%{ if(apply_filter ==TRUE) filter(., condition) else . } %\u0026gt;%...\r","date":1572652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572652800,"objectID":"0e8f0cc2150f52d9da0b02ac03dae236","permalink":"/vizs-and-tips/conditional-pipes-r-tidyverse/","publishdate":"2019-11-02T00:00:00Z","relpermalink":"/vizs-and-tips/conditional-pipes-r-tidyverse/","section":"vizs-and-tips","summary":"Don't leave the pipeflow","tags":[],"title":"Conditional Pipes","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Tips","Datathon"],"content":"\r\nKaggle - https://www.kaggle.com\nDriven Data - https://www.drivendata.org/competitions/\nCodaLab - https://competitions.codalab.org/\nAlibaba Tianchi - https://tianchi.aliyun.com/competition/gameList/activeList\nAnalyticsvidhya - https://datahack.analyticsvidhya.com/contest/all\nhackerearth - https://www.hackerearth.com/challenges/competitive/\nAgorize - https://www.agorize.com/en/challenges\n\nThere are also international events you might know:\n\nIDA (international Data Analysis Olympiad) (Registro en Enero) - https://idao.world/\nIronViz - https://www.tableau.com/iron-viz\nTopCoder - https://tco19.topcoder.com/competition-overview/algorithm\nData Mining Cup - https://www.data-mining-cup.com/\n\nNowadays, many national and local competitions are launched. We recommend you to search about them!\n\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1570406400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570406400,"objectID":"b5d2a0df261c0114223712a65f18d657","permalink":"/vizs-and-tips/data-competition-platforms-beyond-kaggle/","publishdate":"2019-10-07T00:00:00Z","relpermalink":"/vizs-and-tips/data-competition-platforms-beyond-kaggle/","section":"vizs-and-tips","summary":"Kaggle is not all there!","tags":[],"title":"Data competition platforms","type":"vizs-and-tips"},{"authors":["Pablo Cánovas"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rfiltering-data-frame-by-condition-on-multiple-columns-r-tidyverse\rSome times you need to filter a data frame applying the same condition over multiple columns. Obviously you could explicitly write the condition over every column, but that’s not very handy.\nFor those situations, it is much better to use filter_at in combination with all_vars.\nImagine we have the famous iris dataset with some attributes missing and want to get rid of those observations with any missing value.\n## # A tibble: 10 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 2 NA 3 1.4 NA setosa ## 3 3 4.7 3.2 1.3 0.2 setosa ## 4 4 NA 3.1 1.5 0.2 setosa ## 5 5 5 3.6 1.4 0.2 setosa ## 6 6 5.4 3.9 1.7 0.4 setosa ## 7 7 4.6 3.4 1.4 0.3 setosa ## 8 8 NA 3.4 1.5 0.2 setosa ## 9 9 4.4 2.9 1.4 0.2 setosa ## 10 10 NA NA NA NA setosa\rWe could write the condition on every column, but that would cumbersome:\niris %\u0026gt;%\rfilter(!is.na(Sepal.Length) \u0026amp;\r!is.na(Sepal.Width) \u0026amp;\r!is.na(Petal.Length) \u0026amp;\r!is.na(Petal.Width)\r)\rInstead, we just have to select the columns we will filter on and apply the condition:\nfeatures \u0026lt;-iris %\u0026gt;%names() %\u0026gt;%keep(~str_detect(.,\u0026quot;[.]\u0026quot;))\riris %\u0026gt;%filter_at(vars(features), all_vars(!is.na(.)))\r## # A tibble: 5 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 3 4.7 3.2 1.3 0.2 setosa ## 2 5 5 3.6 1.4 0.2 setosa ## 3 6 5.4 3.9 1.7 0.4 setosa ## 4 7 4.6 3.4 1.4 0.3 setosa ## 5 9 4.4 2.9 1.4 0.2 setosa\rHere we have used the function all_vars in the predicate to explicit that\revery feature must satisfy the condition.\rTo be honest, for that purpose it would have been easier to simply use iris %\u0026gt;% na.omit().\nBut what if we wanted the opposite? Keeping only the rows with all the selected features missing is as easy as changing the predicate part:\niris %\u0026gt;%filter_at(vars(features), all_vars(is.na(.)))\r## # A tibble: 1 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 10 NA NA NA NA setosa\rAnother option is to apply the condition on any feature. That’s where any_vars comes to rescue. Here we keep only the observations with at least one missing feature:\niris %\u0026gt;%filter_at(vars(features), any_vars(is.na(.)))\r## # A tibble: 5 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 2 NA 3 1.4 NA setosa ## 3 4 NA 3.1 1.5 0.2 setosa ## 4 8 NA 3.4 1.5 0.2 setosa ## 5 10 NA NA NA NA setosa\rAlso, there are some other fancy ways to manipulate data frames with the filter family. One trick is using contains() or starts_with() to select the variables:\niris %\u0026gt;%filter_at(vars(contains(\u0026quot;Length\u0026quot;)), all_vars(. \u0026gt;=1.4))\r## # A tibble: 5 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 5 5 3.6 1.4 0.2 setosa ## 3 6 5.4 3.9 1.7 0.4 setosa ## 4 7 4.6 3.4 1.4 0.3 setosa ## 5 9 4.4 2.9 1.4 0.2 setosa\rAnother example is applying the condition on columns that satisfy certain condition with filter_if:\niris %\u0026gt;%filter_if(is.numeric, any_vars(. \u0026gt;5))\r## # A tibble: 6 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 6 5.4 3.9 1.7 0.4 setosa ## 3 7 4.6 3.4 1.4 0.3 setosa ## 4 8 NA 3.4 1.5 0.2 setosa ## 5 9 4.4 2.9 1.4 0.2 setosa ## 6 10 NA NA NA NA setosa\r","date":1570233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570233600,"objectID":"099de6d08d215cc98583d6f1167c23db","permalink":"/vizs-and-tips/filtering-data-frame-by-condition-on-multiple-columns-r-tidyverse/","publishdate":"2019-10-05T00:00:00Z","relpermalink":"/vizs-and-tips/filtering-data-frame-by-condition-on-multiple-columns-r-tidyverse/","section":"vizs-and-tips","summary":"You could write the condition over each column, but we will show you how to deal with 100+ features","tags":[],"title":"Filtering a data frame by condition on multiple columns","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rAre you starting your data exploration? Do you want to have an easy overview of your variable NA percentage?\nWe create a function to benchmark different ways of achieving it:\nlibrary(microbenchmark)\rlibrary(tidyverse)\r\rbenchmark_count_na_by_column \u0026lt;-function(dataset){\rmicrobenchmark(\r# Summary table output\rdataset %\u0026gt;%summary(),\r# Numeric output\rcolSums(is.na(dataset)),\rsapply(dataset, function(x) sum(is.na(x))),\r# List output\rdataset %\u0026gt;%map(~sum(is.na(.))),\rlapply( dataset, function(x) sum(is.na(x))),\r# Df output\rdataset %\u0026gt;%\rselect(everything()) %\u0026gt;%\rsummarise_all(funs(sum(is.na(.)))),\rdataset %\u0026gt;%\rsummarise_each(funs(sum(is.na(.)))),\r# Tibble output\rdataset %\u0026gt;%map_df(~sum(is.na(.)))\r)\r}\rSee the performance dealing with small datasets:\nprint(airquality %\u0026gt;%nrow()) # 153 rows\rbenchmark_count_na_by_column(airquality)\r## Unit: microseconds\r##funct min lq mean median uq max neval class\r##summary() 1480.5 1582.60 1979.676 1897.30 2100.45 6403.2 100 table\r##colSums() 24.4 38.45 47.854 44.70 53.90 152.4 100 integer\r##sapply() 23.2 35.05 67.891 39.65 50.30 2494.8 100 integer\r##map() 140.2 182.60 214.092 200.75 238.50 549.6 100 list\r##lapply() 11.2 15.65 27.093 18.85 22.45 750.1 100 list\r##summarise_all() 1996.9 2147.80 2650.223 2382.90 2798.55 8133.7 100 data.frame\r##summarise_each() 2277.9 2497.05 2951.477 2898.40 3080.65 7977.2 100 data.frame\r##map_df() 190.0 249.00 331.368 275.40 326.05 383 100 tbl_df\rLet’s see how well them scale with 100000 rows dataset:\nbig_dataset %\u0026gt;%nrow() # 100 000 rows\rbenchmark_count_na_by_column(big_dataset)\r## Unit: milliseconds\r##funct min lq mean median uq max neval class\r##summary() 113.7535 129.35070 138.716624 133.14050 143.45920 252.0149 100 table\r##colSums() 4.4280 5.31080 12.502741 5.65005 18.77570 124.8206 100 integer\r##sapply() 2.2452 3.03095 6.788395 3.15310 15.04010 18.6061 100 integer\r##map() 2.5950 3.28390 5.760602 3.38020 3.69445 19.4527 100 list\r##lapply() 2.2018 2.95700 6.219106 3.03605 3.62860 19.5514 100 list\r##summarise_all() 5.0982 5.85135 10.093431 6.05940 6.87070 127.5107 100 data.frame\r##summarise_each() 5.7251 6.16980 10.191426 6.33065 6.72210 125.2943 100 data.frame\r##map_df() 2.6913 3.42045 7.694863 3.56720 3.89715 122.2030 100 tbl_df\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569974400,"objectID":"704af2123e373a156efe0124b7f41ad8","permalink":"/vizs-and-tips/counting-nas-by-column-r-benchmark/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/vizs-and-tips/counting-nas-by-column-r-benchmark/","section":"vizs-and-tips","summary":"Benchmarking several functions","tags":[],"title":"Counting NAs by column in R","type":"vizs-and-tips"},{"authors":["Pablo Cánovas"],"categories":["Metrics","Post"],"content":"\r\r\rIntroduction\rScale dependent error metrics\rPercentage-error metrics\rScale-free error metrics\rConclusions\rReferences\r\r\rIntroduction\rThe idea of this post comes from the different error metrics I have dealt with working with time series data and forecasting models.\nAmong other things, we make energy production forecasts of renewable power plants of different capacities and technologies.\rOur aim is to develop forecasting models that reduce the penalties caused by the deviations.\nMost of the models I work with are regression models, and therefore in this article I am focusing only on regression error metrics.\nUnfortunately, there is no absolute “right” accuracy metric.\rChoosing the right metric is a problem-specific matter, and it involves answering questions like:\n\rWhich decision will you base on the forecast?\rWhat are the consequences of a wrong forecast?\rWho is going to check and monitorize the errors?\rDo we care about the percentage error or about the magnitude of the deviation?\rDoes it makes any difference to over-forecast or under-forecast the variable of interest?\r\rAnswering the above questions lead us to determine we need to find a metric that:\n\rIs scale independent, so the errors are comparable between power plants.\rIs symmetric, as we do not want to weight the deviations differently according to their sign.\rExpress the error in absolute terms, so the error reflects the real-life imbalance costs.\rThe error calculated over different periods should be equivalent to the aggregated calculation over those periods individually.\r\rEach metric behaves in a certain way and therefore reflects in a unique manner the features of the models.\rDepending on their properties, we can classify the metrics in several categories.\rLet’s take a look at them:\n\rScale dependent error metrics\rMaybe the most popular and simple error metric is MAE:\nMAE:\rThe Mean Absolute Error is defined as:\n\\[ MAE = \\frac{1}{N}\\sum_{t=1}^{N} |A_t - F_t| \\]\nWhile the MAE is easily interpretable (each residual contributes proportionally to the total amount of error), one could argue that using the sum of the residuals is not the best choice, as we could want to highlight especially whether the model incur in some large errors.\n\rMSE \u0026amp; RMSE\rFor those cases, maybe MSE (Mean Squared Error) or RMSE (Root Mean Squared Error) are a better choice. Here the error grows quadratically and therefore extreme values penalize the metric to a greater extent.\n\\[ MSE = \\frac{1}{N} \\sum_{t=1}^{N} |A_t - F_t|^2 \\]\n\\[ RMSE = \\sqrt{MSE} \\]\nThe main problem with scale dependent metrics is that they are not suitable to compare errors from different sources.\nIn our case, the capacity of the power plants would determine the magnitude of the errors and therefore comparing them between facilities would not make much sense.\rThis is something we should try to avoid when choosing the metric.\n\r\rPercentage-error metrics\rNext group express the error in percentage terms.\nMAPE\rThe most widespread one is the Mean Absolute Percentage Error:\n\\[ MAPE_\\% = \\frac{1}{N}\\sum_{t=1}^{N} \\frac{|A_t - F_t|}{A_t} \\times 100\\]\nAs we said above, depending on our goal, MAPE could be suitable or not. From my point of view percentage error metrics have some major drawbacks.\rThey may give different values for two observations with the same absolute error, depending on whether they share the same actual value or not:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r\r\r2\r\r150\r\r100\r\r50\r\r33\r\r\r\r\rBesides, MAPE diverges when actual values tend to zero.\rIn our case it is impractical, as this could lead to extreme cases such as:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r3\r\r1\r\r11\r\r10\r\r1000\r\r\r\r\rThat is an undesired behaviour for an error metric since we don’t want to assign huge errors to deviations that involve insignificant operating costs. That suggests a first strong conclusion:\n\rWe need to find error metrics that are aligned with our business goals.\n\rBesides, in the example above we can see that MAPE isn’t symmetric as it weights differently two residuals whether the forecast is above or below the actual value.\rThat idea of symmetry lead us to sMAPE.\n\rsMAPE\rTrying to solve that assymetry, an alternative to MAPE was proposed. It is called sMAPE, which stands for Symmetric Mean Absolute Percentage Error:\n\\[ sMAPE_\\% = \\frac{2}{N} \\sum_{t=1}^{N}\\frac{|A_t - F_t|}{|A_t| + |F_t|} \\times 100\\]\nHowever, against all odds Symmetric MAPE is not symmetric: as MAPE, it may present different values for the same absolute deviation:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rsMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r20\r\r\r\r2\r\r100\r\r50\r\r50\r\r33\r\r\r\r\rFor our use case it is very inconvenient that the same absolute deviation may be quantified with two different error values.\nThis is a key question: We don’t want to minimize the percentage error but to minimize the economic losses due to forecast deviations, and they are exclusively connected to the sum of the absolute errors.\rTherefore, we should evaluate the accuracy based on that criteria.\nAs a final point, simply mention that some others have proposed the Log Ratio \\(ln(F_t/A_t)\\) as a better alternative to MAPE.\rYou can read a brief description in the previously mentioned sMAPE article or\ran extended discussion in the original paper by Chris Tofallis\n\r\rScale-free error metrics\rThese are error metrics that have been conveniently normalized to make them dimensionless.\nThe main advantages of these metrics are:\n\rSame absolute deviations lead to the same error.\rThey are symmetric.\rThey are comparable between power plants.\rThey are connected to our economic goals.\r\rNMAE\rFirst of all we have NMAE that stands for Normalized Mean Absolute Error.\rThis metric is specific to the energy forecasting business as it is normalized by the capacity C of the power plant, but one could generalize it to any other area provided that there exist an upper bound for the forecasts.\nNMAE is expressed as a percentage. It is our preferred metric as it is truly connected with the business goals, it’s easily interpretable and comparable between plants.\n\\[ NMAE_\\% = \\frac{1}{N}\\sum_{t=1}^{N} \\frac{|A_t - F_t|}{C} \\times 100\\]\nBesides, it shows the desirable property:\n\\[ NMAE_{p1 ∪ p2} = \\frac{1}{2}(NMAE_{p1} + NMAE_{p2})\\]\rGiven both periods have the same length. If not (e.g: consecutive months), you would only have to adjust by their relative length.\n\rThe real-life cost of a forecast error is proportional to the absolute value of the residuals.\n\rThe only case when this metric does not apply is whenever the capacity notion has no sense: If the range of the possible values is not bounded, what normalizing constant should I choose?\nThis would be the case when forecasting temperatures or electricity market prices.\rUsing MAE could be appropiate in these cases, as the units are in the same scale than the magnitude (ºC or €/MWh) and so the errors are easily interpretable, although they would not be truly comparable across different markets or locations.\n\rMAD/Sum Ratio\rIn energy-related businesses, I have spotted another error metric usually (and, as far as I know, wrongly) called WMAE.\rNow, WMAE should stand for “Weighted Mean Average Error”. However, the definition I stumbled upon several times was:\r\\[ \\frac{1}{N}\\frac{ \\sum_{t=1}^{N}{|A_t - F_t|}}{\\sum_{t=1}^{N}{A_t}} \\times 100\\]\nwhich is basically the MAE normalized by acummulated energy production.\nIt resembles MAD/Mean Ratio:\n\\[ MAD/Mean Ratio_\\% = \\frac{1}{N}\\frac{ \\sum_{t=1}^{N}{|A_t - F_t|}}{\\frac{1}{N}\\sum_{t=1}^{N}{A_t}} \\times 100\\]\nFrom my point of view, and as an analogy of the MAD/Mean Ratio, the first expression should be called MAD/Sum Ratio.\rTheir properties are similar:\n\rTheir range is [0, \\(\\infty\\)) for non-negative values, which may be difficult to interpret.\rThey both show the same asymmetry as MAPE: Different error values come from the same absolute difference between forecasts and actuals.\rSmall absolute deviations may be associated to big MAD/Mean or MAD/Sum Ratios, given the actual values are small.\r\rFor all those reasons, we insist on the idea that they are kind of disconnected from our loss function.\n\rMASE\rThere are other scale-free metrics. One of them is MASE (Mean Absolute Scaled Error), proposed by Rob J. Hyndman:\n\\[ MASE =\\frac{\\frac{1}{J} \\sum_j |A_j - F_j|} {\\frac{1}{T-1}\\sum_{t=2}^T |A_{t}-A_{t-1}|} \\]\nwhere the numerator is the error in the forecast period and the denominator is the MAE of the one-step “naive forecast method” on the training set, that is \\(F_t = A_{t-1}\\).\rBecause of that, MASE is a metric specifically designed for time series.\nAgain, whether it is suitable for your needs or not depends entirely on the problem.\rWhile it has certain interesting properties such as scale-independence, convergence when \\(A_t\\to0\\) and symmetry,\rin our case this metric isn’t optimal for several reasons:\n\rThe training series must be completed, i.e., with no gaps. In our case, sometimes we have some measurements missing.\rMASE is equal to 1 when the forecast performance is similar to the naive forecast in the training set. That implies a dependence with the historic period that isn’t always very convenient: if in any given moment we happen to recieve some missing historical production measurements, the accuracy of our model suddenly would change, which may be kind of unintuitive and difficult to track through time.\rMASE is unbounded on the upper side.\rIt doesn’t seem to be a friendly metric to use with non-technical people, such as clients or stakeholders: How large are the expected losses for a 1.2 MASE?\r\r\rEMAE\rI found yet another scale-free error metric in a recent paper from the Energy Department of the Politecnico di Milano,\nThey called it EMAE (Envelope-weighted Mean Absolute Error):\n\\[ EMAE_\\% = \\frac{1}{N}\\frac{ \\sum_{t=1}^{N}{|A_t - F_t|}}{\\sum_{t=1}^{N}{\\max(A_t, F_t)}} \\times 100\\]\nThis metric is quite similar to the MAD/Sum Ratio above but divides by the sum of the maximum between the forecast and the measured power for each observation. It is also expressed as a percentage. This function shows some nice properties:\n\rIt is scale-independent.\rIt is symmetric.\rIt maps absolute deviation to one unique value.\rIt is easily interpretable as its range is [0,100].\rIt doesn’t diverge in any point.\rIt’s a nice alternative to NMAE since a capacity value is not required.\r\rThis formula allows for a cool graphic interpretation of the error: the numerator matchs with the yellow area whereas the denominator corresponds to the sum of the blue and yellow areas:\n\r\rConclusions\r\rThere is no “best metric” to measure model performance. There are several metrics that highlight different characteristics.\n\rOne key aspect is to find error metrics that are connected with our objectives.\n\rSince in most cases the real-life cost of a forecast error is proportional to the absolute value of the residuals, the choice of the metric should be consistent with it.\n\rFor our case, NMAE presents the ideal characteristics of interpretability, stability and relation with our loss function that make it the optimal choice.\n\rEMAE is proposed as a nice alternative for the cases NMAE cannot be applied.\n\r\r\rReferences\r\rAnother look at forecast-accuracy metrics for intermittent demand\rForecasting: Principles and Practice\rErrors on percentage errors\rA new accuracy measure based on bounded relative error for time series forecasting\rComparison of Training Approaches for Photovoltaic Forecasts by Means of Machine Learning\rOn the assymetry of the symmetric MAPE\rA better measure of relative prediction accuracty for model selection and model estimation\rA Guide to Forecast Error Measurement Statistics and How to Use Them\r\r\r","date":1569024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569024000,"objectID":"fb0bd4c5b5e3f82e9eba165fefefac3c","permalink":"/post/energy-forecasting-error-metrics-data-science/","publishdate":"2019-09-21T00:00:00Z","relpermalink":"/post/energy-forecasting-error-metrics-data-science/","section":"post","summary":"A discussion about the main error metrics and their properties","tags":[],"title":"Energy forecasting error metrics","type":"post"},{"authors":["Pablo Cánovas"],"categories":["Metrics","Post"],"content":"\r\rIntroduction\rI recently came across this interesting discussion about percentage errors and I would like to talk about MAPE and its characteristics.\nMAPE is the acronym of Mean Absolute Percentage Error and is defined as\n\\[MAPE = \\frac{100}{N} \\sum_{t=1}^{N} \\frac{|A_t - F_t|}{|A_t|}\\]\nbeing \\(A_t\\) the Actuals and \\(F_t\\) the Forecasts\nThere is some confusion and disagreement about the behaviour of MAPE.\nMAPE express the deviation in relative terms and provides a simple interpretation of the error.\rIt is easy to calculate and communicate and probably that is why it has been widely used in forecasting business.\nHowever, it suffers from some known issues.\n\rThe problems\r\rMAPE ranges from 0 to \\(\\infty\\): it diverges with \\(A_t \\to 0\\) which leads to problems when dealing with data with zero values such as intermittent demand data or energy forecasting.\rThis problem is even worse when working with data with arbitrary zero values, e.g, forecasting temperatures near 0\\(^o\\) in Celsius or Fahrenheit scale. To be fair, this would be an issue using any percentage error metric.\n\rMAPE is said to be asymmetric in the sense it puts heavier penalty on negative errors. When \\(F_t \u0026lt; A_t\\) the maximum possible error value is 100%,\rhowever there is no limit when forecasting on the high side. Besides, given the same absolute difference \\(|A_t - F_t|\\), MAPE is greater when \\(F_t \u0026gt; A_t\\):\n\r\r\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r\r\r2\r\r150\r\r100\r\r50\r\r33\r\r\r\r\rHowever, there is some controversy over this last point.\rSome people argue this is a false dichotomy because it doesn’t make sense to compare two situations where you are exchanging forecast and actual values, and defend MAPE actually is symmetric because you can’t get a lower MAPE just by lowering your forecasts:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r\r\r2\r\r100\r\r50\r\r50\r\r50\r\r\r\r\r\rThe…solution?\rTrying to solve the alledgelly asymmetry, some alternative versions have been proposed. The more general one is:\n\\[ sMAPE = \\frac{200}{N} \\sum_{t=1}^{N}\\frac{|A_t - F_t|}{|A_t| + |F_t|} \\]\nFirst thing to notice is that the range of this symmetric MAPE is \\(\\big[0,200 \\big]\\) which is somewhat antiintuitive. I can’t see myself explaining model deviations in such metric to anybody with a non-technical background.\rThis could be solved simply dividing by 2, although that would be an aesthetic change only.\rOn the bright side, this version of sMAPE doesn’t diverge, which brings some sanity and stability to the metric.\nBut the aspect that really fascinates me is that the so-called symmetric MAPE is not symmetric.\rIn fact, sMAPE symmetrizes the asymmetric case above, and the other way around:\n\rExchanging actual and forecast values does produce the same sMAPE value.\r\r\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\rsMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r20\r\r\r\r2\r\r150\r\r100\r\r50\r\r33\r\r20\r\r\r\r\r\rModifying the forecast while holding fixed actual values and absolute deviation do not produce the same sMAPE value. This maybe the most important case.\r\r\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\rsMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r20\r\r\r\r2\r\r100\r\r50\r\r50\r\r50\r\r33\r\r\r\r\rThis second point is a critical issue: simply biasing the model without improving its accuracy should never produce different error values.\nTaking all this into account, the proposed metric seems to be even worse than the original one. Quite surprising!\n\rAn alternative\rSome others have proposed the log ratio \\(ln(F_t/A_t)\\) as a better alternative to MAPE.\rIt shows, indeed, better statistical properties than others metrics:\n\rApplying least squares regression to this metric estimates the geometric mean whereas minimizing MAPE or sMAPE does not lead to an established measure of location.\rGiven that geometric mean cannot exceed arithmetic mean, using least squares with log ratio will be more robust to outliers than OLS.\rIts values belong to a symmetric range: \\([-\\infty, \\infty]\\). However, it shows the same asymmetric behaviour than sMAPE: Exchanging actuals and forecasts holds the error\r(with a negative value!), but similar absolute deviations with same actual value don’t correspond with equal error values.\r\rIf interested in more information about this less-known metric, check out A better measure of relative prediction accuracy for model selection and model estimation (Chris Tofallis, 2015)\nI hope this may have brought some light into this quirky behaviour of MAPE and sMAPE.\nI also wrote a more general discussion about forecasting error metrics you might want to take a look at.\n\r","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566777600,"objectID":"6745f1f75e5cc5d584d9b01b899b3f77","permalink":"/post/symmetric-mape-is-not-symmetric-data-science/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/post/symmetric-mape-is-not-symmetric-data-science/","section":"post","summary":"Against all odds, it isn't","tags":[],"title":"Symmetric MAPE is not symmetric","type":"post"}]