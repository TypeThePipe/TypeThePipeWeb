[{"authors":["carlos-vecina"],"categories":null,"content":"Carlos Vecina is a data scientist with experience using ML and AI to bring value to business in CRM, Marketing and energy markets environments.\n","date":1579564800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1579564800,"objectID":"7f2ce30e6e7155580a08c73da392044a","permalink":"/authors/carlos-vecina/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/carlos-vecina/","section":"authors","summary":"Carlos Vecina is a data scientist with experience using ML and AI to bring value to business in CRM, Marketing and energy markets environments.","tags":null,"title":"Carlos Vecina","type":"authors"},{"authors":["pablo-canovas"],"categories":null,"content":"Pablo Cánovas is a data scientist with experience developing machine learning models applied to electricity markets.\n","date":1579564800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1579564800,"objectID":"78b4973aee7e471f2427600fe9f47d84","permalink":"/authors/pablo-canovas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/pablo-canovas/","section":"authors","summary":"Pablo Cánovas is a data scientist with experience developing machine learning models applied to electricity markets.","tags":null,"title":"Pablo Cánovas","type":"authors"},{"authors":["Carlos Vecina"],"categories":["R","Post","Shiny","Ggplot"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rHere you can find the R code. It’s an ‘in progress’ script. I will develop basic features like:\n\rploting/rendering code refactoring;\n\rGGanimate with the algortihm steps moving forward;\n\rand, of course, several pathfinding algorithms and evolutionary ones.\n\r\rAll these features and much more in following posts! Stay tuned! \nlibrary (shiny)\rlibrary (ggplot2)\rlibrary (tidyverse)\rsource(\u0026quot;helpers/ColourBorders.R\u0026quot;)\rsource(\u0026quot;helpers/PlotMapGrid.R\u0026quot;)\r\r\rui \u0026lt;-fluidPage(\rmainPanel(\rcolumn(12,offset = 5, \rtitlePanel(\u0026quot;Pathfinding Algorithm Visualization using R!\u0026quot;)),\rHTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\rcolumn(12,offset = 5,HTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\ractionButton(\u0026quot;go_search_actionButton\u0026quot;, \u0026quot;Go Search!\u0026quot;),\ractionButton(\u0026quot;clean_all_actionButton\u0026quot;, \u0026quot;Clean All\u0026quot;)),\rHTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\rcolumn(12,offset=5, plotOutput(\u0026quot;map_grid_plotOutput\u0026quot;,\rclick=\u0026quot;map_grid_plotOutput_click\u0026quot;))\r))\r\r\rserver \u0026lt;-function(input, output){\r\r## Initial params\rmax_steps \u0026lt;-50\rmatrix_x_size \u0026lt;-20\rmatrix_y_size \u0026lt;-20\rgrid_map_reactive \u0026lt;-matrix(ncol = matrix_x_size,\rnrow = matrix_y_size,\rdata = 0) \r\r## Colours Dict (in progress)\r# 1- Wall\r# 2- Init\r# 3- Obj\r# 4- Step done\r# 5- Goal achieved\r\r# Initialize objts\rgrid_map_reactive[4,15] \u0026lt;-3 # obj\rgrid_map_reactive[17,3] \u0026lt;-2 # init\rinitial_step \u0026lt;-which(grid_map_reactive ==2,\rarr.ind = TRUE)\rgrid_map_reactive \u0026lt;-ColourBorders(grid_map_reactive, 1) # rounding walls\rreact_df \u0026lt;-reactiveValues(df = grid_map_reactive,\rorig = grid_map_reactive,\rwalls = grid_map_reactive)\r\robserve({\rif(!is.null(input$map_grid_plotOutput_click)){\rnew_x_value \u0026lt;-trunc(input$map_grid_plotOutput_click$x)\rnew_y_value \u0026lt;-trunc(input$map_grid_plotOutput_click$y)\r\rif(between(new_x_value,2,matrix_x_size-1) \u0026amp;between(new_y_value,2,matrix_y_size-1)){\risolate(react_df$df[new_y_value,new_x_value] \u0026lt;-if_else(react_df$df[new_y_value,new_x_value]==0,\r1,0))\risolate(react_df$df[4,15] \u0026lt;-3)\risolate(react_df$df[17,3] \u0026lt;-2)\risolate(react_df$df[17,3] \u0026lt;-2)\risolate(react_df$walls \u0026lt;-react_df$df)\r\routput$map_grid_plotOutput \u0026lt;-renderPlot({\r\rPlotMapGrid(react_df$df,\rmatrix_x_size,\rmatrix_y_size)\r\r}, width=600, height=600,position=\u0026quot;center\u0026quot;)\r}}\r}) \r\r# Go search! Pseudo-random pathfinding algortihm\robserveEvent(input$go_search_actionButton,{\r\rif(nrow(which(react_df$df ==4, arr.ind = TRUE))\u0026gt;=1) react_df$df \u0026lt;-react_df$walls # click search without clean\rcurrent_step \u0026lt;-initial_step \robj \u0026lt;-which(react_df$df ==3, arr.ind = TRUE)\rprevious_steps_with_opt \u0026lt;-current_step\r\rfor(i in 1:max_steps){\rnext_step_col \u0026lt;-tribble(~row, ~col,\rcurrent_step[1]+1,current_step[2]+0,\rcurrent_step[1]+0,current_step[2]+1,\rcurrent_step[1]-1,current_step[2]+0,\rcurrent_step[1]+0,current_step[2]-1)\rnext_values \u0026lt;-NULL\r\rfor(r in 1:nrow(next_step_col)){\rnext_values \u0026lt;-c(next_values,\rreact_df$df[next_step_col[[r,1]],\rnext_step_col[[r,2]]])\r}\rif(3 %in%next_values){\r\rcurrent_step \u0026lt;-next_step_col[next_values==3,] %\u0026gt;%\ras.matrix()\r\rreact_df$df[current_step] \u0026lt;-5\r\rbreak()\r\r} else if(0 %in%next_values){\r\rif(sum(next_values==0)\u0026gt;1){\r\rprevious_steps_with_opt \u0026lt;-current_step\r\r}\r\rcurrent_step \u0026lt;-next_step_col[next_values==0,] %\u0026gt;%\rsample_n(1) %\u0026gt;%\ras.matrix()\r\rreact_df$df[current_step] \u0026lt;-4\r\r} else {\r\rcurrent_step \u0026lt;-previous_steps_with_opt\r\r}\r}\r})\r\r# Reset all\robserveEvent(input$clean_all_actionButton,{\r\rreact_df$df \u0026lt;-react_df$orig\rreact_df$walls \u0026lt;-react_df$orig\r\r})\r\r# First panel\routput$map_grid_plotOutput \u0026lt;-renderPlot({\r\rPlotMapGrid(react_df$df,\rmatrix_x_size,\rmatrix_y_size)\r\r}, width=550, height=600,position=\u0026quot;center\u0026quot;)\r\r}\r\r\rshinyApp(ui=ui, server = server)\rHere the helpers:\nColourBorders \u0026lt;-function(df, col_value){\r\r## Rounding walls \r# Params: df - Map grid\r# col_value - Colour to fill the rounding blocks\r# Return: df with the filled roundings\r\rdf[1,] \u0026lt;-col_value\rdf[,1] \u0026lt;-col_value\rdf[nrow(df),] \u0026lt;-col_value\rdf[,ncol(df)] \u0026lt;-col_value\r\rreturn(df)\r\r}\r\rPlotMapGrid \u0026lt;-function(df, matrix_x_size, matrix_y_size){\r\r## Plot the interactive grid \r# Params: df - Map grid\r# matrix_x_size - X_axis limit\r# matrix_y_size - Y_axis limit\r# Return: plot with the pathfinding\r\r\rplot \u0026lt;-rbind(\rwhich(df==1, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#623B17\u0026quot;),\rwhich(df ==2, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#13293D\u0026quot;),\rwhich(df ==3, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#ffff66\u0026quot;),\rwhich(df ==4, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#99ccff\u0026quot;),\rwhich(df ==5, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#1B998B\u0026quot;)\r\r) %\u0026gt;%\rdata.frame(stringsAsFactors = F) %\u0026gt;%\rtransmute(y = as.numeric(row), x = as.numeric(col), fill_col=fill_col) %\u0026gt;%\rggplot(aes(x+0.5,y+0.5)) +\rgeom_tile(width = 1, height = 1, fill = df$fill_col, col=\u0026quot;black\u0026quot;) +\rscale_y_reverse() +\rscale_x_continuous(breaks = seq(0, matrix_x_size, 1),\rlimits = c(0+0.5, matrix_x_size+1.5), \rminor_breaks = NULL) +\rscale_y_continuous(breaks = seq(0, matrix_y_size, 1),\rlimits = c(0+0.5, matrix_y_size+1.5),\rminor_breaks = NULL) +\rtheme_linedraw()+\rtheme(axis.title.x=element_blank(),\raxis.title.y=element_blank(),\raxis.text.x=element_blank(),\raxis.text.y=element_blank(),\raxis.ticks.x=element_blank(),\raxis.ticks.y=element_blank())\r\rreturn(plot)\r\r}\r\rbody {\rtext-align: justify}\rp {\rword-spacing: 3px;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579564800,"objectID":"888307249c7c1afd21aafa2805a68715","permalink":"/post/pathfinding-algorithms-visualizer-using-r/","publishdate":"2020-01-21T00:00:00Z","relpermalink":"/post/pathfinding-algorithms-visualizer-using-r/","section":"post","summary":"Setting up the interactive grid with Shiny and ggplot! Trail with some kind of random-walker algorithm.","tags":[],"title":"Pathfinding Algorithms Visualizer using R! (I) Setting up the interactive grid","type":"post"},{"authors":["Pablo Cánovas"],"categories":["R","Tips","Tidyverse"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rSome time ago I made one of the best discoveries I have ever made in the Tidyverse: a tool called tidylog.\rThis package is built on top of dplyr and tidyr and provides us with feedback on the results of the operations. Actually, this is a feature that already appeared in the Stata software.\nWhen performing one operation at a time, it is easy to track the changes made on a table.\rHowever things get increasingly obscure when chaining multiple functions or dealing with big data frames.\nWe all love piping operations. I often ‘play’ to perform the whole transformation without leaving the pipeflow. But the counterpart is missing the intermediate states: you can make some big mistakes and be unaware of them until it’s too late and maybe you have to undone some work or rethink your analysis.\nIn this context, some additional info is always welcome. I think this feature is specially convenient for beginners, but not only! I have myself wasted several hours debugging long pipelines and trying to understand where the problems came from.\nLet’s see a tiny bit of its behaviour with a simple example:\nflights %\u0026gt;%\rselect(year:day, hour, origin, dest, tailnum, carrier) %\u0026gt;%\rmutate(month = if_else(nchar(month) ==1, paste0(\u0026quot;0\u0026quot;,month), as.character(month)),\rday = if_else(nchar(day) ==1, paste0(\u0026quot;0\u0026quot;,day), as.character(day))) %\u0026gt;%\runite(\u0026quot;date\u0026quot;, year:day, sep = \u0026quot;/\u0026quot;, remove = T) %\u0026gt;%\rmutate(date = ymd(date)) %\u0026gt;%\rfilter(hour \u0026gt;=8) %\u0026gt;%\ranti_join(planes, by = \u0026quot;tailnum\u0026quot;) %\u0026gt;%\rcount(tailnum, sort = TRUE) \r\r# select: dropped 11 variables (dep_time, sched_dep_time, dep_delay, arr_time, sched_arr_time, …)\r# mutate: converted \u0026#39;month\u0026#39; from integer to character (0 new NA)\r# converted \u0026#39;day\u0026#39; from integer to character (0 new NA)\r# mutate: converted \u0026#39;date\u0026#39; from character to double (0 new NA)\r# filter: removed 50,726 rows (15%), 286,050 rows remaining\r# anti_join: added no columns\r# \u0026gt; rows only in x 45,008\r# \u0026gt; rows only in y ( 39)\r# \u0026gt; matched rows (241,042)\r# \u0026gt; =========\r# \u0026gt; rows total 45,008\r# count: now 716 rows and 2 columns, ungrouped\rPretty neat! It is specially useful with joins, as it provides plenty of details and they can be a source of duplicated or missing rows.\nI decided to write this little post now to celebrate that tidylog v1.0.0 has recently been released! Check the official repo out to see more examples or show some love to @elbersb on Twitter!\nAll in all, I think this package was a missing piece in the Tidyverse ecosystem: It is incredibly useful, whereas making advantage of it is as simple as writing library(tidylog). Integrating this package into our daily R work is a no-brainer!\n\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579564800,"objectID":"08a407f74d15e353bdba6f8a76b3808a","permalink":"/vizs-and-tips/tidylog/","publishdate":"2020-01-21T00:00:00Z","relpermalink":"/vizs-and-tips/tidylog/","section":"vizs-and-tips","summary":"Logging your pipelines","tags":[],"title":"Tidylog","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips","Tidyverse"],"content":"\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rSupose you are analysing survey data. You are asked to get the mean in a representative way, weighting your individuals depending on the number of members of their segment.\nlibrary(tidyverse)\r\rsurvey_data \u0026lt;-tribble(\r~id, ~region1, ~region2, ~gender, ~q1, ~q2,\r1,\u0026quot;sp\u0026quot;,\u0026quot;mad\u0026quot;,\u0026quot;m\u0026quot;, 2,5,\r2,\u0026quot;it\u0026quot;, \u0026quot;bol\u0026quot;, \u0026quot;m\u0026quot;, 5, 10,\r3,\u0026quot;sp\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;f\u0026quot;, 2, 2,\r4,\u0026quot;sp\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;f\u0026quot;, 7, 7,\r5,\u0026quot;it\u0026quot;, \u0026quot;bol\u0026quot;, \u0026quot;m\u0026quot;, 2, 7) \rsurvey_data %\u0026gt;%\rgroup_by(region1, region2, gender) %\u0026gt;%\rmutate(weight = 1/n()) %\u0026gt;%\rungroup() %\u0026gt;%\rsummarise_at(vars(contains(\u0026quot;q\u0026quot;)),\rfuns(weighted_mean = sum(. *weight)/sum(weight)))\r\r\rq1_weighted_mean\r\rq2_weighted_mean\r\r\r\r\r\r3.333333\r\r6\r\r\r\r\r","date":1579132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579132800,"objectID":"012435e267765e93675d8ea0f583660f","permalink":"/vizs-and-tips/summarise_at-weighted-mean-tidyverse/","publishdate":"2020-01-16T00:00:00Z","relpermalink":"/vizs-and-tips/summarise_at-weighted-mean-tidyverse/","section":"vizs-and-tips","summary":"Survey analysis using R","tags":[],"title":"Using summarise_at(). Weighted mean Tidyverse approach","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Tips","Magic"],"content":"\rA recurrent complain about Jupyter Notebooks between beginner users is the lack of information about the self-created environment variables. If you have this question, probably first of all you should be sure about the Jupyter Notebooks main purpose (totally different from IDEs like Spyder or Pycharm).\nBut in case a notebook is all what you need, you have few ways to display this information. The first and easiest one is to use the magic method %whos\rTwo alternative ways are nbextension and Jupyter Lab variable inspector. You can find more information here\n","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"28ebdcebc3be362d7f68c200d4adcfcb","permalink":"/vizs-and-tips/magic-whos/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/vizs-and-tips/magic-whos/","section":"vizs-and-tips","summary":"Kind of magic","tags":[],"title":"List all the defined variables in Jupyter Notebooks","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Vizs","Ggplot2"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rYou can see the code below :)\nlibrary(ggplot2)\r# library(plotly)\rlibrary(tibble)\rlibrary(dplyr)\r\rskills \u0026lt;-tribble(\r~Skill, ~Hours, ~Class,\r\u0026quot;AWS\u0026quot;, 500, \u0026quot;BigData\u0026quot;,\r\u0026quot;Python\u0026quot;, 8000, \u0026quot;Language\u0026quot;,\r\u0026quot;Spark\u0026quot;, 4000, \u0026quot;BigData\u0026quot;,\r\u0026quot;R\u0026quot;, 9000, \u0026quot;Language\u0026quot;,\r\u0026quot;Git\u0026quot;, 2000, \u0026quot;Tools\u0026quot;,\r\u0026quot;Jira\u0026quot;, 2000, \u0026quot;Tools\u0026quot;,\r\u0026quot;Forecasting\u0026quot;, 5000, \u0026quot;Objetive\u0026quot;,\r\u0026quot;Segmentation\u0026quot;, 2000, \u0026quot;Objetive\u0026quot;,\r\u0026quot;Computer Vision\u0026quot;, 600, \u0026quot;Objetive\u0026quot;,\r\u0026quot;SQL\u0026quot;, 4500, \u0026quot;Language\u0026quot;,\r\u0026quot;IBM Data Stage \u0026amp; SPSS\u0026quot;, 1200, \u0026quot;Tools\u0026quot;,\r\u0026quot;Shiny R\u0026quot;, 1500, \u0026quot;Visualization\u0026quot;,\r\u0026quot;Tableau\u0026quot;, 1000, \u0026quot;Visualization\u0026quot;,\r\u0026quot;Spotfire\u0026quot;, 500, \u0026quot;Visualization\u0026quot;\r) \r# plotly(\rggplot(data=skills,aes(x=reorder(Skill,-desc(Hours)), y= Hours, fill=Class, label=paste0(Hours,\u0026quot; h\u0026quot;))) +\rgeom_bar(stat = \u0026quot;identity\u0026quot;, colour=\u0026quot;black\u0026quot;) +\rcoord_flip() +\rlabs(x=\u0026quot; \u0026quot;, y=\u0026quot;Hours\u0026quot;, fill=\u0026quot; \u0026quot;) +\rtheme_minimal() +\rscale_fill_brewer(palette = \u0026quot;YlOrBr\u0026quot;,direction = -1) +\rgeom_label(show_guide = F, aes(y=400)) # Use show_guide despite the warning\r","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578355200,"objectID":"928907531386dec428888f171d0aca3c","permalink":"/vizs-and-tips/skills-chart/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/vizs-and-tips/skills-chart/","section":"vizs-and-tips","summary":"Skills snapshot in 6 Ggplot2 lines","tags":[],"title":"Skills chart using Gplot2 with R","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips","Ggplot"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rlibrary(ggplot2)\rlibrary(gganimate)\rlibrary(tidyverse)\rdf_evolution_data \u0026lt;-data.frame(Name=rep(c(\u0026quot;Madrid\u0026quot;,\u0026quot;Barcelona\u0026quot;,\r\u0026quot;Valencia\u0026quot;,\u0026quot;Alicante\u0026quot;,\r\u0026quot;Sevilla\u0026quot;),5),\rYear = factor(sort(rep(2001:2005, 5))),\rValue = runif(25,100,1000))\rdf_evolution_data_filtered \u0026lt;-df_evolution_data %\u0026gt;%\rgroup_by(Year) %\u0026gt;%\rmutate(Rank = rank(Value)) %\u0026gt;%\rfilter(Rank \u0026gt;=2)\rggplot(df_evolution_data_filtered) +\rgeom_col(aes(x=Rank, y=Value, group=Name, fill=Name), width=0.4) +\rgeom_text(aes(x=Rank, y=0, label=Name, group=Name), hjust=1.25) +\rtheme_minimal() +ylab(\u0026#39;Value\u0026#39;) +\rtheme(axis.title.y = element_blank(),\raxis.text.y = element_blank(),\raxis.ticks.y = element_blank(),\rplot.margin = unit(c(5,5,5,5), \u0026#39;lines\u0026#39;)) +\rscale_fill_brewer(palette=\u0026quot;Dark2\u0026quot;) +\rcoord_flip(clip=\u0026#39;off\u0026#39;) +\rggtitle(\u0026#39;{closest_state}\u0026#39;) +\rtransition_states(Year, transition_length = 1, state_length = 1) +\rexit_fly(x_loc = 0, y_loc = 0) +enter_fly(x_loc = 0, y_loc = 0)\r","date":1576540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576540800,"objectID":"90ec1d6400b13e773818b1e133f3e258","permalink":"/vizs-and-tips/reorder-bars-gganimate/","publishdate":"2019-12-17T00:00:00Z","relpermalink":"/vizs-and-tips/reorder-bars-gganimate/","section":"vizs-and-tips","summary":"Reorder your groups over time in gganimate plot.","tags":[],"title":"Reordering bars in GGanimate visualization","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips","Ggplot"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rlibrary(tidyverse)\rhuron \u0026lt;-data.frame(year = 1875:1972, \rvalue = LakeHuron,\rstd = runif(length(LakeHuron),0,1))\r\rhuron %\u0026gt;%\rggplot(aes(year, value)) +\rgeom_ribbon(aes(ymin = value -std, ymax = value +std), fill = \u0026quot;steelblue2\u0026quot;) +\rgeom_line(color = \u0026quot;firebrick\u0026quot;, size = 1)\rFor a multi-line plot, you should include the colour and group aesthetic as follows:\nlibrary(tidyverse)\rhuron \u0026lt;-data.frame(year = rep(1875:1972,2), \rgroup = c(rep(\u0026quot;a\u0026quot;,98),rep(\u0026quot;b\u0026quot;,98)),\rvalue = c(LakeHuron, LakeHuron +5),\rstd = runif(length(LakeHuron)*2,0,1))\r\rhuron %\u0026gt;%\rggplot(aes(year, value, fill = group)) +\rgeom_ribbon(aes(ymin = value -std, ymax = value +std, group=group), fill = \u0026quot;steelblue2\u0026quot;) +\rgeom_line(color = \u0026quot;firebrick\u0026quot;, size = 1)\r","date":1574035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574035200,"objectID":"ea3799e1edee098e2153caf2e4b83d01","permalink":"/vizs-and-tips/ggplot-geom_ribbon-shadow/","publishdate":"2019-11-18T00:00:00Z","relpermalink":"/vizs-and-tips/ggplot-geom_ribbon-shadow/","section":"vizs-and-tips","summary":"Plot your confidence intervals easily","tags":[],"title":"Shadowing your ggplot lines. Forecasting confidence interval use case.","type":"vizs-and-tips"},{"authors":["Pablo Cánovas"],"categories":["R","Tidyverse","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rHow could we apply certain functions conditionally without leaving the pipeflow?\rThis way:\ndf %\u0026gt;%{ if(apply_filter ==TRUE) filter(., condition) else . } %\u0026gt;%...\r","date":1572652800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572652800,"objectID":"970eb8056d2f591261051640a757ce2a","permalink":"/vizs-and-tips/conditional-pipes/","publishdate":"2019-11-02T00:00:00Z","relpermalink":"/vizs-and-tips/conditional-pipes/","section":"vizs-and-tips","summary":"Don't leave the pipeflow","tags":[],"title":"Conditional Pipes","type":"vizs-and-tips"},{"authors":["Pablo Cánovas"],"categories":["R","Tidyverse","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rSome times you need to filter a data frame applying the same condition over multiple columns. Obviously you could explicitly write the condition over every column, but that’s not very handy.\nFor those situations, it is much better to use filter_at in combination with all_vars.\nImagine we have the famous iris dataset with some attributes missing and want to get rid of those observations with any missing value.\n## # A tibble: 10 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 2 NA 3 1.4 NA setosa ## 3 3 4.7 3.2 1.3 0.2 setosa ## 4 4 NA 3.1 1.5 0.2 setosa ## 5 5 5 3.6 1.4 0.2 setosa ## 6 6 5.4 3.9 1.7 0.4 setosa ## 7 7 4.6 3.4 1.4 0.3 setosa ## 8 8 NA 3.4 1.5 0.2 setosa ## 9 9 4.4 2.9 1.4 0.2 setosa ## 10 10 NA NA NA NA setosa\rWe could write the condition on every column, but that would cumbersome:\niris %\u0026gt;%\rfilter(!is.na(Sepal.Length) \u0026amp;\r!is.na(Sepal.Width) \u0026amp;\r!is.na(Petal.Length) \u0026amp;\r!is.na(Petal.Width)\r)\rInstead, we just have to select the columns we will filter on and apply the condition:\nfeatures \u0026lt;-iris %\u0026gt;%names() %\u0026gt;%keep(~str_detect(.,\u0026quot;[.]\u0026quot;))\riris %\u0026gt;%filter_at(vars(features), all_vars(!is.na(.)))\r## # A tibble: 5 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 3 4.7 3.2 1.3 0.2 setosa ## 2 5 5 3.6 1.4 0.2 setosa ## 3 6 5.4 3.9 1.7 0.4 setosa ## 4 7 4.6 3.4 1.4 0.3 setosa ## 5 9 4.4 2.9 1.4 0.2 setosa\rHere we have used the function all_vars in the predicate to explicit that\revery feature must satisfy the condition.\rTo be honest, for that purpose it would have been easier to simply use iris %\u0026gt;% na.omit().\nBut what if we wanted the opposite? Keeping only the rows with all the selected features missing is as easy as changing the predicate part:\niris %\u0026gt;%filter_at(vars(features), all_vars(is.na(.)))\r## # A tibble: 1 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 10 NA NA NA NA setosa\rAnother option is to apply the condition on any feature. That’s where any_vars comes to rescue. Here we keep only the observations with at least one missing feature:\niris %\u0026gt;%filter_at(vars(features), any_vars(is.na(.)))\r## # A tibble: 5 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 2 NA 3 1.4 NA setosa ## 3 4 NA 3.1 1.5 0.2 setosa ## 4 8 NA 3.4 1.5 0.2 setosa ## 5 10 NA NA NA NA setosa\rAlso, there are some other fancy ways to manipulate data frames with the filter family. One trick is using contains() or starts_with() to select the variables:\niris %\u0026gt;%filter_at(vars(contains(\u0026quot;Length\u0026quot;)), all_vars(. \u0026gt;=1.4))\r## # A tibble: 5 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 5 5 3.6 1.4 0.2 setosa ## 3 6 5.4 3.9 1.7 0.4 setosa ## 4 7 4.6 3.4 1.4 0.3 setosa ## 5 9 4.4 2.9 1.4 0.2 setosa\rAnother example is applying the condition on columns that satisfy certain condition with filter_if:\niris %\u0026gt;%filter_if(is.numeric, any_vars(. \u0026gt;5))\r## # A tibble: 6 x 6\r## rowid Sepal.Length Sepal.Width Petal.Length Petal.Width Species\r## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 1 5.1 NA 1.4 0.2 setosa ## 2 6 5.4 3.9 1.7 0.4 setosa ## 3 7 4.6 3.4 1.4 0.3 setosa ## 4 8 NA 3.4 1.5 0.2 setosa ## 5 9 4.4 2.9 1.4 0.2 setosa ## 6 10 NA NA NA NA setosa\r","date":1570233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570233600,"objectID":"d12377ce3bed7facae426c6025077a6c","permalink":"/vizs-and-tips/filtering-a-data-frame-by-condition-on-multiple-columns/","publishdate":"2019-10-05T00:00:00Z","relpermalink":"/vizs-and-tips/filtering-a-data-frame-by-condition-on-multiple-columns/","section":"vizs-and-tips","summary":"You could write the condition over each column, but I would like to see you with 100+ features","tags":[],"title":"Filtering a data frame by condition on multiple columns","type":"vizs-and-tips"},{"authors":["Pablo Cánovas"],"categories":["metrics"],"content":"\r\r\rIntroduction\rScale dependent error metrics\rPercentage-error metrics\rScale-free error metrics\rConclusions\rReferences\r\r\rIntroduction\rThe idea of this post comes from the different error metrics I have dealt with working with time series data and forecasting models.\nAmong other things, we make energy production forecasts of renewable power plants of different capacities and technologies.\rOur aim is to develop forecasting models that reduce the penalties caused by the deviations.\nMost of the models I work with are regression models, and therefore in this article I am focusing only on regression error metrics.\nUnfortunately, there is no absolute “right” accuracy metric.\rChoosing the right metric is a problem-specific matter, and it involves answering questions like:\n\rWhich decision will you base on the forecast?\rWhat are the consequences of a wrong forecast?\rWho is going to check and monitorize the errors?\rDo we care about the percentage error or about the magnitude of the deviation?\rDoes it makes any difference to over-forecast or under-forecast the variable of interest?\r\rAnswering the above questions lead us to determine we need to find a metric that:\n\rIs scale independent, so the errors are comparable between power plants.\rIs symmetric, as we do not want to weight the deviations differently according to their sign.\rExpress the error in absolute terms, so the error reflects the real-life imbalance costs.\rThe error calculated over different periods should be equivalent to the aggregated calculation over those periods individually.\r\rEach metric behaves in a certain way and therefore reflects in a unique manner the features of the models.\rDepending on their properties, we can classify the metrics in several categories.\rLet’s take a look at them:\n\rScale dependent error metrics\rMaybe the most popular and simple error metric is MAE:\nMAE:\rThe Mean Absolute Error is defined as:\n\\[ MAE = \\frac{1}{N}\\sum_{t=1}^{N} |A_t - F_t| \\]\nWhile the MAE is easily interpretable (each residual contributes proportionally to the total amount of error), one could argue that using the sum of the residuals is not the best choice, as we could want to highlight especially whether the model incur in some large errors.\n\rMSE \u0026amp; RMSE\rFor those cases, maybe MSE (Mean Squared Error) or RMSE (Root Mean Squared Error) are a better choice. Here the error grows quadratically and therefore extreme values penalize the metric to a greater extent.\n\\[ MSE = \\frac{1}{N} \\sum_{t=1}^{N} |A_t - F_t|^2 \\]\n\\[ RMSE = \\sqrt{MSE} \\]\nThe main problem with scale dependent metrics is that they are not suitable to compare errors from different sources.\nIn our case, the capacity of the power plants would determine the magnitude of the errors and therefore comparing them between facilities would not make much sense.\rThis is something we should try to avoid when choosing the metric.\n\r\rPercentage-error metrics\rNext group express the error in percentage terms.\nMAPE\rThe most widespread one is the Mean Absolute Percentage Error:\n\\[ MAPE_\\% = \\frac{1}{N}\\sum_{t=1}^{N} \\frac{|A_t - F_t|}{A_t} \\times 100\\]\nAs we said above, depending on our goal, MAPE could be suitable or not. From my point of view percentage error metrics have some major drawbacks.\rThey may give different values for two observations with the same absolute error, depending on whether they share the same actual value or not:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r\r\r2\r\r150\r\r100\r\r50\r\r33\r\r\r\r\rBesides, MAPE diverges when actual values tend to zero.\rIn our case it is impractical, as this could lead to extreme cases such as:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r3\r\r1\r\r11\r\r10\r\r1000\r\r\r\r\rThat is an undesired behaviour for an error metric since we don’t want to assign huge errors to deviations that involve insignificant operating costs. That suggests a first strong conclusion:\n\rWe need to find error metrics that are aligned with our business goals.\n\rBesides, in the example above we can see that MAPE isn’t symmetric as it weights differently two residuals whether the forecast is above or below the actual value.\rThat idea of symmetry lead us to sMAPE.\n\rsMAPE\rTrying to solve that assymetry, an alternative to MAPE was proposed. It is called sMAPE, which stands for Symmetric Mean Absolute Percentage Error:\n\\[ sMAPE_\\% = \\frac{2}{N} \\sum_{t=1}^{N}\\frac{|A_t - F_t|}{|A_t| + |F_t|} \\times 100\\]\nHowever, against all odds Symmetric MAPE is not symmetric: as MAPE, it may present different values for the same absolute deviation:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rsMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r20\r\r\r\r2\r\r100\r\r50\r\r50\r\r33\r\r\r\r\rFor our use case it is very inconvenient that the same absolute deviation may be quantified with two different error values.\nThis is a key question: We don’t want to minimize the percentage error but to minimize the economic losses due to forecast deviations, and they are exclusively connected to the sum of the absolute errors.\rTherefore, we should evaluate the accuracy based on that criteria.\nAs a final point, simply mention that some others have proposed the Log Ratio \\(ln(F_t/A_t)\\) as a better alternative to MAPE.\rYou can read a brief description in the previously mentioned sMAPE article or\ran extended discussion in the original paper by Chris Tofallis\n\r\rScale-free error metrics\rThese are error metrics that have been conveniently normalized to make them dimensionless.\nThe main advantages of these metrics are:\n\rSame absolute deviations lead to the same error.\rThey are symmetric.\rThey are comparable between power plants.\rThey are connected to our economic goals.\r\rNMAE\rFirst of all we have NMAE that stands for Normalized Mean Absolute Error.\rThis metric is specific to the energy forecasting business as it is normalized by the capacity C of the power plant, but one could generalize it to any other area provided that there exist an upper bound for the forecasts.\nNMAE is expressed as a percentage. It is our preferred metric as it is truly connected with the business goals, it’s easily interpretable and comparable between plants.\n\\[ NMAE_\\% = \\frac{1}{N}\\sum_{t=1}^{N} \\frac{|A_t - F_t|}{C} \\times 100\\]\nBesides, it shows the desirable property:\n\\[ NMAE_{p1 ∪ p2} = \\frac{1}{2}(NMAE_{p1} + NMAE_{p2})\\]\rGiven both periods have the same length. If not (e.g: consecutive months), you would only have to adjust by their relative length.\n\rThe real-life cost of a forecast error is proportional to the absolute value of the residuals.\n\rThe only case when this metric does not apply is whenever the capacity notion has no sense: If the range of the possible values is not bounded, what normalizing constant should I choose?\nThis would be the case when forecasting temperatures or electricity market prices.\rUsing MAE could be appropiate in these cases, as the units are in the same scale than the magnitude (ºC or €/MWh) and so the errors are easily interpretable, although they would not be truly comparable across different markets or locations.\n\rMAD/Sum Ratio\rIn energy-related businesses, I have spotted another error metric usually (and, as far as I know, wrongly) called WMAE.\rNow, WMAE should stand for “Weighted Mean Average Error”. However, the definition I stumbled upon several times was:\r\\[ \\frac{1}{N}\\frac{ \\sum_{t=1}^{N}{|A_t - F_t|}}{\\sum_{t=1}^{N}{A_t}} \\times 100\\]\nwhich is basically the MAE normalized by acummulated energy production.\nIt resembles MAD/Mean Ratio:\n\\[ MAD/Mean Ratio_\\% = \\frac{1}{N}\\frac{ \\sum_{t=1}^{N}{|A_t - F_t|}}{\\frac{1}{N}\\sum_{t=1}^{N}{A_t}} \\times 100\\]\nFrom my point of view, and as an analogy of the MAD/Mean Ratio, the first expression should be called MAD/Sum Ratio.\rTheir properties are similar:\n\rTheir range is [0, \\(\\infty\\)) for non-negative values, which may be difficult to interpret.\rThey both show the same asymmetry as MAPE: Different error values come from the same absolute difference between forecasts and actuals.\rSmall absolute deviations may be associated to big MAD/Mean or MAD/Sum Ratios, given the actual values are small.\r\rFor all those reasons, we insist on the idea that they are kind of disconnected from our loss function.\n\rMASE\rThere are other scale-free metrics. One of them is MASE (Mean Absolute Scaled Error), proposed by Rob J. Hyndman:\n\\[ MASE =\\frac{\\frac{1}{J} \\sum_j |A_j - F_j|} {\\frac{1}{T-1}\\sum_{t=2}^T |A_{t}-A_{t-1}|} \\]\nwhere the numerator is the error in the forecast period and the denominator is the MAE of the one-step “naive forecast method” on the training set, that is \\(F_t = A_{t-1}\\).\rBecause of that, MASE is a metric specifically designed for time series.\nAgain, whether it is suitable for your needs or not depends entirely on the problem.\rWhile it has certain interesting properties such as scale-independence, convergence when \\(A_t\\to0\\) and symmetry,\rin our case this metric isn’t optimal for several reasons:\n\rThe training series must be completed, i.e., with no gaps. In our case, sometimes we have some measurements missing.\rMASE is equal to 1 when the forecast performance is similar to the naive forecast in the training set. That implies a dependence with the historic period that isn’t always very convenient: if in any given moment we happen to recieve some missing historical production measurements, the accuracy of our model suddenly would change, which may be kind of unintuitive and difficult to track through time.\rMASE is unbounded on the upper side.\rIt doesn’t seem to be a friendly metric to use with non-technical people, such as clients or stakeholders: How large are the expected losses for a 1.2 MASE?\r\r\rEMAE\rI found yet another scale-free error metric in a recent paper from the Energy Department of the Politecnico di Milano,\nThey called it EMAE (Envelope-weighted Mean Absolute Error):\n\\[ EMAE_\\% = \\frac{1}{N}\\frac{ \\sum_{t=1}^{N}{|A_t - F_t|}}{\\sum_{t=1}^{N}{\\max(A_t, F_t)}} \\times 100\\]\nThis metric is quite similar to the MAD/Sum Ratio above but divides by the sum of the maximum between the forecast and the measured power for each observation. It is also expressed as a percentage. This function shows some nice properties:\n\rIt is scale-independent.\rIt is symmetric.\rIt maps absolute deviation to one unique value.\rIt is easily interpretable as its range is [0,100].\rIt doesn’t diverge in any point.\rIt’s a nice alternative to NMAE since a capacity value is not required.\r\rThis formula allows for a cool graphic interpretation of the error: the numerator matchs with the yellow area whereas the denominator corresponds to the sum of the blue and yellow areas:\n\r\rConclusions\r\rThere is no “best metric” to measure model performance. There are several metrics that highlight different characteristics.\n\rOne key aspect is to find error metrics that are connected with our objectives.\n\rSince in most cases the real-life cost of a forecast error is proportional to the absolute value of the residuals, the choice of the metric should be consistent with it.\n\rFor our case, NMAE presents the ideal characteristics of interpretability, stability and relation with our loss function that make it the optimal choice.\n\rEMAE is proposed as a nice alternative for the cases NMAE cannot be applied.\n\r\r\rReferences\r\rAnother look at forecast-accuracy metrics for intermittent demand\rForecasting: Principles and Practice\rErrors on percentage errors\rA new accuracy measure based on bounded relative error for time series forecasting\rComparison of Training Approaches for Photovoltaic Forecasts by Means of Machine Learning\rOn the assymetry of the symmetric MAPE\rA better measure of relative prediction accuracty for model selection and model estimation\rA Guide to Forecast Error Measurement Statistics and How to Use Them\r\r\r","date":1569024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569024000,"objectID":"a9c0cc0b31d8a90b243453f2313c02fa","permalink":"/post/energy-forecasting-error-metrics/","publishdate":"2019-09-21T00:00:00Z","relpermalink":"/post/energy-forecasting-error-metrics/","section":"post","summary":"A discussion about the main error metrics and their properties","tags":[],"title":"Energy forecasting error metrics","type":"post"},{"authors":["Pablo Cánovas"],"categories":["metrics"],"content":"\r\rIntroduction\rI recently came across this interesting discussion about percentage errors and I would like to talk about MAPE and its characteristics.\nMAPE is the acronym of Mean Absolute Percentage Error and is defined as\n\\[MAPE = \\frac{100}{N} \\sum_{t=1}^{N} \\frac{|A_t - F_t|}{|A_t|}\\]\nbeing \\(A_t\\) the Actuals and \\(F_t\\) the Forecasts\nThere is some confusion and disagreement about the behaviour of MAPE.\nMAPE express the deviation in relative terms and provides a simple interpretation of the error.\rIt is easy to calculate and communicate and probably that is why it has been widely used in forecasting business.\nHowever, it suffers from some known issues.\n\rThe problems\r\rMAPE ranges from 0 to \\(\\infty\\): it diverges with \\(A_t \\to 0\\) which leads to problems when dealing with data with zero values such as intermittent demand data or energy forecasting.\rThis problem is even worse when working with data with arbitrary zero values, e.g, forecasting temperatures near 0\\(^o\\) in Celsius or Fahrenheit scale. To be fair, this would be an issue using any percentage error metric.\n\rMAPE is said to be asymmetric in the sense it puts heavier penalty on negative errors. When \\(F_t \u0026lt; A_t\\) the maximum possible error value is 100%,\rhowever there is no limit when forecasting on the high side. Besides, given the same absolute difference \\(|A_t - F_t|\\), MAPE is greater when \\(F_t \u0026gt; A_t\\):\n\r\r\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r\r\r2\r\r150\r\r100\r\r50\r\r33\r\r\r\r\rHowever, there is some controversy over this last point.\rSome people argue this is a false dichotomy because it doesn’t make sense to compare two situations where you are exchanging forecast and actual values, and defend MAPE actually is symmetric because you can’t get a lower MAPE just by lowering your forecasts:\n\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r\r\r2\r\r100\r\r50\r\r50\r\r50\r\r\r\r\r\rThe…solution?\rTrying to solve the alledgelly asymmetry, some alternative versions have been proposed. The more general one is:\n\\[ sMAPE = \\frac{200}{N} \\sum_{t=1}^{N}\\frac{|A_t - F_t|}{|A_t| + |F_t|} \\]\nFirst thing to notice is that the range of this symmetric MAPE is \\(\\big[0,200 \\big]\\) which is somewhat antiintuitive. I can’t see myself explaining model deviations in such metric to anybody with a non-technical background.\rThis could be solved simply dividing by 2, although that would be an aesthetic change only.\rOn the bright side, this version of sMAPE doesn’t diverge, which brings some sanity and stability to the metric.\nBut the aspect that really fascinates me is that the so-called symmetric MAPE is not symmetric.\rIn fact, sMAPE symmetrizes the asymmetric case above, and the other way around:\n\rExchanging actual and forecast values does produce the same sMAPE value.\r\r\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\rsMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r20\r\r\r\r2\r\r150\r\r100\r\r50\r\r33\r\r20\r\r\r\r\r\rModifying the forecast while holding fixed actual values and absolute deviation do not produce the same sMAPE value. This maybe the most important case.\r\r\r\rCase\r\rActual\r\rForecast\r\rAbsoluteDifference\r\rMAPE\r\rsMAPE\r\r\r\r\r\r1\r\r100\r\r150\r\r50\r\r50\r\r20\r\r\r\r2\r\r100\r\r50\r\r50\r\r50\r\r33\r\r\r\r\rThis second point is a critical issue: simply biasing the model without improving its accuracy should never produce different error values.\nTaking all this into account, the proposed metric seems to be even worse than the original one. Quite surprising!\n\rAn alternative\rSome others have proposed the log ratio \\(ln(F_t/A_t)\\) as a better alternative to MAPE.\rIt shows, indeed, better statistical properties than others metrics:\n\rApplying least squares regression to this metric estimates the geometric mean whereas minimizing MAPE or sMAPE does not lead to an established measure of location.\rGiven that geometric mean cannot exceed arithmetic mean, using least squares with log ratio will be more robust to outliers than OLS.\rIts values belong to a symmetric range: \\([-\\infty, \\infty]\\). However, it shows the same asymmetric behaviour than sMAPE: Exchanging actuals and forecasts holds the error\r(with a negative value!), but similar absolute deviations with same actual value don’t correspond with equal error values.\r\rIf interested in more information about this less-known metric, check out A better measure of relative prediction accuracy for model selection and model estimation (Chris Tofallis, 2015)\nI hope this may have brought some light into this quirky behaviour of MAPE and sMAPE.\nI also wrote a more general discussion about forecasting error metrics you might want to take a look at.\n\r","date":1566777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566777600,"objectID":"f709f6855ba9d0dd218c3897668c93f4","permalink":"/post/symmetric-mape-is-not-symmetric/","publishdate":"2019-08-26T00:00:00Z","relpermalink":"/post/symmetric-mape-is-not-symmetric/","section":"post","summary":"Against all odds, it isn't","tags":[],"title":"Symmetric MAPE is not symmetric","type":"post"},{"authors":["Carlos Vecina"],"categories":["R"],"content":"\rIn 7 minutes reading, You will learn how to turn your ggplot visualizations into amazing interactive 3D plots you can export or embed in HTML/Rmarkdown. Or even better, you will export as mp4 an animation rotating the figure.\nAs a use case, we are going to join the Spanish demographic data and GIS map, and then visualize it\n\n1. Introduction\r\nDuring the last weeks a ‘new’ package has received the R community attention. We say ‘new’ because it joined recently the CRAN, althought the very first commits in github repo date back more than a year. Its name is rayshader and in the author’s own words:\n\n\r“rayshader uses elevation data in a base R matrix and a combination of raytracing, spherical texture mapping, overlays, and ambient occlusion to generate beautiful topographic 2D and 3D maps”\n\r\nIn my view, Tyler Morgan-Wall (package’s author) hit the jackpot with the new addition of two specific functions. These are plot_gg() and render_movie(). The first one converts the ggplot to a 3D figure using one or two lines of code making it deadly-simple. The second one renders an animation in which we can set up several parameters like zoom, fps, angles and inclinations… as user-friendly as possible.\n\n\nLet’s try these new functionalities! \rThe only condition you must have a color or fill aesthetic, unless you can also play in the same plot wiht size.\rMany times 3D plots are not the right choice for most of the data visualization cases. Therefore, I tried to bring to this article a non gratuitous example.\nAs a practical challenge, we will visualize in an interactive 3D map the average age in each city of Spain. Cool? First of all we need the population stats. We get it from the INE webpage. Secondly we have to delimiter Spanish cities with they GIS coordinates. Then we are merging these data to create a ggplot chart. Once we have the ggplot object we are going to use the rayshader package to map color aesthetic to the third spatial dimension. To conclude, we are going to render it as rotating 3D video.\nLet´s do it step by step.\n\n\r\r2. Visualazing Spanish cities average age.\rWe usually want to start our pratical work drawing the main steps in our project and our principal goals. So in a general layer, we want to visualiza the average age. Firstly in a ggplot-color way, go one step further and make the plot 3D and end with an animation where the Z axis will be the average age.\n\n2.1- Downloading census data\rAs said, for our purpose, we need to collect data from two sources. We use INE open data portal to download census ages data by city. After a not very user-friendly search, we got it. I provide you the following link, where you can find the continuous register statistics:\rlink.\nAiming to keep focused, we don’t get distracted and we are going to download the 2018 file. However, is worth noting the INEbase efforts to make easier the INE open data platform.\nWe start loading (or downloading) the packages we are going to use. In other article or tip we will provide a custom function to Load and Download Rpackages in onle line.\rMoreover we define the required functions and download directories.\nlibrary(pxR)\rlibrary(RColorBrewer)\rlibrary(rgeos)\r#install.packages(\u0026quot;rgdal\u0026quot;, repos = \u0026quot;http://cran.us.r-project.org\u0026quot;) reinstall cause gpclib dependencie https://stackoverflow.com/questions/30790036/error-istruegpclibpermitstatus-is-not-true\rlibrary(rgdal)\rlibrary(rayshader)\rlibrary(knitr)\rlibrary(magrittr)\rlibrary(tidyverse)\ras.numeric.factor \u0026lt;- function(x) { # Custom function to convert fctr to num factor value\rreturn(suppressWarnings(as.numeric(levels(x))[x]))\r}\rif(!dir.exists(\u0026quot;data\u0026quot;)) dir.create(\u0026quot;data\u0026quot;) # Create the download directory\r\nDownloading INE 2018 file:\nutils::download.file(url = \u0026quot;http://www.ine.es/pcaxisdl/t20/e245/p05/a2018/l0/00000006.px\u0026quot;,\rdestfile = \u0026quot;data/census_2018.px\u0026quot;)\r\ntbl_census_2018 \u0026lt;- read.px(\u0026quot;data/census_2018.px\u0026quot;) %\u0026gt;% # Load \u0026amp; format\ras_tibble()\rWe parse the data to obtain a name,pcode,average age dataframe\ntbl_census_2018 %\u0026lt;\u0026gt;% set_names(c(\u0026quot;age\u0026quot;, \u0026quot;city\u0026quot;, \u0026quot;sex\u0026quot;, \u0026quot;population\u0026quot;)) %\u0026gt;% # Cambiamos los nombre\rna.omit() %\u0026gt;% # Na rmv\rfilter((city!=\u0026quot;Total\u0026quot;)\u0026amp;(age!=\u0026quot;Total\u0026quot;)\u0026amp;(sex==\u0026quot;Ambos sexos\u0026quot;)) %\u0026gt;% # Duplicate info rmv\rseparate(city, c(\u0026#39;postal_code\u0026#39;, \u0026#39;city_name\u0026#39;), sep=\u0026quot;-\u0026quot;) %\u0026gt;% # Sep City column\rmutate(age = as.numeric.factor(age)) %\u0026gt;% # Conv to numeric\rgroup_by(city_name, postal_code) %\u0026gt;% # Group to operate\rsummarise(avg_age = sum(population*age,na.rm = T)/sum(population,na.rm=T)) %\u0026gt;% # Avg age\rselect(city_name, postal_code, avg_age) # Discard columns\rkable( # Just Rmarkdown format\rtbl_census_2018 %\u0026gt;% head(2)\r)\r\r\rcity_name\rpostal_code\ravg_age\r\r\r\rAbabuj\r44001\r52.40789\r\rAbades\r40001\r45.40000\r\r\r\r\n\r2.2- Downloading GIS data\rThe second source we are going to use is the Geo data. We will use cities coordinates and matching it with Spanish demographic data previously obtained.\nDownloading map overlay:\ntemp \u0026lt;- tempfile() # Create the tempfile\ru=\u0026quot;http://www.arcgis.com/sharing/rest/content/items/8e31c4c1a0b348f79058f212d0d807a1/data\u0026quot;\rutils::download.file(url = u, destfile = temp,\rmode=\u0026quot;wb\u0026quot;) # Binary mode for correct download\runzip(temp, exdir = \u0026quot;data/cities_gis\u0026quot;) # Unzip in data/cities_gis\runlink(temp) # Delete temp file\rWe parse the spatial information to convert it into tabular data. We expect that the Canary Islands coordinates will skew the plot, so it’s our decision to keep focused in our 3D objetive and filter peninsular coordinates. It’s also possible, and a better practice, to move insular coordinates looking for a compact plot, instead of filter them out.\nTo complete this data processing, we use fortify function that allows us to don’t load more packages. However, this function throws a warning suggesting the broom::tidy() one.\ntlb_cities_gis \u0026lt;- readOGR(dsn = \u0026quot;data/cities_gis/Municipios_ETRS89_30N.shp\u0026quot;,\rverbose=FALSE) # Spatial data reading\rtlb_cities_gis %\u0026lt;\u0026gt;% fortify(region = \u0026quot;Codigo\u0026quot;) # %\u0026gt;% # Conv \u0026quot;spatial object\u0026quot; to data.frame\r# broom::tidy()\rplot_canarias \u0026lt;- F # Control param, initial app config\rif(plot_canarias==F){ # Should be moduled in a funct\rtlb_cities_gis %\u0026lt;\u0026gt;%\rfilter((long\u0026gt;0) \u0026amp; (lat\u0026gt;4000000)) # Filter peninsular data\r} \rFinaly, we join both creating the final dataset, which we are going to use to make the plots. Note that we use left join to keep de geo data.\ntbl_cities_avg_age \u0026lt;- tlb_cities_gis %\u0026gt;% left_join(tbl_census_2018, by = c(\u0026quot;id\u0026quot; = \u0026quot;postal_code\u0026quot;)) \rAs a good practice, we are going to check the number of NAs generated after the left join. These NAs meaning is that there are cities localized but without average year information\nWe can see that these missing values represents just 1% of the data, so we are going to impute them with the previous postal code info. I bet that you can easily improve this procedure but I consider it’s prety acceptable enought seeing the low NA ratio.\nkable( # RMarkdown output format\rtbl_cities_avg_age %\u0026gt;%\rgroup_by(id) %\u0026gt;%\rsummarise(na = sum(is.na(avg_age))) %\u0026gt;% # NAs by city\rsummarise(missing_perc = sum(na\u0026gt;0)/length(na)*100) %\u0026gt;% # Perc cities with at least 1 na select(missing_perc)\r,\ralign = \u0026quot;c\u0026quot;\r)\r\r\rmissing_perc\r\r\r\r0.9268413\r\r\r\rtbl_cities_avg_age %\u0026lt;\u0026gt;% arrange(id) %\u0026gt;% fill(avg_age, .direction = \u0026quot;down\u0026quot;) # Fill with the previous pc data.\r\n\r2.3- GGplot visualization\rInspired in http://blog.manugarri.com/making-a-beautiful-map-of-spain-in-ggplot2/\nOnce we have created the final dataset, we are able to start ploting it. Of course longitude in X-axis and latitude en Y-axis. Firstly average city age is represented using a color palette. Red colours are assigned to older people and blue ones to younger city population. We get it in ggplot with the fill aesthetic.\nmyPalette \u0026lt;- colorRampPalette(rev(brewer.pal(11, \u0026quot;Spectral\u0026quot;))) # Create reverse Spectral palette\rplot_cities \u0026lt;- ggplot() +\rgeom_polygon(data = tbl_cities_avg_age, aes(fill = avg_age, x = long, y = lat, group = id)) + # Dummy variable to correct fill by PCode.\rscale_fill_gradientn(colours=myPalette(4)) + # Choose palette colours.\rlabs(fill=\u0026quot;Avg age\u0026quot;)\rplot(plot_cities)\r\n\r2.4- 3D Rayshader Visualization!\rThat was pretty nice. It’s sure that you can reach the general propose to be able to locate inmediately older an younger zones. Although as we will disccuss in a future post, human eyes aren’t ready to distinguiss almost nothing but big color contrasts. What about complement color with a third dimension through z axis?\nLet’s see how it works\nplot_gg(plot_cities,multicore=TRUE,width=5,height=3,scale=310) # Plot_gg de rayshader\rrender_snapshot()\r\nHmm you told something about render_movie()… What if we anime it?\n\n\r2.5- 3D animation with rayshader\rIn the last plot, it results the correct angle election as a key point. But what if we animate it with a rotating effect?\nThis is what the following function take cares on:\nrender_movie(\u0026quot;img/movie_spain.mp4\u0026quot;,frames = 720, fps=30,zoom=0.6,fov = 30)\r\rbody {\rtext-align: justify}\rp {\rword-spacing: 3px;\r}\r\r\r\r","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569354975,"objectID":"352959a7c37a1271d1bf9c389899ae4b","permalink":"/post/ggplot-to-3d-in-r-with-rayshader/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/post/ggplot-to-3d-in-r-with-rayshader/","section":"post","summary":"In 7 minutes reading, You will learn how to turn your ggplot visualizations into amazing interactive 3D plots you can export or embed in HTML/Rmarkdown. Or even better, you will export as mp4 an animation rotating the figure.\nAs a use case, we are going to join the Spanish demographic data and GIS map, and then visualize it\n\n1. Introduction\r\nDuring the last weeks a ‘new’ package has received the R community attention.","tags":["rayshader","ggplot","viz","vizR","visualization"],"title":"Turn your GGplot to 3D animation. Awesome 2D to 3D plots in R with Rayshader","type":"post"},{"authors":null,"categories":null,"content":"","date":1556323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556323200,"objectID":"d1b00d2ca072fe33596fd4b2a36b1113","permalink":"/project/real-state-datathon/","publishdate":"2019-04-27T00:00:00Z","relpermalink":"/project/real-state-datathon/","section":"project","summary":"Forecasting web page visitors. Hosted by CajaMar, Idealista \u0026 Mindsait.","tags":["Competitions"],"title":"Real State Modeling Datathon 2019","type":"project"},{"authors":null,"categories":null,"content":"","date":1541030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541030400,"objectID":"f0270c039edb7f315df04bcef0228c49","permalink":"/project/r-hispano-crm-excellency/","publishdate":"2018-11-01T00:00:00Z","relpermalink":"/project/r-hispano-crm-excellency/","section":"project","summary":"Text Mining use cases in CRM and a light use case with spanish banking apps.","tags":["Talks"],"title":"Talk - Text Mining for CRM excellency.","type":"project"},{"authors":null,"categories":null,"content":"Explore the most conflictive streets for bikers.\nLink: http://carlosvecina.es/spotbike\n","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"a7092a239df0e6126b05d833f01ad1fe","permalink":"/project/spotbike-shiny/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/project/spotbike-shiny/","section":"project","summary":"Explore the most conflictive streets for bikers.","tags":["Dashboards"],"title":"Bike accidents dashboard.","type":"project"},{"authors":null,"categories":null,"content":"Shiny Dashboard to explore the criptocurrency market, past prices, SMAs\u0026hellip;\nLink: http://carlosvecina.es/crypto-invest\n","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"aff093c9710c0e2d3dc6f31d9b36ac6d","permalink":"/project/cryptocurrency-shiny/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/project/cryptocurrency-shiny/","section":"project","summary":"Shiny Dashboard to explore the criptocurrency market, past prices, SMAs...","tags":["Dashboards"],"title":"Cryptocurrencies exploratory dashboard.","type":"project"}]