[{"authors":["carlos-vecina"],"categories":null,"content":"Carlos Vecina es un científico de datos con experienca en la aplicación del Machine Learning y de la Inteligencia Artificial con el objetivo de aportar gran valor a negocio en áreas como el CRM, el Marketing y en la compra-venta dentro del mercado eléctrico.\n","date":1700006400,"expirydate":-62135596800,"kind":"taxonomy","lang":"es","lastmod":1700006400,"objectID":"7f2ce30e6e7155580a08c73da392044a","permalink":"/es/authors/carlos-vecina/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/es/authors/carlos-vecina/","section":"authors","summary":"Carlos Vecina es un científico de datos con experienca en la aplicación del Machine Learning y de la Inteligencia Artificial con el objetivo de aportar gran valor a negocio en áreas como el CRM, el Marketing y en la compra-venta dentro del mercado eléctrico.","tags":null,"title":"Carlos Vecina","type":"authors"},{"authors":["pablo-canovas"],"categories":null,"content":"Pablo Cánovas es un científico de datos con experiencia desarrollando y productivizando modelos de Machine Learning aplicados al mercado energético europeo.\n","date":1593302400,"expirydate":-62135596800,"kind":"taxonomy","lang":"es","lastmod":1593302400,"objectID":"78b4973aee7e471f2427600fe9f47d84","permalink":"/es/authors/pablo-canovas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/es/authors/pablo-canovas/","section":"authors","summary":"Pablo Cánovas es un científico de datos con experiencia desarrollando y productivizando modelos de Machine Learning aplicados al mercado energético europeo.","tags":null,"title":"Pablo Cánovas","type":"authors"},{"authors":["Carlos Vecina"],"categories":["Python","Post","Serie Pandas"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #204a87; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #8f5902; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #204a87; font-weight: bold; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r¿Eres un entusiasta de la ciencia de datos o un profesional que busca agilizar tu flujo de trabajo? Bueno, has llegado al lugar perfecto. En el universo de Python, la biblioteca Pandas es tu aliada clave para conquistar los desafíos del manejo de datos. Imagínate tener en tus manos una caja de herramientas súper potente que transforma la manera en que juegas con los datos. Eso es exactamente lo que Pandas te ofrece.\nAhora, hablemos de una habilidad esencial en tu arsenal de ciencia de datos: eliminar columnas en un DataFrame con Pandas. ¿Por qué es tan crucial? Porque en el mundo real, los datos no siempre llegan en el formato perfecto. A veces, menos es más y necesitas depurar tu DataFrame para obtener esa visión clara que te conducirá a insights impresionantes.\nEste artículo no es solo un tutorial, es tu guía definitiva sobre cómo eliminar columnas en Pandas y en Polars, cubriendo varios métodos y ofreciendo ejemplos de código para cada uno.. Prepárate para potenciar tus habilidades. ¡Vamos allá!\n\nEliminación de columnas en Pandas\rEmpecemos creando un dataframe inicial al que iremos haciendo diferentes ‘perrerías’.\nimport pandas as pd\r\r\rbase_df = pd.DataFrame({\r \u0026#39;id\u0026#39;: [1, 2, 3],\r \u0026#39;nombre\u0026#39;: [\u0026#39;Ana\u0026#39;, \u0026#39;Carlos\u0026#39;, \u0026#39;Mike\u0026#39;],\r \u0026#39;provincia\u0026#39;: [\u0026#39;Alicante\u0026#39;, \u0026#39;Alicante\u0026#39;, \u0026#39;Denver\u0026#39;],\r \u0026#39;departamento\u0026#39;: [3, 3, 3],\r \u0026#39;equipo\u0026#39;: [17, 17, 25],\r\r})\rbase_df\r## id nombre provincia departamento equipo\r## 0 1 Ana Alicante 3 17\r## 1 2 Carlos Alicante 3 17\r## 2 3 Mike Denver 3 25\r\n1- Método .drop()\rComo hemos comentado, drop puede usarse tanto para filas como para columnas, así que utilizaremos el argumento axis=1 para indicar que nos referimos a las columnas. Para hacer referencia a las filas, usaríamos axis=0.\nPor último, como muchos otros métodos de los Pandas DataFrames, debemos decidir si queremos hacerlo inplaceo no. Esto tendrá efectos en la apariencia de nuestro código y en el rendimiento del programa.\rSin embargo, dropes uno de los métodos en los que se desaconseja el uso, ya que no presenta mejoras de rendimiento y sólo limita el encadenamiento de funciones (ya que lo hacemos inplace lo que nos devuelve es un None). Más información en este post y en la PDEP-8 donde podéis seguir la conversación sobre el tema, abierta a fecha de publicación 16/11.\rEn caso de no usar inplace, deberemos reasignar el resultado del drop.\n# Eliminar una columna\rbase_df.drop(\u0026#39;provincia\u0026#39;, axis=1) #, inplace=True) en caso de que no queramos, por defecto a false\r\r# Eliminar múltiples columnas\r## id nombre departamento equipo\r## 0 1 Ana 3 17\r## 1 2 Carlos 3 17\r## 2 3 Mike 3 25\rbase_df.drop([\u0026#39;id\u0026#39;, \u0026#39;departamento\u0026#39;], axis=1) # inplace=True)\r## nombre provincia equipo\r## 0 Ana Alicante 17\r## 1 Carlos Alicante 17\r## 2 Mike Denver 25\r\n\r2- Selección de columnas mediante corchetes [] y métodos .loc e .iloc\rbase_df[[\u0026#39;nombre\u0026#39;, \u0026#39;provincia\u0026#39;]]\r## nombre provincia\r## 0 Ana Alicante\r## 1 Carlos Alicante\r## 2 Mike Denver\rTambién podemos usar loc / iloc para la selección de columnas. Esta opción suele ser muy poco más lenta que la anterior si sólo quieres eliminar columnas, mientras ofrece mucha más flexibilidad.\nbase_df.loc[:, [\u0026#39;nombre\u0026#39;, \u0026#39;provincia\u0026#39;]]\r## nombre provincia\r## 0 Ana Alicante\r## 1 Carlos Alicante\r## 2 Mike Denver\rbase_df.loc[:, [\u0026#39;nombre\u0026#39;, \u0026#39;provincia\u0026#39;]]\r## nombre provincia\r## 0 Ana Alicante\r## 1 Carlos Alicante\r## 2 Mike Denver\rLo bueno del método nativo de Pandas, es que nos ofrece una manera flexible de selección de columnas y filas por los filtros y condiciones que nosotros queramos fácilmente.\n\n\r3- Uso de del\rLimitaciones: Es menos flexible que drop(), ya que solo puede eliminar una columna a la vez y no devuelve una copia del DataFrame, lo que puede ser un inconveniente en ciertos flujos de trabajo. el funcionamiento es como el inplace del método drop.\ncopia_df = base_df.copy()\rdel copia_df[\u0026#39;departamento\u0026#39;]\rdel copia_df[\u0026#39;provincia\u0026#39;]\rcopia_df\r## id nombre equipo\r## 0 1 Ana 17\r## 1 2 Carlos 17\r## 2 3 Mike 25\rImportante: usamos el método copy() a la hora de hacer una copia del dataframe. En caso de no hacerlo, lo que hacemos es hacer una copia por referencia por lo que las modificaciones que le hagamos al objeto nuevo, serán también aplicados al dataframe original. Veamos el ejemplo:\ncopia_de_copia_df = copia_df\rdel copia_de_copia_df[\u0026#39;equipo\u0026#39;]\rcopia_df\r## id nombre\r## 0 1 Ana\r## 1 2 Carlos\r## 2 3 Mike\r\n\r\rEliminar columnas en Polars\rUsemos el DataFrame de Pandas y transformémoslo a Polars:\nimport polars as pl # usando version 0.19.3\r\rbase_df_pl = pl.from_pandas(base_df)\rDel mismo modo que lo hacíamos en Pandas, Polars implementa n método para sus dataframes con el mismo nombre drop.\nbase_df_pl.drop([\u0026quot;id\u0026quot;,\u0026quot;equipo\u0026quot;])\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\rwhite-space: pre-wrap;\r}\r\rshape: (3, 3)nombreprovinciadepartamentostrstri64\u0026quot;Ana\u0026quot;\u0026quot;Alicante\u0026quot;3\u0026quot;Carlos\u0026quot;\u0026quot;Alicante\u0026quot;3\u0026quot;Mike\u0026quot;\u0026quot;Denver\u0026quot;3\rTambién se podemos indicar el nombre de las columnas separadas por coma sin usar una lista.\nOtra que manera que tenemos disponible es usar los Polars selectors junto con drop, pudiendo eliminar columnas de manera más interesante. Podemos eliminar columnas de un dataframe según su tipo.\nimport polars.selectors as cs\r\rbase_df_pl.dtypes\r## [Int64, Utf8, Utf8, Int64, Int64]\rbase_df_pl.drop(cs.numeric())\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\rwhite-space: pre-wrap;\r}\r\rshape: (3, 2)nombreprovinciastrstr\u0026quot;Ana\u0026quot;\u0026quot;Alicante\u0026quot;\u0026quot;Carlos\u0026quot;\u0026quot;Alicante\u0026quot;\u0026quot;Mike\u0026quot;\u0026quot;Denver\u0026quot;\rDeberemos, como anteriormente, reasignar el resultado o bien a la misma variable, o bien a una nueva según convenga.\nPor último, para eliminar columnas en base a su contenido (más allá del tipo), no tenemos una manera ‘pytonica’ de hacerlo con la API de Polars y que encaje por ejemplo en un pipeline Lazy. Deberemos materializar los datos y obtener los nombres de las columnas que cumplan nuestras condiciones deseadas, y ahora sí se podría incluir dentro de un drop.\n# Seleccionamos las columas de texto donde el número de elementos únicos sea mayor a 2\rcol_name_diff = [col.name for col in base_df_pl.select(cs.string().n_unique() \u0026gt; 2) if col.all()]\rbase_df_pl.select(col_name_diff)\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\rwhite-space: pre-wrap;\r}\r\rshape: (3, 1)nombrestr\u0026quot;Ana\u0026quot;\u0026quot;Carlos\u0026quot;\u0026quot;Mike\u0026quot;\r\nMantente al día de las novedades de Pandas y Polars\rEspero que esta publicación te haya ayudado a familiarizarte con la selección y eliminación de columnas en dataframes de Pandas y Polars, y te haya permitido disfrutar de una exhibición de algunas de sus características.\nSi deseas mantenerte actualizado y no perderte nada…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido de Python Polars!\r\r\r\r\r\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1700006400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1700006400,"objectID":"bfa44610c7edc9e8693040009099f914","permalink":"/es/post/eliminar-columnas-dataframe-python/","publishdate":"2023-11-15T00:00:00Z","relpermalink":"/es/post/eliminar-columnas-dataframe-python/","section":"post","summary":"Veamos las diferentes y mejores maneras de eliminar columnas en un DataFrame usando las dos principales librerías de Python, Pandas y la nueva librería de alto rendimiento llamada Polars.","tags":["Python","Pandas","Polars"],"title":"Eliminar columnas de una DataFrame de Python Pandas... ¡y en Polars!","type":"post"},{"authors":["Carlos Vecina"],"categories":["Python","Post"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ff0000; font-weight: bold; } /* Alert */\rcode span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #7d9029; } /* Attribute */\rcode span.bn { color: #40a070; } /* BaseN */\rcode span.bu { color: #008000; } /* BuiltIn */\rcode span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4070a0; } /* Char */\rcode span.cn { color: #880000; } /* Constant */\rcode span.co { color: #60a0b0; font-style: italic; } /* Comment */\rcode span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #ba2121; font-style: italic; } /* Documentation */\rcode span.dt { color: #902000; } /* DataType */\rcode span.dv { color: #40a070; } /* DecVal */\rcode span.er { color: #ff0000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #40a070; } /* Float */\rcode span.fu { color: #06287e; } /* Function */\rcode span.im { color: #008000; font-weight: bold; } /* Import */\rcode span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #007020; font-weight: bold; } /* Keyword */\rcode span.op { color: #666666; } /* Operator */\rcode span.ot { color: #007020; } /* Other */\rcode span.pp { color: #bc7a00; } /* Preprocessor */\rcode span.sc { color: #4070a0; } /* SpecialChar */\rcode span.ss { color: #bb6688; } /* SpecialString */\rcode span.st { color: #4070a0; } /* String */\rcode span.va { color: #19177c; } /* Variable */\rcode span.vs { color: #4070a0; } /* VerbatimString */\rcode span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\r\rCómo renombrar columnas en un DataFrame en Python: Una Guía práctica\rEn el mundo del análisis de datos con Python, los DataFrames son una herramienta fundamental. Sin embargo, es común encontrarse con la necesidad de renombrar columnas para mejorar la legibilidad o para cumplir con ciertas convenciones de nombrado. Aquí te explicamos cómo puedes renombrar columnas de un DataFrame en Python utilizando la biblioteca Pandas, esencial para la manipulación de datos.\n\n¿Por qué renombrar columnas? Renombrar columnas en Pandas con rename\rRenombrar columnas en un DataFrame puede ser necesario por varios motivos:\n\rClaridad: Los nombres de las columnas pueden ser confusos o demasiado técnicos.\rConsistencia: En proyectos con múltiples DataFrames, es útil tener nombres de columnas consistentes.\rNecesidades de Análisis: Algunas funciones o métodos pueden requerir nombres de columna específicos.\r\rComo ya sabemos, Pandas (échale un ojo a su última versión) es una biblioteca de Python que proporciona estructuras de datos y herramientas de análisis de datos. Uno de sus objetos más poderosos es el DataFrame, que puedes modificar fácilmente, incluyendo la acción de renombrar columnas.\nSi aún no tienes instalado Pandas, puedes hacerlo usando pip, poetry o el gestor de dependencias / entornos que suelas utilizar en tus proyectos\nAhora, veamos un ejemplo de cómo renombrar columnas en un DataFrame en Python:\nimport pandas as pd\r\r# Crear un DataFrame de ejemplo\rdf = pd.DataFrame({\r \u0026#39;A\u0026#39;: [1, 2, 3],\r \u0026#39;B\u0026#39;: [4, 5, 6],\r \u0026#39;C\u0026#39;: [7, 8, 9]\r})\r\r# Imprimir el DataFrame original\rprint(\u0026quot;DataFrame Original:\\n\u0026quot;, df)\r\r# Renombrar columnas utilizando un diccionario\r## DataFrame Original:\r## A B C\r## 0 1 4 7\r## 1 2 5 8\r## 2 3 6 9\rdf.rename(columns={\u0026#39;A\u0026#39;: \u0026#39;Primera\u0026#39;, \u0026#39;B\u0026#39;: \u0026#39;Segunda\u0026#39;, \u0026#39;C\u0026#39;: \u0026#39;Tercera\u0026#39;}, inplace=True)\r\r# Imprimir el DataFrame después de renombrar columnas\rprint(\u0026quot;\\nDataFrame con Columnas Renombradas:\\n\u0026quot;, df)\r## ## DataFrame con Columnas Renombradas:\r## Primera Segunda Tercera\r## 0 1 4 7\r## 1 2 5 8\r## 2 3 6 9\rPara trabajar con DataFrames en Python, es esencial comenzar importando la biblioteca Pandas, lo cual hacemos utilizando el alias ‘pd’. Una vez importada Pandas, creamos un DataFrame simple, compuesto por tres columnas denominadas ‘A’, ‘B’ y ‘C’, las cuales se llenan con datos de ejemplo. El siguiente paso es renombrar estas columnas, para lo cual utilizamos el método .rename() del DataFrame. Este método requiere pasar un diccionario que asocie los nombres actuales de las columnas (las claves) con los nuevos nombres deseados (los valores).\nAl especificar el argumento inplace=True, aseguramos que los cambios se apliquen directamente en el DataFrame original. Finalmente, para confirmar que los cambios se han realizado correctamente, imprimimos el DataFrame modificado, mostrando así las columnas con sus nuevos nombres.\n\n\rRenombrar columnas en Polars\rPor supuesto, además de Pandas, existen otras bibliotecas de Python que manejan DataFrames de manera eficiente. Una de ellas es Polars, que se está abriendo paso en el ecosistema de Python. Es conocida por su rapidez y rendimiento al manejar grandes conjuntos de datos. Al igual que en Pandas, renombrar columnas en un DataFrame en Python usando Polars es una tarea sencilla pero fundamental para mantener los datos organizados.\nimport polars as pl\r\r# Crear un DataFrame de ejemplo en Polars\rdf_polars = pl.DataFrame({\r \u0026#39;A\u0026#39;: [1, 2, 3],\r \u0026#39;B\u0026#39;: [4, 5, 6],\r \u0026#39;C\u0026#39;: [7, 8, 9]\r})\rprint(\u0026quot;DataFrame Original de Polars:\\n\u0026quot;, df_polars)\r\r\r# Renombrar columnas en Polars\r## DataFrame Original de Polars:\r## shape: (3, 3)\r## ┌─────┬─────┬─────┐\r## │ A ┆ B ┆ C │\r## │ --- ┆ --- ┆ --- │\r## │ i64 ┆ i64 ┆ i64 │\r## ╞═════╪═════╪═════╡\r## │ 1 ┆ 4 ┆ 7 │\r## │ 2 ┆ 5 ┆ 8 │\r## │ 3 ┆ 6 ┆ 9 │\r## └─────┴─────┴─────┘\rdf_polars = df_polars.rename({\u0026quot;A\u0026quot;: \u0026quot;Primera\u0026quot;, \u0026quot;B\u0026quot;: \u0026quot;Segunda\u0026quot;, \u0026quot;C\u0026quot;: \u0026quot;Tercera\u0026quot;})\r\r# Imprimir el DataFrame después de renombrar columnas\rprint(\u0026quot;\\nDataFrame de Polars con Columnas Renombradas:\\n\u0026quot;, df_polars)\r## ## DataFrame de Polars con Columnas Renombradas:\r## shape: (3, 3)\r## ┌─────────┬─────────┬─────────┐\r## │ Primera ┆ Segunda ┆ Tercera │\r## │ --- ┆ --- ┆ --- │\r## │ i64 ┆ i64 ┆ i64 │\r## ╞═════════╪═════════╪═════════╡\r## │ 1 ┆ 4 ┆ 7 │\r## │ 2 ┆ 5 ┆ 8 │\r## │ 3 ┆ 6 ┆ 9 │\r## └─────────┴─────────┴─────────┘\rEn este ejemplo, creamos un DataFrame de Polars con datos de muestra y lo imprimimos. Posteriormente, usamos el método .rename() para cambiar los nombres de las columnas. A diferencia de Pandas, no necesitas especificar inplace=True, ya que en Polars la asignación se realiza de manera directa al objeto.\nPara seguir leyendo más características de Polars, te dejamos este post sobre cómo aplicar funciones de manera encadenada a un DataFrame de Polars\n\n\rBuenas prácticas al renombrar columnas\rAl renombrar columnas de un DataFrame en Python, es importante seguir ciertas buenas prácticas:\nSimplicidad: Escoge nombres de columna simples y descriptivos.\nConsistencia: Usa un estilo consistente, como snake_case (ej. ranking_score) o camelCase (rankingScore). Puedes usar linters y formateadores que te ayuden a mantener la consistencia en tus projectos y repositorios de código.\nUnicidad: Asegúrate de que cada nombre de columna sea único dentro del DataFrame.\n\n\rMantente actualizado en consejos de Python principiante e intermedio\rRenombrar columnas en un DataFrame en Python es una tarea común y sencilla, pero esencial para mantener tus datos organizados y fáciles de entender. Tanto con Pandas y Polars, puedes hacerlo en una línea de código, lo cual simplifica enormemente el proceso de limpieza y preparación de datos antes de proceder al análisis.\nEsperamos que este tutorial te haya ayudado a entender cómo renombrar columnas en un DataFrame en Python y te motive a seguir explorando las poderosas capacidades de las librerías expuestas. ¡Feliz análisis de datos!\nSi deseas mantenerte actualizado…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Síguenos para más contenido sobre Python! \r\r\r\r\r\r\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1699488000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1699488000,"objectID":"1043f9068581665fa53b3f3f758d8a75","permalink":"/es/post/renombrar-columna-python-pandas-polars/","publishdate":"2023-11-09T00:00:00Z","relpermalink":"/es/post/renombrar-columna-python-pandas-polars/","section":"post","summary":"Descubre cómo dominar los diccionarios en Python con nuestra guía exhaustiva. Aprende a crear, manejar y optimizar diccionarios para tus proyectos de programación.","tags":["Python","Principiantes"],"title":"Cómo renombrar columnas en un DataFrame en Python usando Pandas y Polars","type":"post"},{"authors":["Carlos Vecina"],"categories":["Python","Post"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ff0000; font-weight: bold; } /* Alert */\rcode span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #7d9029; } /* Attribute */\rcode span.bn { color: #40a070; } /* BaseN */\rcode span.bu { color: #008000; } /* BuiltIn */\rcode span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4070a0; } /* Char */\rcode span.cn { color: #880000; } /* Constant */\rcode span.co { color: #60a0b0; font-style: italic; } /* Comment */\rcode span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #ba2121; font-style: italic; } /* Documentation */\rcode span.dt { color: #902000; } /* DataType */\rcode span.dv { color: #40a070; } /* DecVal */\rcode span.er { color: #ff0000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #40a070; } /* Float */\rcode span.fu { color: #06287e; } /* Function */\rcode span.im { color: #008000; font-weight: bold; } /* Import */\rcode span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #007020; font-weight: bold; } /* Keyword */\rcode span.op { color: #666666; } /* Operator */\rcode span.ot { color: #007020; } /* Other */\rcode span.pp { color: #bc7a00; } /* Preprocessor */\rcode span.sc { color: #4070a0; } /* SpecialChar */\rcode span.ss { color: #bb6688; } /* SpecialString */\rcode span.st { color: #4070a0; } /* String */\rcode span.va { color: #19177c; } /* Variable */\rcode span.vs { color: #4070a0; } /* VerbatimString */\rcode span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\r\rDiccionarios en Python. Añade elementos, recorre el diccionario y mucho más.\rBienvenidos al mundo de Python, donde las estructuras de datos como los diccionarios pueden transformar tu forma de manejar la información. Un diccionario en Python es una herramienta versátil, capaz de mapear claves únicas a valores. Aprender a añadir elementos y manipular estos diccionarios es esencial para cualquier desarrollador o analista de datos.\n¿Qué es un Diccionario en Python?\rPython ofrece diversas estructuras de datos, siendo el diccionario una de las más potentes. Un diccionario en Python es una colección desordenada de elementos, cada uno con una clave y un valor. Es ideal para almacenar y recuperar datos con una etiqueta, similar a cómo funciona un diccionario real.\nComo la mayoría de las estructuras de datos de Python, los diccionarios tienen métodos inherentes y a nuestra disposición. Un ejemplo de ellos son: .keys(), .values(), .update() y .items()\nEstos métodos proporcionan un conjunto poderoso de herramientas para manejar los diccionarios en Python, permitiendo a los desarrolladores principiantes manipular eficientemente esta estructura de datos clave-valor. Cada método tiene un propósito específico y entender cuándo y cómo usar cada uno es fundamental para la programación eficiente en Python.\nCreando tu Primer Diccionario:\rPara comenzar, definamos un diccionario en Python. Es una tarea sencilla y directa. Utilizamos las llaves {} con una estructura interna de {\"clave\": \"valor\"}.\nmi_diccionario = {\r \u0026#39;nombre\u0026#39;: \u0026#39;Marta\u0026#39;, \r \u0026#39;edad\u0026#39;: 45, \r \u0026#39;ciudad\u0026#39;: \u0026#39;Buenos Aires\u0026#39;\r}\rprint(mi_diccionario)\r## {\u0026#39;nombre\u0026#39;: \u0026#39;Marta\u0026#39;, \u0026#39;edad\u0026#39;: 45, \u0026#39;ciudad\u0026#39;: \u0026#39;Buenos Aires\u0026#39;}\rLos elementos previos a : son las claves. Estas son únicas y, como hemos dicho, desordenadas (significando que no es posible acceder por índice ni hacer ninguna operación con ellos en las que se espere un orden determinado para las claves).\rLos segundos elementos son los valores. Es importante colocar una coma detrás de cada clave-valor.\nPuesto que no hay muchas limitaciones respecto al tipo de objetos que pueden ser incluidos en los valores de un diccionario, por supuesto es posible tener diccionarios anidados. Sería:\nmi_diccionario = {\r \u0026#39;nombre\u0026#39;: \u0026#39;Marta\u0026#39;, \r \u0026#39;edad\u0026#39;: 45, \r \u0026#39;ciudad\u0026#39;: \u0026#39;Buenos Aires\u0026#39;,\r \u0026#39;direccion\u0026#39;: {\u0026#39;calle\u0026#39;: \u0026#39;XXX\u0026#39;, \u0026#39;codigo_postal\u0026#39;: \u0026#39;030303\u0026#39;}\r}\rprint(mi_diccionario)\r## {\u0026#39;nombre\u0026#39;: \u0026#39;Marta\u0026#39;, \u0026#39;edad\u0026#39;: 45, \u0026#39;ciudad\u0026#39;: \u0026#39;Buenos Aires\u0026#39;, \u0026#39;direccion\u0026#39;: {\u0026#39;calle\u0026#39;: \u0026#39;XXX\u0026#39;, \u0026#39;codigo_postal\u0026#39;: \u0026#39;030303\u0026#39;}}\r\n\r\rCómo Añadir Elementos a un Diccionario\rAñadir elementos a un diccionario es una tarea común. Veamos cómo se hace de manera eficiente.\nPara añadir un elemento individual podemos hacerlo de la siguiente forma:\nmi_diccionario[\u0026#39;profesión\u0026#39;] = \u0026#39;Desarrolladora\u0026#39;\rPara hacer lo propio con múltiples elementos, podemos hacer uso del método anteriormente comnetado: update().\nmi_diccionario.update({\u0026#39;empresa\u0026#39;: \u0026#39;GG\u0026#39;, \u0026#39;hobby\u0026#39;: \u0026#39;Ajedrez\u0026#39;})\rComo vemos, usamos el método update de nuestro diccionario inicial para añadirle un segundo diccionario que creamos con las llaves {}.\nPor supuesto, un diccionario previamente asignado a una variable funcionará, pero cualquier otro tipo de objeto no va a funcionar.\n# No es aceptado sin ser tipo diccionario {}\r#mi_diccionario.update(\u0026quot;no\u0026quot;:\u0026quot;funciona\u0026quot;) \r\rsi_funciona_dict = {\u0026quot;si\u0026quot;: \u0026quot;funciona\u0026quot;}\rmi_diccionario.update(si_funciona_dict)\rEsto funciona porque el type(si_funciona_dict) es diccionario, y como comentábamos es necesario otro diccionario como tipo para ser añadido.\nPara terminar este apartado de añadido de elementos a un diccionario, veamos que tal y como introdujimos, las restricciones en cuanto a qué tipo de valores / objetos podemos añadir a un diccionario son muy pocas.\nPor ello, podemos añadir otros diccionarios, listas o incluso objetos creados por nosostros como valor en los diccionarios de Python.\nmi_diccionario[\u0026#39;lenguajes\u0026#39;] = [\u0026#39;Python\u0026#39;, \u0026#39;Rust\u0026#39;]\rmi_diccionario[\u0026#39;educación\u0026#39;] = {\u0026#39;grado\u0026#39;: \u0026#39;B.Sc.\u0026#39;, \u0026#39;especialización\u0026#39;: \u0026#39;Informática\u0026#39;}\r\n\rSelección y elliminación de elementos\rEn Python, puedes seleccionar y eliminar elementos de un diccionario de varias maneras. Aquí están las más comunes, junto con ejemplos para cada una:\nSelección de Elementos en un Diccionario:\nAcceso Directo por Clave:\rUsas la clave directamente para obtener el valor.\nd = {\u0026#39;nombre\u0026#39;: \u0026#39;Alicia\u0026#39;, \u0026#39;edad\u0026#39;: 25, \u0026#39;nota\u0026#39;: 8.4}\rnombre = d[\u0026#39;nombre\u0026#39;] # \u0026#39;Alice\u0026#39;\rEsto lanzará un KeyError si la clave no existe.\nMétodo .get():\nObtiene el valor asociado con la clave. Al contrario de la anterior manera, de este modo nos devuelve un valor predeterminado si la clave no existe, sin lanzar un error que pare la ejecución.\nPara muchos usos esta es la mejor manera de proceder.\nedad = d.get(\u0026#39;edad\u0026#39;, \u0026#39;No especificado\u0026#39;) # 25\rprofesion = d.get(\u0026#39;profesion\u0026#39;, \u0026#39;No especificado\u0026#39;) # \u0026#39;No especificado\u0026#39;\rprofesion = d.get(\u0026#39;profesion\u0026#39;, None) # Nulo, pero sin fallar\rUso de .items() para Selección:\rIterar sobre pares clave-valor para seleccionar datos.\nfor clave, valor in d.items():\r print(f\u0026quot;{clave}: {valor}\u0026quot;)\r## nombre: Alicia\r## edad: 25\r## nota: 8.4\rEliminación de Elementos en un Diccionario:\nMétodo .pop():\rElimina la clave y devuelve el valor. Si la clave no se encuentra, se devuelve un valor por defecto si se ha especificado, de lo contrario se lanzará un KeyError.\nedad = d.pop(\u0026#39;edad\u0026#39;, \u0026#39;Clave no encontrada\u0026#39;) # Elimina \u0026#39;edad\u0026#39; y devuelve 25\rMétodo .popitem():\rElimina y devuelve un par clave-valor. En las versiones de Python 3.7 en adelante, este método elimina el último par agregado.\nitem = d.popitem() # Devuelve y elimina el último par agregado (\u0026#39;nombre\u0026#39;: \u0026#39;Alice\u0026#39;)\rOperador del:\rElimina la clave y su valor asociado. Si la clave no existe, se lanzará un KeyError.\ndel d[\u0026#39;nombre\u0026#39;] # Elimina la clave \u0026#39;nombre\u0026#39; y su valor asociado\rComprensión de Diccionarios para Filtrar:\rCrea un nuevo diccionario con elementos seleccionados, efectivamente eliminando los que no quieres. Esta manera de crear diccionarios la vamos a comentar en detalle en el siguiente párrafo.\nd = {k: v for k, v in d.items() if v is not None} # Elimina elementos con valores None\rMétodo .clear():\rElimina todos los elementos del diccionario, dejándolo vacío.\nd.clear() # Elimina todos los elementos\rEstas operaciones te permiten tener un control detallado sobre la selección y eliminación de elementos en los diccionarios de Python, lo que es esencial para la gestión eficiente de datos y estructuras de datos en tus programas.\n\n\rIteración, diccionarios y ‘dict comprehension’ o compresión de diccionario\rLa iteración sobre diccionarios es un aspecto fundamental de su uso. Aquí te mostramos cómo iterar sobre las claves y valores.\nfor clave, valor in mi_diccionario.items():\r print(f\u0026quot;{clave}: {valor}\u0026quot;)\r## nombre: Marta\r## edad: 45\r## ciudad: Buenos Aires\r## direccion: {\u0026#39;calle\u0026#39;: \u0026#39;XXX\u0026#39;, \u0026#39;codigo_postal\u0026#39;: \u0026#39;030303\u0026#39;}\r## profesión: Desarrolladora\r## empresa: GG\r## hobby: Ajedrez\r## si: funciona\r## lenguajes: [\u0026#39;Python\u0026#39;, \u0026#39;Rust\u0026#39;]\r## educación: {\u0026#39;grado\u0026#39;: \u0026#39;B.Sc.\u0026#39;, \u0026#39;especialización\u0026#39;: \u0026#39;Informática\u0026#39;}\rRespecto a la creación de diccionarios por compresión, igual que las listas, consiste en la creación del diccionario de la siguiente manera:\ncomprension_dict = {f\u0026#39;clave_{i}\u0026#39;: i for i in range(3)}\r\r# Es lo mismo que hacer\r\rbucle_dict = {}\rfor i in range(3):\r bucle_dict.update({f\u0026#39;clave_{i}\u0026#39;: i})\r \rcomprension_dict == bucle_dict\r## True\rHay alguna otra cosa aquí. Aparte de la comprensión, que como vemos consiste convertir en diccionario el iterable que hay en su interior, también tenemos un f-string. Los f-string es la manera que tenemos en las nuevas versiones de Python para añadir el valor de una expresión o variable dentro de strings. A la string se le añade una f'' o `f”“.\n\n\rTodos los métodos de los diccionarios\rPor aquí te dejamos la explicación de todos los métodos de los diccionarios disponibles. Los paréntesis vacíos es porque el método no espera argumentos. En aquellos métodos que sí se esperan argumentos, añadimos entre paréntesis el tipo de los argumentos.\n\rdict.clear(): Vacía todos los elementos del diccionario, dejándolo como un diccionario vacío.\n\rdict.copy(): Retorna una copia superficial del diccionario. Útil cuando necesitas trabajar con una copia y no modificar el original.\n\rdict.fromkeys(seq[, v]): Crea un nuevo diccionario con claves a partir de seq y valores todos establecidos a v. Si v no se proporciona, el valor por defecto será None.\n\rdict.get(key[, d]): Devuelve el valor para key si key está en el diccionario; de lo contrario, devuelve d, que por defecto es None. Es una forma segura de acceder a los valores sin el riesgo de una excepción.\n\rdict.items(): Devuelve una vista de los pares clave-valor del diccionario, lo que es útil para iterar sobre ellos.\n\rdict.keys(): Devuelve una vista de las claves en el diccionario. Útil cuando solo necesitas trabajar con las claves.\n\rdict.pop(key[, d]): Elimina la clave especificada y devuelve el valor correspondiente. Si la clave no se encuentra, y se proporciona el argumento d, se devuelve d; si d no se proporciona, se lanza una excepción.\n\rdict.popitem(): Elimina y devuelve un par (clave, valor) del diccionario. Los pares se devuelven en un orden LIFO (last-in, first-out). Es útil para desestructurar diccionarios.\n\rdict.setdefault(key[, d]): Devuelve el valor de la clave si está en el diccionario. Si no está, inserta la clave con un valor de d y lo devuelve (d es por defecto None).\n\rdict.update([other]): Actualiza el diccionario con los pares clave-valor de other, sobrescribiendo las claves existentes. other puede ser otro diccionario o cualquier iterable de pares clave-valor.\n\rdict.values(): Devuelve una vista de todos los valores en el diccionario. Es útil cuando los valores son lo que te interesa.\n\r\rDominar cómo añadir elementos y trabajar con diccionarios en Python es un paso crucial en tu viaje como programador. Estas operaciones son la base de la manipulación de datos y te abrirán las puertas a técnicas más avanzadas de programación y análisis de datos.\n\n\rMantente actualizado en consejos de Python principiante e intermedio\rAhora que conoces cómo trabajar con diccionarios en Python y cómo añadir elementos, te animamos a experimentar por tu cuenta. Crea tus propios diccionarios, juega con ellos y ve cómo puedes optimizar tus códigos y análisis.\nSi deseas mantenerte actualizado…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Síguenos para más contenido sobre Python! \r\r\r\r\r\r\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1699401600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1699401600,"objectID":"31396135d55ee801255297bfe3c2ff27","permalink":"/es/post/diccionario-en-python/","publishdate":"2023-11-08T00:00:00Z","relpermalink":"/es/post/diccionario-en-python/","section":"post","summary":"Dominando Pydantic, Enums e IntEnums para aplicaciones Python robustas. Fusiona el poder de las validaciones de datos de Pydantic y el concepto de Enum, IntEnum y StrEnum.","tags":["Python","Pydantic"],"title":"Diccionarios en Python. Domina los básicos: Crear, añadir y eliminar elementos.","type":"post"},{"authors":["Carlos Vecina"],"categories":["Python","Tips"],"content":"\r\r\rLas listas en Python. Entendiendo sus características y cómo añadir y eliminar elementos de ellas\r\rAñadir elementos a una lista de Python\r\rappend():\rextend() y operador +: Alternativas para la concatenación.\rinsert(): Añade elemento en una posición determinado de la lista\r\rEliminar elementos de la lista\r\rremove(): Por elemento\rpop(): Elimina elemento de una lista basado en su índice.\rclear(): Vacia por completo la list\rPython sets (conjuntos) y HashLists como listas sin elementos duplicados\r\rMantente al día de Python en Typethepipe\r\r\r\rLas listas en Python. Entendiendo sus características y cómo añadir y eliminar elementos de ellas\rEn Python, las listas son una estructura de datos versátil y ampliamente utilizada que permite almacenar una colección ordenada de elementos, que pueden ser de diferentes tipos. Las principales características de las listas incluyen:\n\rsu capacidad para contener elementos heterogéneos,\rsu indexación basada en cero,\rla capacidad de modificar elementos existentes,\ragregar nuevos elementos y eliminar elementos.\r\rLas listas son mutables, lo que significa que pueden cambiar su contenido después de haber sido creadas. Además, las listas admiten operaciones como la concatenación, la reproducción y la aplicación de funciones a cada elemento de la lista, lo que las hace herramientas poderosas para manipular y organizar datos.\nCon ejemplos prácticos y consejos útiles, este post te ayudará a dominar las habilidades fundamentales para trabajar con listas en Python y optimizar la manipulación de datos en tus proyectos de programación.\n\nAñadir elementos a una lista de Python\rPara añadir elementos a una lista, nos podemos valer del método append() para agregar un elemento al final de la lista o el método insert() para insertar un elemento en una posición específica. También puedes extender una lista con otra lista utilizando el método extend() o utilizar el operador + para concatenar dos listas. Estas opciones te brindan la flexibilidad para modificar tus listas según tus necesidades, lo que es esencial en el desarrollo de aplicaciones y la manipulación de datos en Python.\n\nappend():\rImagina que estás creando una lista de reproducción de música. Cada vez que descubres una nueva canción que te encanta, simplemente la añades al final de tu lista con append(). ¡Así de fácil!\n\rmi_lista = []\rmi_lista.append(\u0026#39;tomate\u0026#39;)\rRecuerda que append() siempre añade elementos al final de la lista. Si necesitas insertar elementos en una posición específica, lo comentaremos en los siguientes parágrafos.\n\n\rextend() y operador +: Alternativas para la concatenación.\rTambién podemos concatenar listas. Esto se puede hacer con el operador + entre dos listas o bien usando el método extend de una de ellas. Ambas operaciones deben partir de la existencia de dos listas, y el resultado será una lista con los elementos de las dos iniciales, sin anidación de listas.\n\rmi_lista_alimentos_ext = mi_lista + [\u0026quot;lechuga\u0026quot;, \u0026quot;pimiento\u0026quot;, \u0026quot;ajo\u0026quot;]\rmi_lista.extend([\u0026quot;lechuga\u0026quot;, \u0026quot;pimiento\u0026quot;, \u0026quot;ajo\u0026quot;])\rmi_lista == mi_lista_alimentos_ext\r## True\rmi_lista_alimentos_ext\r## [\u0026#39;tomate\u0026#39;, \u0026#39;lechuga\u0026#39;, \u0026#39;pimiento\u0026#39;, \u0026#39;ajo\u0026#39;]\rPor anidación de listas nos referimos al siguiente ejemplo, que según el caso y pese a ser un objeto más complejo y haber otras alternativas, también nos va a ser útil. Tendremos una lista como elemento dentro de otra lista.\nmi_lista.append([\u0026#39;tomate\u0026#39;])\rmi_lista\r## [\u0026#39;tomate\u0026#39;, \u0026#39;lechuga\u0026#39;, \u0026#39;pimiento\u0026#39;, \u0026#39;ajo\u0026#39;, [\u0026#39;tomate\u0026#39;]]\rLa ventaja de usar extend() es que modificas una lista existente en lugar de crear una nueva.\nAmbas opciones de concatenación son útiles en diferentes situaciones, dependiendo de si prefieres mantener intactas tus listas originales o si estás dispuesto a modificar una de ellas para obtener la concatenación deseada.\n\n\rinsert(): Añade elemento en una posición determinado de la lista\rO insertar el elemento en un índice determinado:\nmi_lista.insert(0, [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;])\rmi_lista\r## [[\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;], \u0026#39;tomate\u0026#39;, \u0026#39;lechuga\u0026#39;, \u0026#39;pimiento\u0026#39;, \u0026#39;ajo\u0026#39;, [\u0026#39;tomate\u0026#39;]]\rLa posibilidad de insertar elementos en una ubicación específica es útil cuando necesitas mantener un orden particular en tu lista o cuando deseas insertar elementos en medio de una secuencia sin reemplazar los elementos existentes. Esta funcionalidad es especialmente valiosa en situaciones en las que se requiere una manipulación precisa de los datos almacenados en una lista. Aunque, de nuevo, en esas situaciones viene bien evaluar si en lugar de ello, necesitamos hacer uso de un objeto diferente a la lista . Todo dependerá de la utilidad que necesitemos conseguir.\n\n\r\rEliminar elementos de la lista\r¿Qué pasa si por el contratrio lo que necesitamos es eliminar elementos de una lista? Eliminar elementos de una lista en Python es una operación común, ya que te permite mantener tus datos actualizados y adaptados a las necesidades de tu aplicación. Par aello, puedes utilizar métodos como remove(), que elimina la primera ocurrencia de un valor específico, o pop(), que elimina un elemento en una posición dada y lo devuelve. También puedes utilizar la instrucción del para eliminar elementos por su índice. Además, puedes emplear métodos como clear() para vaciar por completo la lista o slicing para crear una nueva lista sin los elementos que deseas eliminar. Estas herramientas te permiten gestionar eficazmente tus datos en Python y mantener tus listas actualizadas de acuerdo a las necesidades de tu programa.\n\nremove(): Por elemento\rEl método remove() en Python se utiliza para eliminar la primera ocurrencia de un elemento específico en una lista. Es importante destacar que si intentas eliminar un elemento que no existe en la lista, se generará un error.\nmi_lista.remove(\u0026#39;tomate\u0026#39;)\rmi_lista\r## [[\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;b\u0026#39;], \u0026#39;lechuga\u0026#39;, \u0026#39;pimiento\u0026#39;, \u0026#39;ajo\u0026#39;, [\u0026#39;tomate\u0026#39;]]\rPara eliminar todas las ocurrencias, es necesario por tanto algo como:\nmi_lista = [1, 2, 3, 4, 3, 5, 6, 3]\relemento_a_eliminar = 3\rmi_lista = [x for x in mi_lista if x != elemento_a_eliminar]\rprint(mi_lista)\r## [1, 2, 4, 5, 6]\rDe esta manera, podemos fácilmente eliminar todos los determinados elementos en una lista, no solo la primera ocurrencia.\n\n\rpop(): Elimina elemento de una lista basado en su índice.\rEl método pop() en Python es una herramienta versátil que te permite eliminar elementos de una lista según su índice, lo que lo convierte en una función imprescindible para el manejo de datos. Al especificar un índice como primer argumento, pop() elimina el elemento en esa posición y lo devuelve, lo que te brinda el poder de acceder a ese elemento antes de su eliminación si es necesario. Además, si utilizas pop() sin un índice, eliminará y te devolverá el último elemento de la lista de forma predeterminada. Esta flexibilidad lo convierte en una función de alto valor tanto para tareas simples como para complejas en programación, y es esencial para mantener el control y la precisión en la manipulación de tus listas en Python.\nVeamos un ejemplo:\nmi_lista.pop(0)\r## 1\ry aquí lo guardamos en un objecto mi_carrito_compra mientras lo eliminamos de la lista de alimentos:\nmi_carrito_compra = []\rmi_carrito_compra.append(mi_lista_alimentos_ext.pop(0))\rmi_carrito_compra\r## [\u0026#39;tomate\u0026#39;]\rPor defecto, si no se le pasa ningún índice, el método pop() extraerá de la lista el último elemento.\n\n\rclear(): Vacia por completo la list\rEl método clear() en Python es como un “botón de reinicio” para tus listas. Cuando lo utilizas, vacía por completo una lista, eliminando todos sus elementos. Por ejemplo, si estás desarrollando una aplicación que almacena datos temporales en una lista y deseas borrar esos datos de manera eficiente cuando ya no son necesarios, clear() es la función que necesitas.\n\n\rPython sets (conjuntos) y HashLists como listas sin elementos duplicados\rLos conjuntos en Python son estructuras de datos que funcionan de manera similar a las listas, pero con una característica fundamental: no permiten elementos duplicados. Al usar conjuntos, puedes crear colecciones de datos únicos de manera eficiente. Esto significa que si intentas agregar un elemento que ya está presente en el conjunto, simplemente se ignorará, lo que es perfecto cuando necesitas garantizar la unicidad de tus datos. Pueden expresarse con set() o con {} por ejemplo: {1, 2, 3}.\nVeamos un ejemplo de conjuntos en Python:\nmi_lista_con_duplicados = [\u0026quot;manzana\u0026quot;, \u0026quot;platano\u0026quot;, \u0026quot;manzana\u0026quot;]\rset(mi_lista_con_duplicados)\r## {\u0026#39;platano\u0026#39;, \u0026#39;manzana\u0026#39;}\ry sus operaciones entre conjuntos de Python más básicas:\nmi_nueva_lista = [\u0026quot;uva\u0026quot;, \u0026quot;manzana\u0026quot;]\rset(mi_lista_con_duplicados) - set(mi_nueva_lista)\r## {\u0026#39;platano\u0026#39;}\rset(mi_lista_con_duplicados + mi_nueva_lista)\r## {\u0026#39;uva\u0026#39;, \u0026#39;platano\u0026#39;, \u0026#39;manzana\u0026#39;}\rEl principal uso de los conjuntos o sets es la comprobación rápida de pertenencia. Por lo tanto, no depende del orden, por lo que podemos considerarlos como ‘no ordenados’ a diferencia de las listas.\n\n\r\rMantente al día de Python en Typethepipe\rMantente al día con las últimas novedades y consejos en programación en Typethepipe. Síguenos para estar al tanto de los avances en el mundo de Python y continuar mejorando tus habilidades de desarrollo. ¡Hasta la próxima y no olvides Seguirnos!\n\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python y Data Science! \r\r\r\r\r\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1699315200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1699315200,"objectID":"4004c3c9793368f9c6fa15bd0cfdfbb3","permalink":"/es/vizs-and-tips/python-anadir-eliminar-elementos-lista/","publishdate":"2023-11-07T00:00:00Z","relpermalink":"/es/vizs-and-tips/python-anadir-eliminar-elementos-lista/","section":"vizs-and-tips","summary":"Conviértete en un maestro de la manipulación de Listas en Python: Añade y elimina elementos con Precisión. Con ejemplos prácticos y consejos útiles, este post te ayudará a dominar las habilidades fundamentales para trabajar con listas en Python.","tags":[],"title":"Cómo añadir y eliminar elementos en una lista de Python","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Tips"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #204a87; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #8f5902; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #204a87; font-weight: bold; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rComo bien sabes, el formato JSON resulta útil para diversas tareas de programación, que van desde archivos de configuración hasta el almacenamiento de pesos y parámetros de modelos, lo que lo convierte en una elección versátil. Con Polars, puedes cargar, manipular y escribir archivos JSON sin esfuerzo, agilizando tus procesos de manejo de datos.\nJSON (JavaScript Object Notation) es un formato de datos amigable para el usuario, conocido por su simplicidad y legibilidad, lo que lo hace perfecto para una variedad de aplicaciones. Su versatilidad y compatibilidad con numerosos lenguajes de programación lo convierten en una herramienta poderosa para la representación y el intercambio de datos en la era moderna.\n\nCómo trabajar con archivos JSON en Polars\rEn medio del mundo dinámico de la manipulación y el análisis de datos, hay una biblioteca de Python que está causando sensación: como ya hemos tratado en TypeThePipe, se trata de Polars. Si bien el procesamiento de datos se asocia con frecuencia a la biblioteca Pandas, Polars emerge durante los últimos meses, destacándose por su rendimiento ultrarrápido y un amplio conjunto de funciones, cada vez más creciente. Lo que distingue a Polars es su capacidad para manejar datos JSON, lo que lo convierte en un activo indispensable para las personas que trabajan con estructuras de datos complejas y siempre cambiantes.\nEn este post, vamos a indagar en la manipulación de JSON y revelar cómo fácilmente podemos serializar/deserializar DataFrames, LazyDataFrames y Expresiones de JSON.\n\nLeyendo JSON con la función de Polars read_json\rLa función de Polars read_json nos permite fácilmente importar datos desde JSON y convertirlos en un DataFrame o LazyDataFrame estructurado, simplificandonos el proceso de análisis de datos.\nAdemás, puedes agregar parámetros relativos al esquema del mismo. Bien estés trabajando con estructuras JSON complejas o sencillas, este método maneja la conversión de manera eficiente, lo que te ahorra tiempo y esfuerzo. Es una característica útil que hace que la manipulación de datos sea más confiable y robusta.\nimport json\r\rconfig_json = {\r \u0026quot;model_type\u0026quot;: \u0026quot;regression\u0026quot;,\r \u0026quot;model_reg_vars\u0026quot;: {\r \u0026quot;price\u0026quot;: \u0026quot;continuous\u0026quot;,\r \u0026quot;zip_range\u0026quot;: \u0026quot;categorical\u0026quot;\r },\r \u0026quot;model_dep_var\u0026quot;: {\r \u0026quot;y\u0026quot;: \u0026quot;categorical\u0026quot;\r },\r \u0026quot;model_version_tag\u0026quot;: 1.19\r}\r\r\rwith open(\u0026#39;data.json\u0026#39;, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f:\r json.dump(config_json, f, indent=2)\rimport polars as pl\r\rdf_from_json = (\rpl.read_json(\u0026quot;data.json\u0026quot;,\r schema={\r \u0026#39;model_type\u0026#39;: pl.Utf8, \r \u0026#39;model_reg_vars\u0026#39;: pl.Struct([pl.Field(\u0026#39;price\u0026#39;, pl.Utf8), pl.Field(\u0026#39;zip_range\u0026#39;, pl.Utf8)]), \r \u0026#39;model_dep_var\u0026#39;: pl.Struct([pl.Field(\u0026#39;y\u0026#39;, pl.Utf8)]), \r \u0026#39;model_version_tag\u0026#39;: pl.Float64\r }\r )\r)\rpl.read_json(\u0026quot;data.json\u0026quot;).schema\r## {\u0026#39;model_type\u0026#39;: Utf8, \u0026#39;model_reg_vars\u0026#39;: Struct([Field(\u0026#39;price\u0026#39;, Utf8), Field(\u0026#39;zip_range\u0026#39;, Utf8)]), \u0026#39;model_dep_var\u0026#39;: Struct([Field(\u0026#39;y\u0026#39;, Utf8)]), \u0026#39;model_version_tag\u0026#39;: Float64}\r\nDesanidando campos de JSON dentro de columnas DataFrame\rSeveral strategies can be taken for unnesting JSON fields from a POlars DataFrame. First one one can rename_fields as Struct method.\nmodel_reg_col_name = \u0026quot;model_reg_vars\u0026quot;\rstruct_names = [f\u0026#39;{model_reg_col_name}_{i}\u0026#39; for i in df_from_json[model_reg_col_name].struct.fields]\r\r(\r df_from_json\r .select(pl.col(model_reg_col_name).struct.rename_fields(struct_names))\r .unnest(model_reg_col_name)\r)\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\r}\r\rshape: (1, 2)model_reg_vars_pricemodel_reg_vars_zip_rangestrstr\u0026quot;continuous\u0026quot;\u0026quot;categorical\u0026quot;\rAnother way if you have few nested fields and know their name, you can simply use select() and access them by struct.field()\ndf_from_json.select(\r pl.all().exclude(\u0026quot;model_reg_vars\u0026quot;),\r pl.col(\u0026quot;model_reg_vars\u0026quot;).struct.field(\u0026quot;zip_range\u0026quot;),\r pl.col(\u0026quot;model_reg_vars\u0026quot;).struct.field(\u0026quot;price\u0026quot;)\r)\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\r}\r\rshape: (1, 5)model_typemodel_dep_varmodel_version_tagzip_rangepricestrstruct[1]f64strstr\u0026quot;regression\u0026quot;{\u0026quot;categorical\u0026quot;}1.19\u0026quot;categorical\u0026quot;\u0026quot;continuous\u0026quot;\r\n\rDesanidando campos dentro de varias columnas en Polars\rDesanidar varias columnas de tipo ‘struct’ en Polars es una tarea que a menudo surge al tratar con datos complejos y anidados. Polars proporciona una forma directa de hacerlo utilizando el método ‘unnest’ en múltiples columnas de tipo ‘struct’ de manera simultánea. Esta operación esencialmente aplana las estructuras anidadas, haciendo que los datos sean más accesibles para su análisis y manipulación. Al especificar los nombres de las columnas que deben desanidarse, puedes trabajar de manera eficiente con los datos contenidos en esas estructuras, simplificando tus tareas de procesamiento de datos en Polars.\ndf_from_json.unnest(\u0026quot;model_dep_var\u0026quot;, \u0026quot;model_reg_vars\u0026quot;)\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\r}\r\rshape: (1, 5)model_typepricezip_rangeymodel_version_tagstrstrstrstrf64\u0026quot;regression\u0026quot;\u0026quot;continuous\u0026quot;\u0026quot;categorical\u0026quot;\u0026quot;categorical\u0026quot;1.19\rEsto es genial siempre y cuando los nombres de los campos anidados no colisionen. Si eso sucede, se espera que la función ‘unnest’ falle.\nUna manera un tanto ingeniosa de evitar errores por columnas duplicadas es la que se propone en la respuesta a la pregunta de Stack Overflow. Sin embargo, es un enfoque un tanto ‘hacker’ porque debes modificar la función ‘unnest’ del DataFrame de Polars. Hacerlo sin una estrategia clara podría dar lugar a inconsistencias en el código de tu proyecto\ndef unnest(self, columns, *more_columns, prefix=None, suffix=None, col_prefix=False, col_suffix=False, drop_existing=False):\r if isinstance(columns, str):\r columns = [columns]\r if more_columns:\r columns = list(columns)\r columns.extend(more_columns)\r #check to see if any new parameters are used, if not just return as is current behavior\r if drop_existing==False and not (prefix or suffix or col_prefix or col_suffix):\r return self._from_pydf(self._df.unnest(columns))\r final_prefix=\u0026quot;\u0026quot;\r final_suffix=\u0026quot;\u0026quot;\r \r for col in columns:\r if col_prefix:\r final_prefix=col+\u0026quot;_\u0026quot;+prefix if prefix else col+\u0026quot;_\u0026quot;\r if col_suffix:\r final_suffix=\u0026quot;_\u0026quot;+col+suffix if suffix else \u0026quot;_\u0026quot;+col\r tempdf = self[0].select(col)\r innercols = tempdf._from_pydf(tempdf._df.unnest([col])).columns\r newcols = [final_prefix+innercol+final_suffix for innercol in innercols]\r self = (\r self\r .with_columns(pl.col(col).struct.rename_fields(newcols))\r .drop([drop_col for drop_col in newcols if drop_col in self.columns])\r )\r return self._from_pydf(self._df.unnest(columns))\rpl.DataFrame.unnest=unnest\r\nDe esta manera, puedes agregar programáticamente un sufijo a las columnas, como equivalente a lo que hemos visto en la sección anterior.\ndf_from_json.unnest(\u0026quot;model_dep_var\u0026quot;, \u0026quot;model_reg_vars\u0026quot;, col_suffix=True)\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\r}\r\rshape: (1, 5)model_typeprice_model_reg_varszip_range_model_reg_varsy_model_dep_varmodel_version_tagstrstrstrstrf64\u0026quot;regression\u0026quot;\u0026quot;continuous\u0026quot;\u0026quot;categorical\u0026quot;\u0026quot;categorical\u0026quot;1.19\r\n\r\rPolars write_json\rdf_from_json.write_json()\r## \u0026#39;{\u0026quot;columns\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;model_type\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Utf8\u0026quot;,\u0026quot;values\u0026quot;:[\u0026quot;regression\u0026quot;]},{\u0026quot;name\u0026quot;:\u0026quot;model_reg_vars\u0026quot;,\u0026quot;datatype\u0026quot;:{\u0026quot;Struct\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;price\u0026quot;,\u0026quot;dtype\u0026quot;:\u0026quot;Utf8\u0026quot;},{\u0026quot;name\u0026quot;:\u0026quot;zip_range\u0026quot;,\u0026quot;dtype\u0026quot;:\u0026quot;Utf8\u0026quot;}]},\u0026quot;values\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;price\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Utf8\u0026quot;,\u0026quot;values\u0026quot;:[\u0026quot;continuous\u0026quot;]},{\u0026quot;name\u0026quot;:\u0026quot;zip_range\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Utf8\u0026quot;,\u0026quot;values\u0026quot;:[\u0026quot;categorical\u0026quot;]}]},{\u0026quot;name\u0026quot;:\u0026quot;model_dep_var\u0026quot;,\u0026quot;datatype\u0026quot;:{\u0026quot;Struct\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;y\u0026quot;,\u0026quot;dtype\u0026quot;:\u0026quot;Utf8\u0026quot;}]},\u0026quot;values\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;y\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Utf8\u0026quot;,\u0026quot;values\u0026quot;:[\u0026quot;categorical\u0026quot;]}]},{\u0026quot;name\u0026quot;:\u0026quot;model_version_tag\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Float64\u0026quot;,\u0026quot;values\u0026quot;:[1.19]}]}\u0026#39;\rdf_from_json.write_json(row_oriented=True)\r## \u0026#39;[{\u0026quot;model_type\u0026quot;:\u0026quot;regression\u0026quot;,\u0026quot;model_reg_vars\u0026quot;:{\u0026quot;price\u0026quot;:\u0026quot;continuous\u0026quot;,\u0026quot;zip_range\u0026quot;:\u0026quot;categorical\u0026quot;},\u0026quot;model_dep_var\u0026quot;:{\u0026quot;y\u0026quot;:\u0026quot;categorical\u0026quot;},\u0026quot;model_version_tag\u0026quot;:1.19}]\u0026#39;\rPero, ¿qué sucede con la serialización de no solo DataFrames de Polars, sino también expresiones de Polars? ¡También es posible!\n\n\rSerializa expresiones de Polars y LazyDataFrames\rA partir de polars \u0026gt;= 0.18.1, es posible serializar/deserializar una expresión para que funcione de la siguiente manera:\njson_cond_select1 = pl.col(\u0026#39;model_type\u0026#39;).alias(\u0026#39;ml_model_category\u0026#39;).meta.write_json()\rjson_cond_select2 = pl.col(\u0026#39;model_version_tag\u0026#39;).meta.write_json()\rjson_cond_filter1 = (pl.col(\u0026#39;model_version_tag\u0026#39;) == 1.19).meta.write_json()\rLas expresiones son serializables individualmente, y la configuración completa de expr_config también es serializable.\nexpr_config = {\r \u0026#39;select\u0026#39;: [\r pl.Expr.from_json(json_cond_select1),\r pl.Expr.from_json(json_cond_select2),\r ],\r \u0026#39;filters\u0026#39;: [\r pl.Expr.from_json(json_cond_filter1),\r ]\r}\r\r\r(\r pl.read_json(\u0026quot;data.json\u0026quot;)\r .filter(pl.all_horizontal(expr_config[\u0026quot;filters\u0026quot;]))\r .select(expr_config[\u0026quot;select\u0026quot;])\r).lazy().write_json()\r## \u0026#39;{\u0026quot;DataFrameScan\u0026quot;:{\u0026quot;df\u0026quot;:{\u0026quot;columns\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;ml_model_category\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Utf8\u0026quot;,\u0026quot;values\u0026quot;:[\u0026quot;regression\u0026quot;]},{\u0026quot;name\u0026quot;:\u0026quot;model_version_tag\u0026quot;,\u0026quot;datatype\u0026quot;:\u0026quot;Float64\u0026quot;,\u0026quot;values\u0026quot;:[1.19]}]},\u0026quot;schema\u0026quot;:{\u0026quot;inner\u0026quot;:{\u0026quot;ml_model_category\u0026quot;:\u0026quot;Utf8\u0026quot;,\u0026quot;model_version_tag\u0026quot;:\u0026quot;Float64\u0026quot;}},\u0026quot;output_schema\u0026quot;:null,\u0026quot;projection\u0026quot;:null,\u0026quot;selection\u0026quot;:null}}\u0026#39;\r\nMantente al día de las novedades de Polars\rEspero que esta publicación te haya ayudado a familiarizarte con la serialización y el uso de JSON en Polars, y te haya permitido disfrutar de una exhibición de algunas de sus características.\nSi deseas mantenerte actualizado y no perderte nada…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido de Python Polars!\r\r\r\r\r\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r\r","date":1696809600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1696809600,"objectID":"f8ea0df45e03b1bb4c9e9b8446dd04e2","permalink":"/es/vizs-and-tips/python-polars-manipulacion-json/","publishdate":"2023-10-09T00:00:00Z","relpermalink":"/es/vizs-and-tips/python-polars-manipulacion-json/","section":"vizs-and-tips","summary":"Desbloquea todo el potencial de Polars para un manejo de datos JSON sin problemas.","tags":["Python","Polars"],"title":"Python Polars para la manipulación de archivos json. ¡Hazlo de manera fácil y robusta!","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Post"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ff0000; font-weight: bold; } /* Alert */\rcode span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #7d9029; } /* Attribute */\rcode span.bn { color: #40a070; } /* BaseN */\rcode span.bu { color: #008000; } /* BuiltIn */\rcode span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4070a0; } /* Char */\rcode span.cn { color: #880000; } /* Constant */\rcode span.co { color: #60a0b0; font-style: italic; } /* Comment */\rcode span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #ba2121; font-style: italic; } /* Documentation */\rcode span.dt { color: #902000; } /* DataType */\rcode span.dv { color: #40a070; } /* DecVal */\rcode span.er { color: #ff0000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #40a070; } /* Float */\rcode span.fu { color: #06287e; } /* Function */\rcode span.im { color: #008000; font-weight: bold; } /* Import */\rcode span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #007020; font-weight: bold; } /* Keyword */\rcode span.op { color: #666666; } /* Operator */\rcode span.ot { color: #007020; } /* Other */\rcode span.pp { color: #bc7a00; } /* Preprocessor */\rcode span.sc { color: #4070a0; } /* SpecialChar */\rcode span.ss { color: #bb6688; } /* SpecialString */\rcode span.st { color: #4070a0; } /* String */\rcode span.va { color: #19177c; } /* Variable */\rcode span.vs { color: #4070a0; } /* VerbatimString */\rcode span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\r\r¿Qué es un ‘discriminated union’, discriminador de uniones o uniones etiquetadas y cuál es su papel en Pydantic?\rBueno, bueno, bueno, ¡miren quién decidió pasear por el mundo de los discriminadores de Pydantic! 🕶️ Prepárense, amigos, porque estamos a punto de embarcarnos en un irónico y pegajoso paseo en montaña rusa por esta selva salvaje de maravillas de la programación. ¡Abróchense los cinturones!\nEntonces, ¿de qué se trata todo el revuelo de los discriminadores de Pydantic? ¡Oh, son simplemente lo más genial desde el pan rebanado, amigos míos! Imaginen esto: tienen un montón de modelos de datos, cada uno con sus propias peculiaridades y excentricidades. Es como lidiar con un grupo de divas en un drama de secundaria, excepto que en lugar de chismes, se trata de atributos y propiedades. Reinas del drama, ¿verdad?\nAhora, digamos que quieren elegir el modelo perfecto de este conjunto caótico. ¿Cómo diablos van a hacerlo? No teman, porque los discriminadores de Pydantic están aquí para salvar el día, como un superhéroe con un sentido del humor irónico. Son como el Sherlock Holmes de la selección de modelos, deduciendo el ajuste perfecto para ustedes.\n\nHow does Pydantic discriminator works?\rEl discriminador de Pydantic permite la definición de estructuras de datos con múltiples tipos, utilizando un campo de discriminador para determinar el tipo real del objeto. Esto habilita la validación de tipos y la serialización/deserialización basada en el valor del discriminador, asegurando la integridad de los datos y la flexibilidad en la representación de diferentes tipos de objetos.\nA partir de Pydantic 1.9, lo tenemos disponible. Let’s showcase it in an easy way:\nfrom pydantic import BaseModel, Field, parse_obj_as\rfrom typing import Literal, Union, Annotated\r\rclass Tiger(BaseModel):\r animal_type: Literal[\u0026quot;tiger\u0026quot;] = \u0026quot;tiger\u0026quot;\r ferocity_scale: float = Field(..., ge=0, le=10)\r\rclass Shark(BaseModel):\r animal_type: Literal[\u0026quot;shark\u0026quot;] = \u0026quot;shark\u0026quot;\r ferocity_scale: float = Field(..., ge=0, le=10)\r\rclass Lion(BaseModel):\r animal_type: Literal[\u0026quot;lion\u0026quot;] = \u0026quot;lion\u0026quot;\r ferocity_scale: float\r\rclass WildAnimal(BaseModel):\r __root__: Annotated[Union[Tiger, Shark, Lion], Field(..., discriminator=\u0026#39;animal_type\u0026#39;)]\r\rmy_shark = WildAnimal.parse_obj({\u0026#39;animal_type\u0026#39;: \u0026#39;shark\u0026#39;, \u0026#39;ferocity_scale\u0026#39;: 5}).__root__\r#print(Shark(ferocity_scale=5).json())\r\r# Desarialice\rWildAnimal.parse_raw(Shark(ferocity_scale=5).json())\r## WildAnimal(__root__=Shark(animal_type=\u0026#39;shark\u0026#39;, ferocity_scale=5.0))\rprint(isinstance(my_shark, Shark))\r## True\rPuedes encontrar este ejemplo de polimosfirmo junto con algun ejemplo de código, además de alguna interesante discusión en:\rhttps://github.com/pydantic/pydantic/discussions/5785\n\n\rEjemplo de discriminador de unión anotada Pydantic\rPero podríamos utilizar un enfoque muy simple para lograr la mayoría de los usos mediante el uso de la unión Annotated.\nAnimal = Annotated[Union[Tiger, Shark], Field(discriminator=\u0026#39;animal_type\u0026#39;)]\rraw_data = {\r \u0026quot;animal_type\u0026quot;: \u0026quot;tiger\u0026quot;,\r \u0026quot;ferocity_scale\u0026quot;: 6\r}\rparse_obj_as(Animal, raw_data)\r## Tiger(animal_type=\u0026#39;tiger\u0026#39;, ferocity_scale=6.0)\rPrepárate para la magia de la clase Field, cortesía de Pydantic. Está equipada con un poder especial llamado “discriminator”. Al configurar el discriminador en “pet_type”, desbloqueamos la capacidad de distinguir entre nuestras criaturas fantásticas. ¡Es como darles su propio foco especial!\n¡Agárrate fuerte, porque estamos a punto de adentrarnos en las tierras salvajes de raw_data. Guarda los secretos de un “pet_type” con el espíritu ardiente de un “tigre” y un fascinante recuento de “rayas” de 6. Es como si estuviéramos mirando a un zoológico digital.\n¡Y ahora, es hora del espectáculo! Invocamos al poderoso parse_obj_as para que haga su magia de codificación. Le presentamos a nuestro majestuoso Animal y al enigmático raw_data. ¡Abra Kadabra! Con un movimiento de su varita, la transformación se despliega. Los datos crudos se convierten en una impresionante representación de nuestro Animal elegido. ¡Es como una metamorfosis mágica!\n\n\rExample of Polimorfic Base Model\rclass PolymorphicBaseModel(BaseModel):\r type: str\r\r _subtypes = dict()\r\r def __init_subclass__(subcls, type=None, **kwargs):\r super().__init_subclass__(**kwargs)\r if type:\r # n.b. if a subclass declares its own _subtypes dict, it\u0026#39;ll take precedence over this one.\r # This would allow us to re-use the same type names across different classes.\r if type in subcls._subtypes:\r raise AttributeError(\r f\u0026quot;Class {subcls}cannot be registered with polymorphic type=\u0026#39;{type}\u0026#39; because it\u0026#39;s already registered \u0026quot;\r f\u0026quot; to {subcls._subtypes[type]}\u0026quot;\r )\r subcls._subtypes[type] = subcls\r @classmethod\r def _convert_to_real_type(cls, data):\r data_type = data.get(\u0026quot;type\u0026quot;)\r\r if data_type is None:\r raise ValueError(f\u0026quot;Missing \u0026#39;type\u0026#39; for {cls}\u0026quot;)\r\r subcls = cls._subtypes.get(data_type)\r\r if subcls is None:\r raise TypeError(f\u0026quot;Unsupported sub-type: {data_type}\u0026quot;)\r if not issubclass(subcls, cls):\r raise TypeError(f\u0026quot;Inferred class {subcls}is not a subclass of {cls}\u0026quot;)\r\r return subcls(**data)\r\r @classmethod\r def parse_obj(cls, data):\r return cls._convert_to_real_type(data)\r \r \rclass Animal(PolymorphicBaseModel):\r name: str\r color: str = None\r\rclass Cat(Animal, type=\u0026quot;cat\u0026quot;):\r type: Literal[\u0026quot;cat\u0026quot;] = \u0026quot;cat\u0026quot;\r hairless: bool\r\rclass Dog(Animal, type=\u0026quot;dog\u0026quot;):\r type: Literal[\u0026quot;dog\u0026quot;] = \u0026quot;dog\u0026quot;\r breed: str\r\rcat_instance = Animal.parse_obj({\u0026quot;type\u0026quot;:\u0026quot;cat\u0026quot;, \u0026quot;hairless\u0026quot;: False, \u0026quot;name\u0026quot;: \u0026quot;meaw\u0026quot;, \u0026quot;color\u0026quot;: \u0026quot;black\u0026quot;})\rprint(isinstance(cat_instance, Cat))\r## True\rEl PolymorphicBaseModel, una clase base que sienta las bases para el comportamiento polimórfico. Define un atributo de tipo requerido e introduce un diccionario oculto _subtypes para llevar un registro de los subtipos.\nA continuación, nos sumergimos en el método init_subclass, donde sucede la magia. Permite que las subclases se registren a sí mismas con un tipo polimórfico específico. Esto nos permite distinguir entre diferentes subtipos dentro de la jerarquía de PolymorphicBaseModel.\n¡Pero espera, hay más por descubrir! Hacemos uso del método _convert_to_real_type, encargado de convertir los datos a su subtipo real en función del atributo de tipo proporcionado. Comprueba si el tipo es válido, encuentra la subclase correspondiente y asegura que sea una subclase válida de la clase base.\nFinalmente, llegamos al método parse_obj, donde tiene lugar el verdadero análisis. Sirve como punto de entrada para analizar objetos de la jerarquía polimórfica. Utilizando el método _convert_to_real_type, transforma los datos en una instancia de la subclase adecuada.\n¡Y ahí lo tienes! Un vistazo al mundo de los modelos polimórficos. Es un mundo donde las clases base y los subtipos se unen, permitiendo un análisis de objetos flexible y dinámico. Aprovecha el poder del polimorfismo y permite que tu código se adapte y evolucione con elegancia.\n\n\rPydantic 2: TypeAdapter para analizar datos en una unión discriminada\rEn Pydantic v2, puedes utilizar el TypeAdapter para analizar datos en una unión discriminada. Sin embargo, ten en cuenta que Pydantic v2 se encuentra actualmente (2023-06-18) en prelanzamiento, y la versión actual del módulo es la v1.7.\nPor lo tanto, asegúrate de actualizar a Pydantic v2 cuando esté disponible para aprovechar esta característica.\nfrom pydantic import TypeAdapter\r\radapter = TypeAdapter(Annotated[Union[Child1, Child2], Field(discriminator=\u0026#39;type\u0026#39;)])\r\rchild = adapter.validate_json(my_json_data)\r\n\rMantente al tanto de consejos sobre Pydantic y Python\rEsperamos que esta publicación te haya ayudado a familiarizarte con el uso de uniones y discriminadores en Pydantic, mostrando algunas de sus funcionalidades y permitiéndote disfrutar de sus beneficios.\nSi deseas mantenerte actualizado…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python y Pydantic! \r\r\r\r\r\r\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1694995200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1694995200,"objectID":"3720db0add32b6e63c31c765c27f41ed","permalink":"/es/post/pydantic-union-discriminada/","publishdate":"2023-09-18T00:00:00Z","relpermalink":"/es/post/pydantic-union-discriminada/","section":"post","summary":"Validación de tipos poderosa y uniones discriminadas con Pydantic: Simplifica las estructuras de datos y garantiza la seguridad de tipos. Estamos mostrando algunos ejemplos sencillos","tags":["Python","Pydantic"],"title":"Pydantic discriminated unions. Ejmplos de uniones discriminadas para simplificar las estructuras de datos y mejorar el tipado.","type":"post"},{"authors":["Carlos Vecina"],"categories":["Python","Tips"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #204a87; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #8f5902; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #204a87; font-weight: bold; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\nAyer, me pidieron configurar de manera sencilla un control deslizante de fecha y hora en Streamlit. Anteriormente, requería cierto esfuerzo y ajustes en la función st.slider(). Sin embargo, ahora es posible lograrlo de manera fluida, ya que la función del control deslizante funciona casi a la perfección con fechas.\nimport datetime\rimport streamlit as st\r\rMIN_MAX_RANGE = (datetime.datetime(2022,1,1), datetime.datetime(2023,7,1))\rPRE_SELECTED_DATES = (datetime.datetime(2023,1,1), datetime.datetime(2023,7,1))\r\rselected_min, selected_ax = st.slider(\r \u0026quot;Datetime slider\u0026quot;,\r value=PRE_SELECTED_DATES,\r min_value=MIN_MAX_RANGE[0],\r max_value=MIN_MAX_RANGE[1],\r)\rPara configurar los pasos del control deslizante cuando el usuario interactúa con él, puedes hacerlo de la siguiente manera. Ten en cuenta que los valores intermedios no serán seleccionables por defecto y podrían requerir un paso adicional. Además, existe la opción de personalizar el formato de la fecha para su visualización.\nselected_min, selected_ax = st.slider(\r \u0026quot;Datetime slider\u0026quot;,\r value=PRE_SELECTED_DATES,\r step=datetime.timedelta(days=2),\r min_value=MIN_MAX_RANGE[0],\r max_value=MIN_MAX_RANGE[1],\r format=\u0026quot;YYYY-MM-DD\u0026quot;, \r)\rOtra funcionalidad de los controles deslizantes es incluir un ayudante, que usamos con bastante frecuencia. Sin embargo, ten en cuenta que en ciertas versiones de Streamlit, utilizar el argumento “help” en el control deslizante de fecha y hora podría alterar la visualización del título del control deslizante.\n\nPuedes acceder a más contenido gratis sobre Streamlit en nuestro blog TypeThePipe\n\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python! \r\r\r\r\r\r\r","date":1693612800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1693612800,"objectID":"05d2ebc082679df346aa22907292db88","permalink":"/es/vizs-and-tips/streamlit-datetime-slider-python/","publishdate":"2023-09-02T00:00:00Z","relpermalink":"/es/vizs-and-tips/streamlit-datetime-slider-python/","section":"vizs-and-tips","summary":"Creando un control deslizante interactivo de fecha y hora con Streamlit en Python. Fácil y potente.","tags":["Python","Streamlit"],"title":"¿Cómo crear en Streamlit un Datetime Slider o deslizante de fechas.","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["IA","Post"],"content":"\r\rDesde Typethepipe repasamos las claves del evento de ayer de OpenAI y Microsoft. Parece que avanza firme en su misión de comoditizar la IA, cada vez más potente, personalizada y asequible de precio. Además, anuncia un inicio de marketplace de aplicaciones que puede venir a competir con Apple, Google, Amazon… y redefinir como interactuamos con Internet y los dispositivos electrónicos.\n\nOpenAI conferencia Noviembre 2023: GPT-4 Turbo y la Nueva Tienda GPT\rOpenAI ha marcado un hito significativo en la evolución de herramientas y servicios de inteligencia artificial en su primer evento para desarrolladores, DevDay. Este evento liderado por Sam Altman, CEO de OpenAI, ha introducido avances notables que prometen ampliar y enriquecer el futuro de desarrolladores y usuarios por igual. Aquí les presentamos un resumen extendido y detallado para capturar la esencia de los anuncios, listos para revolucionar el campo de la IA.\n\nGPT-4 Turbo: La Nueva Frontera en Modelos Generativos\rOpenAI ha desvelado el GPT-4 Turbo, una versión mejorada de su popular modelo GPT-4. Este modelo no solo cuenta con una ventana de contexto de 128.000 tokens, cuatro veces mayor que su predecesor, sino que también comprende textos e imágenes, estableciendo un nuevo estándar para los modelos generativos.\nAdemás, la nueva API de Asistentes permite a los desarrolladores crear agentes que pueden realizar acciones como recuperar conocimientos externos o ejecutar funciones de programación, abriendo camino a una miríada de aplicaciones, desde asistentes de codificación hasta planificadores de vacaciones impulsados por IA.\n\n\rLa Democratización de la Creación de Herramientas de IA\rEn una iniciativa que democratiza la creación de herramientas de IA, OpenAI ha facilitado que los usuarios construyan versiones personalizadas del GPT para diversas aplicaciones sin necesidad de conocimientos de codificación. Estos bots personalizables pueden ser para entretenimiento, productividad o incluso soluciones empresariales complejas.\nPronto, los creadores podrán publicar y potencialmente monetizar sus GPTs en una tienda dedicada, similar a la App Store de Apple. La tienda GPT presentará creaciones de constructores verificados y proporcionará una plataforma para destacar y recompensar a los GPTs más útiles y populares.\nEstrategia de Monetización en la Tienda GPT\rLa estrategia para monetizar estos GPTs se espera que evolucione, comenzando con una participación en los ingresos y potencialmente llevando a un modelo de suscripción para GPTs individuales si hay demanda. Las demostraciones incluyeron GPTs de organizaciones como Code.org, TripAdvisor y Canva, indicando una mezcla de contribuciones a nivel empresarial e individual a la plataforma.\nLa estrategia de OpenAI para monetizar estas creaciones de IA es innovadora y adaptable, comenzando con un modelo de participación en los ingresos para los creadores de GPT. Esto no solo incentiva la calidad y la utilidad de las aplicaciones de IA, sino que también promueve una economía creativa dentro de la comunidad de OpenAI. Se contempla la posibilidad de adoptar un modelo de suscripción para GPTs individuales si la demanda de los usuarios así lo justifica, lo que proporcionaría una corriente de ingresos sostenible para los creadores de contenido y herramientas de IA de alta calidad.\nEsta táctica de monetización refleja un compromiso de OpenAI con la sostenibilidad y el crecimiento continuo de su ecosistema de IA, alentando a desarrolladores y empresas a invertir en la creación de GPTs especializados. Al posibilitar que los constructores de GPT se beneficien directamente de sus innovaciones, OpenAI está fomentando un entorno donde la creatividad y la tecnología van de la mano, garantizando que la Tienda GPT se convierta en un centro vibrante de actividad empresarial y desarrollo tecnológico.\n\n\r\rCapacidades de Audio, Protección Legal y GPTs personalizados para empresas\rOpenAI no ha dejado atrás las capacidades de audio, lanzando una API de texto a voz con una selección de seis voces preestablecidas, mejorando las experiencias interactivas que la IA puede ofrecer. Además, con el objetivo de proteger a sus usuarios, OpenAI ha introducido Copyright Shield, con el fin de proteger a las empresas de reclamaciones de derechos de autor relacionadas con el contenido creado por las herramientas de OpenAI.\nOpenAI también anunció un programa que ayuda a las empresas a construir modelos personalizados con el apoyo de los investigadores de la compañía. Este servicio, junto con la eliminación del selector de modelos en ChatGPT y el doble de tokens por límite de tasa para todos los clientes de pago de GPT-4, simplifica la experiencia del usuario y amplifica las capacidades de los modelos proporcionados.\n\n\rConclusión: Un Futuro Colaborativo y Accesible en IA\rEn resumen, el DevDay de OpenAI ha sentado las bases para un futuro donde las herramientas de IA son más accesibles, personalizables e integrales para soluciones tanto personales como empresariales. La visión de la compañía es clara: proporcionar las herramientas y permitir que la ingeniosidad de la comunidad impulse la próxima ola de aplicaciones de IA. Esta nueva era de IA se caracteriza por la apertura para construir, compartir y monetizar innovaciones impulsadas por IA, preparando el escenario para un futuro emocionante y colaborativo.\nSi deseas mantenerte actualizado…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Síguenos para las últimas novedades y contenido sobre IA! \r\r\r\r\r\r\r\r\r","date":1691280000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1691280000,"objectID":"458b1861617e5b04734445a5fea8c7c9","permalink":"/es/post/openai-conferencia-gpt-4-turbo-gpts/","publishdate":"2023-08-06T00:00:00Z","relpermalink":"/es/post/openai-conferencia-gpt-4-turbo-gpts/","section":"post","summary":"Analizamos datos de Eurostat sobre la expansión del teletrabajo en los diferentes paises europeos. Descubre los últimos avances de OpenAI con GPT-4 Turbo y la innovadora Tienda GPT. Explora cómo estas herramientas de IA transformarán la tecnología y el desarrollo.","tags":[],"title":"OpenAI revela innovaciones en IA: GPT-4 Turbo y la nueva tienda GPT","type":"post"},{"authors":["Carlos Vecina"],"categories":["Python","Tips"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #204a87; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #8f5902; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #204a87; font-weight: bold; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rPolars pipeline. Aplica tus functiones custom (udf) con la función pipe\rBueno, bueno, estás con Python y echas de menos el rollito pipe?? Encadenar transformaciones a dataframes de manera elegante nunca está de más. Pues.. ¡traemos buenas noticias! En nuestra transición de Pandas a Polars a la hora de trabajar con dataframes, la sintaxis de este último nos ha acabado de encandilar.\nLa función pipedel módulo Polars nos permiten encadenar operaciones pasando el resultado de las mismas como input dde la siguiente operación. Recuerda por ejemplo a los pipes de bash o del ecosistema tidyverse dplyr de R.\nPor supuesto, esta no es una de las mejores ventajas que Polars presenta sobre Pandas… ¡pero nos gusta bastante!\nSigue leyendo para descrubir de un vistazo cómo mantenerse en dentro del pipeline con Polars Python!\nLa función pipe ofrece una forma estructurada de aplicar una secuencia de funciones definidas por el usuario (UDFs). Aquí tienes un ejemplo:\nimport polars as pl\rimport random \r\r# Creamos el Polars DataFrame con las columnas base\rdf = pl.DataFrame({\r \u0026#39;name\u0026#39;: [\u0026#39;Alice\u0026#39;, \u0026#39;Bob\u0026#39;, \u0026#39;Charlie\u0026#39;], \r \u0026#39;offensive_skill\u0026#39;: [5, 30, 85], \r \u0026#39;defensive_skill\u0026#39;: [92, 30, 10]\r })\r \r# Definimos las funciones custom que aplicar\rdef add_position_column(df):\r df = df.with_columns( \r pl.when(pl.col(\u0026#39;defensive_skill\u0026#39;) \u0026gt; 50).then(\u0026#39;CB\u0026#39;)\r .when(pl.col(\u0026#39;offensive_skill\u0026#39;) \u0026gt; 50).then(\u0026#39;FW\u0026#39;)\r .otherwise(\u0026#39;bench\u0026#39;).alias(\u0026quot;position\u0026quot;)\r )\r return df\r\rdef add_squad_number_column(df):\r df = df.with_columns( \r pl.when(pl.col(\u0026#39;position\u0026#39;) == \u0026#39;CD\u0026#39;).then(pl.lit(random.sample(range(2, 6), 1)[0], dtype=pl.Int8))\r .when(pl.col(\u0026#39;position\u0026#39;) == \u0026#39;FW\u0026#39;).then(pl.lit(random.sample(range(7, 19), 1)[0], dtype=pl.Int8))\r .otherwise(\u0026#39;-\u0026#39;).alias(\u0026quot;squad_number\u0026quot;)\r )\r return df\r\r# Encadena las operaciones usando la función pipe\r\r(\r df\r .pipe(add_position_column)\r .pipe(add_squad_number_column)\r)\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\r}\r\rshape: (3, 5)nameoffensive_skilldefensive_skillpositionsquad_numberstri64i64strstr\u0026quot;Alice\u0026quot;592\u0026quot;CB\u0026quot;\u0026quot;-\u0026quot;\u0026quot;Bob\u0026quot;3030\u0026quot;bench\u0026quot;\u0026quot;-\u0026quot;\u0026quot;Charlie\u0026quot;8510\u0026quot;FW\u0026quot;\u0026quot;9\u0026quot;\r\nPolars pipe y ‘lazy evaluation’\rUn truco extra a la hora de usar la función pipe de Polars, es el uso de lazy evaluation con el objetivo de maximizar las ventajas de la optimización de query y paralelización.\nresult = (\r df.lazy()\r .pipe(add_position_column)\r .pipe(add_squad_number_column)\r .collect()\r)\r\rresult\r\r.dataframe  thead  tr  th,\r.dataframe  tbody  tr  td {\rtext-align: right;\r}\r\rshape: (3, 5)nameoffensive_skilldefensive_skillpositionsquad_numberstri64i64strstr\u0026quot;Alice\u0026quot;592\u0026quot;CB\u0026quot;\u0026quot;-\u0026quot;\u0026quot;Bob\u0026quot;3030\u0026quot;bench\u0026quot;\u0026quot;-\u0026quot;\u0026quot;Charlie\u0026quot;8510\u0026quot;FW\u0026quot;\u0026quot;8\u0026quot;\rUsando el método .pipe(), podremos separar funcionalidades y mantener el código más mantenible a largo plazo, mientras mantenemos las ventajas de la paralelización de Polars.\n\n\rPolars user defined functions (udfs)\rEn este punto, deberías estar convencido de que las expresiones de Polars son tan poderosas y flexibles que hay mucho menos necesidad de funciones personalizadas de Python en comparación con otras bibliotecas.\nSin embargo, aún necesitas tener la capacidad de pasar el estado de una expresión a una biblioteca de terceros o aplicar tu función de caja negra sobre los datos en Polars.\n\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python! \r\r\r\r\r\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1679961600,"objectID":"877ddfd77bf571a6a331d1e39c612ff4","permalink":"/es/vizs-and-tips/python-polars-pipe-funcion/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/es/vizs-and-tips/python-polars-pipe-funcion/","section":"vizs-and-tips","summary":"¿Estás explorando Polars como una alternativa a Pandas? ¡Nos encanta por la sensación de pipe flow! Aprende en 3 líneas cómo y cuándo usarlo.","tags":[],"title":"Función pipe en Python Polars. ¡No te salgas del pipeline!","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Post"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #204a87; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #8f5902; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #204a87; font-weight: bold; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\n¿Qué es SQLAlchemy?\rSQLAlchemy es un SQL toolkit de código abierto para interaccionar con bases de datos desde Python. SQLAlchemy proporciona una interfaz de alto nivel para realizar operaciones comunes a bases de datos de diferente naturaleza, de una manera sencilla, abstracta y generalizada, sin tener que atender demasiado a las especifidades de cada una de ellas.\nA este tipo de librerías se las conoce como ORM (en inglés Object-Relational Mapping). Conozcamos un poco más sobre este concepto.\n\n\r¿Qué es un ORM?\rLa finalidad de un ORM es mapear (relacionar) entidades de una base de datos y objetos (p.e clases de Python) de un determinado lenguaje de programación con tablas de una base de datos. Son muy comunes en los paradigmas de programación orientada a objetos, ya que hace uso de ellos para ofrecer una abstracción y una manera de interactuar con las bases de datos en un manera Pytonica sin necesidad de utilizar directamente queries de SQL para ello. Se encargará de realizar las operaciones en el motor de sql de manera transparente para el usuario.\n\nVentajas de usar un ORM en Python\rTener nuestras entidades como objetos en Python puede ser muy interesante a la hora de gestionar aplicaciones e interactuar(consulatar, hacer updates…) de manera sencilla con ellos.\nUno de las ventajas más destacables es que nos podemos abstraer y ser agnósticos a la base de datos con la que trabajemos. SQLALchemy tiene disponible una serie de dialectos, que se pueden extender y se han extendido (ElasticSearch…)\nOtras cosas de las que SQLAlchemy se ocupa por nosotros es la posibilidad de gestionar un pool de conexiones, proveer un context manager, prevención de inyección SQL…\n\n\rContras de usar un ORM en Python\rLas cosas se pueden complicar con operaciones complejas. Mientras que nos ofrece una optimización de queries, cuando empezamos a hacer joins, agrupaciones y queries nesteadas a lo mejor nos queda una sintaxis bastante confusa, a lo peor sufriremos llevándolas a cabo. Muchos ORMs deja ejecutar SQL en crudo, pero perdiendo gran parte de su propósito.\nComo siempre, al añadir un nivel extra de abstracción, la complejidad general podrá amentar, al mismo tiempo que debuggear se puede hacer más complejo al abstraernos de los detalles de la capa de bases de datos.\nAhora que ya sabemos más sobre qué es SQLAlchemy y qué nos permite hacer, veamos con más detalle sus elementos claves.\n\n\r\rElementos clave de SQLAlchemy\rEn cualquier momento puedes bucear en la documentación de SQLAlchemy. Sin embargo, me gustaría comentar brevemente los conceptos clave con los que podrás empezar a trabajar con esta herramienta, teniendo una idea de lo que tenemos entre manos.\nPor ejemplo, ¿cuál es la diferencia entre Engine y Session dentro de SQLALchemy?\nEngine: Es parte del core de SQLAlchemy, gestionando y proveyendo las conexiones a la base de datos como API de bajo nivel. Es capaz de manejar una pool de conexiones, transacciones y ejecución de comandos SQL. Normalmente, se crea al inicio de la aplicación y se utiliza y comparte a lo largo de la ejecución.\rEn última instancia podríamos usar esta entidad para trabajar con la base de datos ejectando SQL sin necesidad de usar las capacidades como ORM en toda su extensión, con sus modelos etc..\nSession: Es un nivel superior de abstración que se situa por encima del Engine. Permite realizar transacciones con la base de datos de una manera orientada a objetos. Se crearán y destruirán durante la ejección de la aplcación según sea necesario. Se encarga de hacer los commits rollbacks.\nRespuesta en SO interesante a este respecto\nOtros conceptos interesantes:\nDialect: Los dialectos son los responsables de ‘traducir’ la sintaxis SQL genérica generada por SQLAlcemy a la sintaxis específica de la base de datos correspondiente. Por ejemplo, gestionar los tipos de datos es uno de los puntos más importantes en este proceso. Tenemos los siguientes disponibles de base:\ntabla de los dialectos disponibles de base en sqlalchemy\r\ry estos son extensibles. Es decir, que si queremos algo extra como interacción con ElasticSearch u OpenSearch (AWS), debemos instalar(o implementar) sus dialectos específicos.\nComo ejemplo, el módulo ElasticSearch dbapi.\nMetadata: Se trata de un objeto que representa y contiene información sobre el esquema de base de datos. Por ejemplo las tablas, constraints, columnas, relaciones… Se usa internamente para generar las instrucciones SQL y para gestionar las migraciones.\nModel: Un modelo en SQLALchemy es un objeto de Python que represena una tabla en base de datos. Heredan de DeclarativeBase.\nAquí tenemos un ejemplo sobre Postgres:\nfrom sqlalchemy import Column, Integer, Float\rfrom sqlalchemy.dialects.postgresql import UUID\rfrom sqlalchemy.orm import DeclarativeBase\rimport uuid\r\r\rclass Base(DeclarativeBase):\r pass\r \rclass Product(Base):\r\r __tablename__ = \u0026quot;products\u0026quot;\r\r id: uuid = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\r price = Column(Float)\r amount = Column(Integer)\r \r def __repr__(self):\r return f\u0026quot;\u0026quot;\u0026quot;\u0026lt;Product(price=\u0026#39;{self.price}\u0026#39;, amount=\u0026#39;{self.amount}\u0026#39;, product_id=\u0026#39;{self.product_id}\u0026#39;)\u0026gt;\u0026quot;\u0026quot;\u0026quot;\r\n\r¿Se pude tipar con mypy en SQLAlchemy v2.0?\rSí, a partir de esta versión no será necesario instalar stubs o módulos específicos para que el mapeo que realiza SQLAlchemy sea compatible con Mypy y con el reconocimiento de la sintaxis por los IDEs. Bastará con pip install sqlalchemy[mypy].\nSiguientdo con el ejemplo anterior, el tipado estático quedaría:\nfrom sqlalchemy import Column, Integer, Float\rfrom sqlalchemy.dialects.postgresql import UUID\rfrom sqlalchemy.orm import DeclarativeBase\rimport uuid\r\r\rclass Base(DeclarativeBase):\r pass\r \rclass OrderNew(Base):\r\r __tablename__ = \u0026quot;orders_new\u0026quot;\r\r id: uuid = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\r price: float = Column(Float)\r amount: int = Column(Integer)\r description: str | None = Column(Integer)\r\r \r def __repr__(self):\r return f\u0026quot;\u0026quot;\u0026quot;\u0026lt;Order(price=\u0026#39;{self.price}\u0026#39;, amount=\u0026#39;{self.amount}\u0026#39;, product_id=\u0026#39;{self.product_id}\u0026#39;)\u0026gt;\u0026quot;\u0026quot;\u0026quot;\r\n\r¿Cuándo usar sessionmaker()?\rNos permite crear una factoría de sesiones, configurando el comportamiento de las sesiones desde un solo lugar. Podemos con ello además separar la configuración de las sesiones de su creación, reduciendo duplicidades de código.\n\n\r¿Qué son los Eventos ORM?\rMediante la API de eventos de SQLAlchemy, podemos configurar listeners que desencadenen la ejecución de determinadas funciones definidas por el usuario. Se usa o bien la función listen() o el decorador @listen_for(). Por ejemplo, esto puede ser útil en el caso de necesitar refrescar credenciales, loggear…\nAquí tenemos un ejemplo:\nfrom sqlalchemy import create_engine\rfrom sqlalchemy.event import listens_for\r\rengine = create_engine(\u0026#39;sqlite:///typethepipe.db\u0026#39;)\r\r@listens_for(engine, \u0026quot;do_connect\u0026quot;, named=True)\rdef aws_token(cparams, **kw):\r cparams[\u0026#39;password\u0026#39;] = get_temp_token() \r print(\u0026quot;AWS token provisioned\u0026quot;)\rSi quieres profundizar en los eventos de SQLA, os dejamos link a la docu como siguiente paso.\n¡Sigue leyendo nuestros Python Posts!\n\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python y SQLALchemy! \r\r\r\r\r\r\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\r","date":1678147200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1678147200,"objectID":"49781e71ff57c0bec348e1927bb346a5","permalink":"/es/post/que-es-sqlalchemy-2/","publishdate":"2023-03-07T00:00:00Z","relpermalink":"/es/post/que-es-sqlalchemy-2/","section":"post","summary":"¿Has escuchado sobre SQLAlchemy y su nueva versión 2.0, pero no sabes bien qué es? SQLAlchemy es una de las librerías más usadas de Python a la hora de tratar con bases de datos.","tags":[],"title":"¿Qué es SqlAlchemy? Prueba la v2.0 para acceder a bases de datos desde Python","type":"post"},{"authors":["Carlos Vecina"],"categories":["Tips"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #204a87; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #8f5902; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #204a87; font-weight: bold; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rEl comando git add es una operación fundamental en el sistema de control de versiones Git. Una necesidad recurrente entre los aprendices de Git es agregar todos los archivos en un directorio / capeta o directorios anidados. Para hacerlo, simplemente necesitamos una instrucción. Este comando es git add .. Funciona de manera recursiva de forma predeterminada.\ngit add .\rSi en lugar de ejecutarlo en el directorio actual, quieres hacerlo en un subdirectorio, es tan fácil como:\ngit add libs/\rNote that you should prefer the . over the usage of * as the shell interprets it and replaces it with all the files and folders in the current directory.\nPuedes usar git add con la opción --all o --update para preparar los archivos que han sido eliminados para su eliminación.\nComo nota final, uno podría añadir archivos enumerados en el .gitignore (ignorándolos) al agregar la bandera -f o --force. Si lo haces en un directorio, funcionará de manera recursiva.\ngit add --force libs/\r#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\rSuscribe for more Git tips!\r\r\r\r\r\r","date":1672876800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1672876800,"objectID":"47f9a12c98312880d3c93d17fdaab9af","permalink":"/es/vizs-and-tips/git-add-recursivo/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/es/vizs-and-tips/git-add-recursivo/","section":"vizs-and-tips","summary":"¿Estas empezando con Git y quieres añadir ficheros recursivamente? Veamos como hacerlo en una sola línea.","tags":[],"title":"Git add recursivo. Cómo añadir directorios y subdirectorios recursivamente","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Post"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ff0000; font-weight: bold; } /* Alert */\rcode span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #7d9029; } /* Attribute */\rcode span.bn { color: #40a070; } /* BaseN */\rcode span.bu { color: #008000; } /* BuiltIn */\rcode span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4070a0; } /* Char */\rcode span.cn { color: #880000; } /* Constant */\rcode span.co { color: #60a0b0; font-style: italic; } /* Comment */\rcode span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #ba2121; font-style: italic; } /* Documentation */\rcode span.dt { color: #902000; } /* DataType */\rcode span.dv { color: #40a070; } /* DecVal */\rcode span.er { color: #ff0000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #40a070; } /* Float */\rcode span.fu { color: #06287e; } /* Function */\rcode span.im { color: #008000; font-weight: bold; } /* Import */\rcode span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #007020; font-weight: bold; } /* Keyword */\rcode span.op { color: #666666; } /* Operator */\rcode span.ot { color: #007020; } /* Other */\rcode span.pp { color: #bc7a00; } /* Preprocessor */\rcode span.sc { color: #4070a0; } /* SpecialChar */\rcode span.ss { color: #bb6688; } /* SpecialString */\rcode span.st { color: #4070a0; } /* String */\rcode span.va { color: #19177c; } /* Variable */\rcode span.vs { color: #4070a0; } /* VerbatimString */\rcode span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\r\r¿Qué es un Enum y su integración con Pydantic?\r¡Oh, esta es una gran pregunta! ¡Nunca la había escuchado antes! Un Enum, para los no iniciados, es una característica ingeniosa que, cuando se combina con la biblioteca Pydantic, te ayuda a controlar el caos de la jungla de datos. Es una combinación del Enum de Python (abreviatura de enumeración) y el poder de validación de Pydantic. Los Enums te permiten definir un conjunto de valores con nombres a los que tus datos deben adherirse. Pydantic luego verifica si tus datos son parte de este club exclusivo y, si no lo son, amablemente les muestra la puerta de salida.\n\n¿Cómo me ayudan Pydantic y Enum?\rSi alguna vez has trabajado con datos, sabes que tienen voluntad propia. A veces son impecables y perfectos. En otras ocasiones, son un desastre total. Los Enums están aquí para salvarte de esos días en los que tus datos deciden actuar por su cuenta.\nAl definir Enums y utilizarlos en tus modelos de Pydantic, creas un conjunto de reglas que tus datos deben seguir, como un profesor estricto pero justo. De esta manera, puedes asegurarte de que solo datos válidos entren en tu sistema y que cualquier valor atípico se maneje adecuadamente.\nfrom enum import Enum\rfrom pydantic import BaseModel, ValidationError\r\rclass Pet(BaseModel):\r name: str\r animal_type: str\r sex: str\r \rPuedes ser más específico al definir tus modelos de Pydantic utilizando Enums:\nfrom pydantic import ValidationError\r\rclass Sex(Enum):\r MALE = \u0026#39;male\u0026#39;\r FEMALE = \u0026#39;female\u0026#39;\r \rclass DomesticAnimals(Enum):\r CAT = \u0026#39;cat\u0026#39;\r DOG = \u0026#39;dog\u0026#39;\r FISH = \u0026#39;fish\u0026#39;\r BIRD = \u0026#39;bird\u0026#39;\r\r# And then\r\rclass Pet(BaseModel):\r name: str\r animal_type: DomesticAnimals\r sex: Sex\r \rPet(name=\u0026#39;Timmy\u0026#39;, animal_type=\u0026#39;bird\u0026#39;, sex=\u0026#39;male\u0026#39;)\r## Pet(name=\u0026#39;Timmy\u0026#39;, animal_type=\u0026lt;DomesticAnimals.BIRD: \u0026#39;bird\u0026#39;\u0026gt;, sex=\u0026lt;Sex.MALE: \u0026#39;male\u0026#39;\u0026gt;)\rAgregar un valor que no existe (por ejemplo, “Tigre”, que no está permitido en animales domésticos) a un Enum existente generará un error el valor no es un miembro de la enumeración válido. Este es uno de los principales casos de uso para ellos.\nimport pytest\r\rwith pytest.raises(ValidationError, match=\u0026#39; value is not a valid enumeration member\u0026#39;) as e_info:\r Pet(\r name=\u0026#39;Timmy\u0026#39;, \r animal_type=\u0026#39;tiger\u0026#39;, \r sex=\u0026#39;male\u0026#39;\r )\rprint(e_info.value)\r## 1 validation error for Pet\r## animal_type\r## value is not a valid enumeration member; permitted: \u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;fish\u0026#39;, \u0026#39;bird\u0026#39; (type=type_error.enum; enum_values=[\u0026lt;DomesticAnimals.CAT: \u0026#39;cat\u0026#39;\u0026gt;, \u0026lt;DomesticAnimals.DOG: \u0026#39;dog\u0026#39;\u0026gt;, \u0026lt;DomesticAnimals.FISH: \u0026#39;fish\u0026#39;\u0026gt;, \u0026lt;DomesticAnimals.BIRD: \u0026#39;bird\u0026#39;\u0026gt;])\r(*Note the UPPER_CASE_NOTATION)\n\n\r¿Y qué hay de IntEnum? ¿Cuál es la diferencia entre Enum e IntEnum?\rEn resumen, la principal diferencia entre Enum e IntEnum radica en el tipo de valores que representan. Enum es una clase de enumeración genérica que puede utilizarse con cualquier tipo de datos, mientras que IntEnum está específicamente diseñado para valores enteros y permite la comparación directa con enteros.\nExisten dos beneficios principales al utilizar IntEnums en los casos de uso correctos:\n\rDado que IntEnum garantiza que todos los miembros de la enumeración tienen un valor entero, es posible ordenarlos.\rLos miembros de IntEnum pueden compararse directamente con enteros, mientras que los miembros de Enum no pueden utilizarse en operadores de comparación de enteros.\r\rfrom enum import IntEnum\rimport pytest\r\rclass ResponseCode(IntEnum):\r OK = 200\r NOT_FOUND = 404\r ERROR = 500\r \rassert ResponseCode.OK == 200\rassert ResponseCode.OK \u0026lt;= ResponseCode.NOT_FOUND\r\rwith pytest.raises(TypeError, match=\u0026#39;cannot extend enumeration\u0026#39;) as e_info: # Check that a TypeError is raised\r class ExtendedResponseCode(ResponseCode):\r CUSTOM = 300\rprint(e_info.value)\r## ExtendedResponseCode: cannot extend enumeration \u0026#39;ResponseCode\u0026#39;\r\n\r\r¿Es posible crear una subclase de un Enum (o un StrEnum / IntEnum)?\rNo se supone que sea posible. Si intentas hacerlo mediante la herencia directa, es posible que se genere un TypeError. Para explicarlo, la documentación dice: “Permitir la creación de subclases de enums que definen miembros llevaría a una violación de algunas invariantes importantes de tipos e instancias.”\n¿Qué estaríamos infringiendo? Veamos el comentario de Guido en (2013):\nfrom enum import Enum\r\rclass Color(Enum):\r red = 1\r green = 2\r blue = 3\r\rclass MoreColor(Color): # this is not possible as we\u0026#39;ve seen\r cyan = 4\r magenta = 5\r yellow = 6\r\rtype(MoreColor.red) is Color\r\rtype(MoreColor.red) is not MoreColor\r\r#En otras palabras, mientras \u0026#39;red\u0026#39; es accesible en MoreColor\r#es realmente una instancia de Color?\r\r#Vaya, esto es un caos. No queremos que MoreColor.red y\r#Color.red sean objetos diferentes, pero usando isinstance() check\r#parece confuso.\r\r#not isinstance(Color.red, MoreColor)\r#isinstance(MoreColor.yellow, Color)\rEn algunas versiones de Python, esto funciona sin mostrar un mensaje de error, pero es un comportamiento no deseado.\nclass Color(Enum):\r red = 1\r green = 2\r blue = 3\r\rclass MoreColor(Enum, Color):\r cyan = 4\r magenta = 5\r yellow = 6\rUno podría argumentar que las enumeraciones existen para garantizar la exclusión mutua sobre un conjunto finito no ordenado. Agregar miembros adicionales a una enumeración existente no viola esta garantía. Por lo tanto, si estás seguro de tu caso de uso y de lo que estás haciendo, es posible crear una solución alternativa. Una solución limpia utilizando un decorador es:\nfrom enum import Enum\rfrom typing import Any, Callable\r\rclass EnumBase(Enum):\r def __eq__(self, other: Any) -\u0026gt; bool:\r if isinstance(other, Enum):\r return self.value == other.value\r return False\r \rdef extend_enum(parent_enum: EnumBase) -\u0026gt; Callable[[EnumBase], EnumBase]:\r \u0026quot;\u0026quot;\u0026quot;Decorator function that extends an enum class with values from another enum class.\u0026quot;\u0026quot;\u0026quot;\r def wrapper(extended_enum: EnumBase) -\u0026gt; EnumBase:\r joined = {}\r for item in parent_enum:\r joined[item.name] = item.value\r for item in extended_enum:\r joined[item.name] = item.value\r return EnumBase(extended_enum.__name__, joined)\r return wrapper\rclass Parent(EnumBase):\r A = 1\r B = 2\r \r@extend_enum(Parent)\rclass ExtendedParent(EnumBase):\r C = 3\r \rprint(\rtype(Parent.A) is Parent,\rtype(Parent.A) is not ExtendedParent,\rParent.A == ExtendedParent.A\r)\r## True True True\rPero esta no es una solución perfecta, ya que tiene algunas desventajas o limitaciones de las que debes ser consciente. En este caso, un Enum no relacionado (llamado RandomEnum) que implementa el mismo valor de enumeración es igual en la comparación con nuestras clases Parent y ExtendedParent:\n\rclass RandomEnum(EnumBase):\r A = 1\r \rParent.A == RandomEnum.A == ExtendedParent.A\r## True\r\nMantente actualizado en consejos de Pydantic y Python\rEsperamos que esta publicación te haya ayudado a familiarizarte con el uso de Enum en Pydantic y te haya permitido disfrutar de una presentación de algunas de sus funcionalidades.\nSi deseas mantenerte actualizado…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python y Pydantic! \r\r\r\r\r\r\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1664928000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1664928000,"objectID":"5acf2ff67724e787aef3c8f601c950a2","permalink":"/es/post/pydantic-enum-intenum/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/es/post/pydantic-enum-intenum/","section":"post","summary":"Dominando Pydantic, Enums e IntEnums para aplicaciones Python robustas. Fusiona el poder de las validaciones de datos de Pydantic y el concepto de Enum, IntEnum y StrEnum.","tags":["Python","Pydantic"],"title":"Pydantic, Enums e IntEnums. Una historia de validación","type":"post"},{"authors":["Carlos Vecina"],"categories":["Python","Post"],"content":"\r\rpre  code.sourceCode { white-space: pre; position: relative; }\rpre  code.sourceCode  span { display: inline-block; line-height: 1.25; }\rpre  code.sourceCode  span:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode  span { color: inherit; text-decoration: inherit; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rpre  code.sourceCode { white-space: pre-wrap; }\rpre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; }\r}\rpre.numberSource code\r{ counter-reset: source-line 0; }\rpre.numberSource code  span\r{ position: relative; left: -4em; counter-increment: source-line; }\rpre.numberSource code  span  a:first-child::before\r{ content: counter(source-line);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ }\r@media screen {\rpre  code.sourceCode  span  a:first-child::before { text-decoration: underline; }\r}\rcode span.al { color: #ff0000; font-weight: bold; } /* Alert */\rcode span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #7d9029; } /* Attribute */\rcode span.bn { color: #40a070; } /* BaseN */\rcode span.bu { color: #008000; } /* BuiltIn */\rcode span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4070a0; } /* Char */\rcode span.cn { color: #880000; } /* Constant */\rcode span.co { color: #60a0b0; font-style: italic; } /* Comment */\rcode span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #ba2121; font-style: italic; } /* Documentation */\rcode span.dt { color: #902000; } /* DataType */\rcode span.dv { color: #40a070; } /* DecVal */\rcode span.er { color: #ff0000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #40a070; } /* Float */\rcode span.fu { color: #06287e; } /* Function */\rcode span.im { color: #008000; font-weight: bold; } /* Import */\rcode span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #007020; font-weight: bold; } /* Keyword */\rcode span.op { color: #666666; } /* Operator */\rcode span.ot { color: #007020; } /* Other */\rcode span.pp { color: #bc7a00; } /* Preprocessor */\rcode span.sc { color: #4070a0; } /* SpecialChar */\rcode span.ss { color: #bb6688; } /* SpecialString */\rcode span.st { color: #4070a0; } /* String */\rcode span.va { color: #19177c; } /* Variable */\rcode span.vs { color: #4070a0; } /* VerbatimString */\rcode span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\r\r¿Qué es un Enum y su integración con Pydantic?\r¡Oh, esta es una gran pregunta! ¡Nunca la había escuchado antes! Un Enum, para los no iniciados, es una característica ingeniosa que, cuando se combina con la biblioteca Pydantic, te ayuda a controlar el caos de la jungla de datos. Es una combinación del Enum de Python (abreviatura de enumeración) y el poder de validación de Pydantic. Los Enums te permiten definir un conjunto de valores con nombres a los que tus datos deben adherirse. Pydantic luego verifica si tus datos son parte de este club exclusivo y, si no lo son, amablemente les muestra la puerta de salida.\n\n¿Cómo me ayudan Pydantic y Enum?\rSi alguna vez has trabajado con datos, sabes que tienen voluntad propia. A veces son impecables y perfectos. En otras ocasiones, son un desastre total. Los Enums están aquí para salvarte de esos días en los que tus datos deciden actuar por su cuenta.\nAl definir Enums y utilizarlos en tus modelos de Pydantic, creas un conjunto de reglas que tus datos deben seguir, como un profesor estricto pero justo. De esta manera, puedes asegurarte de que solo datos válidos entren en tu sistema y que cualquier valor atípico se maneje adecuadamente.\nfrom enum import Enum\rfrom pydantic import BaseModel, ValidationError\r\rclass Pet(BaseModel):\r name: str\r animal_type: str\r sex: str\r \rPuedes ser más específico al definir tus modelos de Pydantic utilizando Enums:\nfrom pydantic import ValidationError\r\rclass Sex(Enum):\r MALE = \u0026#39;male\u0026#39;\r FEMALE = \u0026#39;female\u0026#39;\r \rclass DomesticAnimals(Enum):\r CAT = \u0026#39;cat\u0026#39;\r DOG = \u0026#39;dog\u0026#39;\r FISH = \u0026#39;fish\u0026#39;\r BIRD = \u0026#39;bird\u0026#39;\r\r# And then\r\rclass Pet(BaseModel):\r name: str\r animal_type: DomesticAnimals\r sex: Sex\r \rPet(name=\u0026#39;Timmy\u0026#39;, animal_type=\u0026#39;bird\u0026#39;, sex=\u0026#39;male\u0026#39;)\r## Pet(name=\u0026#39;Timmy\u0026#39;, animal_type=\u0026lt;DomesticAnimals.BIRD: \u0026#39;bird\u0026#39;\u0026gt;, sex=\u0026lt;Sex.MALE: \u0026#39;male\u0026#39;\u0026gt;)\rAgregar un valor que no existe (por ejemplo, “Tigre”, que no está permitido en animales domésticos) a un Enum existente generará un error el valor no es un miembro de la enumeración válido. Este es uno de los principales casos de uso para ellos.\nimport pytest\r\rwith pytest.raises(ValidationError, match=\u0026#39; value is not a valid enumeration member\u0026#39;) as e_info:\r Pet(\r name=\u0026#39;Timmy\u0026#39;, \r animal_type=\u0026#39;tiger\u0026#39;, \r sex=\u0026#39;male\u0026#39;\r )\rprint(e_info.value)\r## 1 validation error for Pet\r## animal_type\r## value is not a valid enumeration member; permitted: \u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;fish\u0026#39;, \u0026#39;bird\u0026#39; (type=type_error.enum; enum_values=[\u0026lt;DomesticAnimals.CAT: \u0026#39;cat\u0026#39;\u0026gt;, \u0026lt;DomesticAnimals.DOG: \u0026#39;dog\u0026#39;\u0026gt;, \u0026lt;DomesticAnimals.FISH: \u0026#39;fish\u0026#39;\u0026gt;, \u0026lt;DomesticAnimals.BIRD: \u0026#39;bird\u0026#39;\u0026gt;])\r(*Note the UPPER_CASE_NOTATION)\n\n\r¿Y qué hay de IntEnum? ¿Cuál es la diferencia entre Enum e IntEnum?\rEn resumen, la principal diferencia entre Enum e IntEnum radica en el tipo de valores que representan. Enum es una clase de enumeración genérica que puede utilizarse con cualquier tipo de datos, mientras que IntEnum está específicamente diseñado para valores enteros y permite la comparación directa con enteros.\nExisten dos beneficios principales al utilizar IntEnums en los casos de uso correctos:\n\rDado que IntEnum garantiza que todos los miembros de la enumeración tienen un valor entero, es posible ordenarlos.\rLos miembros de IntEnum pueden compararse directamente con enteros, mientras que los miembros de Enum no pueden utilizarse en operadores de comparación de enteros.\r\rfrom enum import IntEnum\rimport pytest\r\rclass ResponseCode(IntEnum):\r OK = 200\r NOT_FOUND = 404\r ERROR = 500\r \rassert ResponseCode.OK == 200\rassert ResponseCode.OK \u0026lt;= ResponseCode.NOT_FOUND\r\rwith pytest.raises(TypeError, match=\u0026#39;cannot extend enumeration\u0026#39;) as e_info: # Check that a TypeError is raised\r class ExtendedResponseCode(ResponseCode):\r CUSTOM = 300\rprint(e_info.value)\r## ExtendedResponseCode: cannot extend enumeration \u0026#39;ResponseCode\u0026#39;\r\n\r\r¿Es posible crear una subclase de un Enum (o un StrEnum / IntEnum)?\rNo se supone que sea posible. Si intentas hacerlo mediante la herencia directa, es posible que se genere un TypeError. Para explicarlo, la documentación dice: “Permitir la creación de subclases de enums que definen miembros llevaría a una violación de algunas invariantes importantes de tipos e instancias.”\n¿Qué estaríamos infringiendo? Veamos el comentario de Guido en (2013):\nfrom enum import Enum\r\rclass Color(Enum):\r red = 1\r green = 2\r blue = 3\r\rclass MoreColor(Color): # this is not possible as we\u0026#39;ve seen\r cyan = 4\r magenta = 5\r yellow = 6\r\rtype(MoreColor.red) is Color\r\rtype(MoreColor.red) is not MoreColor\r\r#En otras palabras, mientras \u0026#39;red\u0026#39; es accesible en MoreColor\r#es realmente una instancia de Color?\r\r#Vaya, esto es un caos. No queremos que MoreColor.red y\r#Color.red sean objetos diferentes, pero usando isinstance() check\r#parece confuso.\r\r#not isinstance(Color.red, MoreColor)\r#isinstance(MoreColor.yellow, Color)\rEn algunas versiones de Python, esto funciona sin mostrar un mensaje de error, pero es un comportamiento no deseado.\nclass Color(Enum):\r red = 1\r green = 2\r blue = 3\r\rclass MoreColor(Enum, Color):\r cyan = 4\r magenta = 5\r yellow = 6\rUno podría argumentar que las enumeraciones existen para garantizar la exclusión mutua sobre un conjunto finito no ordenado. Agregar miembros adicionales a una enumeración existente no viola esta garantía. Por lo tanto, si estás seguro de tu caso de uso y de lo que estás haciendo, es posible crear una solución alternativa. Una solución limpia utilizando un decorador es:\nfrom enum import Enum\rfrom typing import Any, Callable\r\rclass EnumBase(Enum):\r def __eq__(self, other: Any) -\u0026gt; bool:\r if isinstance(other, Enum):\r return self.value == other.value\r return False\r \rdef extend_enum(parent_enum: EnumBase) -\u0026gt; Callable[[EnumBase], EnumBase]:\r \u0026quot;\u0026quot;\u0026quot;Decorator function that extends an enum class with values from another enum class.\u0026quot;\u0026quot;\u0026quot;\r def wrapper(extended_enum: EnumBase) -\u0026gt; EnumBase:\r joined = {}\r for item in parent_enum:\r joined[item.name] = item.value\r for item in extended_enum:\r joined[item.name] = item.value\r return EnumBase(extended_enum.__name__, joined)\r return wrapper\rclass Parent(EnumBase):\r A = 1\r B = 2\r \r@extend_enum(Parent)\rclass ExtendedParent(EnumBase):\r C = 3\r \rprint(\rtype(Parent.A) is Parent,\rtype(Parent.A) is not ExtendedParent,\rParent.A == ExtendedParent.A\r)\r## True True True\rPero esta no es una solución perfecta, ya que tiene algunas desventajas o limitaciones de las que debes ser consciente. En este caso, un Enum no relacionado (llamado RandomEnum) que implementa el mismo valor de enumeración es igual en la comparación con nuestras clases Parent y ExtendedParent:\n\rclass RandomEnum(EnumBase):\r A = 1\r \rParent.A == RandomEnum.A == ExtendedParent.A\r## True\r\nMantente actualizado en consejos de Pydantic y Python\rEsperamos que esta publicación te haya ayudado a familiarizarte con el uso de Enum en Pydantic y te haya permitido disfrutar de una presentación de algunas de sus funcionalidades.\nSi deseas mantenerte actualizado…\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python y Pydantic! \r\r\r\r\r\r\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\r.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#2e8516;font-weight:bold}.hljs-comment, .hljs-quote {\rcolor: #0e847b;\rfont-style: italic;\r}.hljs-number, .hljs-literal, .hljs-variable, .hljs-template-variable, .hljs-tag .hljs-attr {\rcolor: #008021;\r}\r\r\r\r","date":1664928000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1664928000,"objectID":"cac4f398a27129361f9465c4a83aa153","permalink":"/es/post/pydantic-enum-intenum/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/es/post/pydantic-enum-intenum/","section":"post","summary":"Dominando Pydantic, Enums e IntEnums para aplicaciones Python robustas. Fusiona el poder de las validaciones de datos de Pydantic y el concepto de Enum, IntEnum y StrEnum.","tags":["Python","Pydantic"],"title":"Pydantic, Enums e IntEnums. Una historia de validación","type":"post"},{"authors":["Carlos Vecina"],"categories":["R","Post"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\n1. Descarga de datos\rComo siempre, comenzamos accediendo a los datos. En este caso, accedemos a la base de datos de Eurostat y nos descargamos el fichero.\nlibrary(tidyverse)\rdownload.file(\u0026quot;https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data/LFSA_EHOMP/?format=SDMX-CSV\u0026amp;compressed=false\u0026quot;, \u0026quot;data.csv\u0026quot;)\rEn un primer análisis, vamos a ver cual es el TOP 5 de paises en los que los empleados tienen algún tipo de modalidad remota.\ndf_european_data \u0026lt;-read_csv(file = \u0026#39;data.csv\u0026#39;,\rcol_types = cols(sex = col_character())) #Especificamos el tipo de la columna sexo\r\rdf_european_data_filtered \u0026lt;-df_european_data %\u0026gt;%\rfilter(freq ==\u0026quot;A\u0026quot; \u0026amp;unit ==\u0026quot;PC\u0026quot; \u0026amp;wstatus ==\u0026quot;EMP\u0026quot; \u0026amp;sex ==\u0026quot;T\u0026quot; \u0026amp;age ==\u0026quot;Y20-64\u0026quot; \u0026amp;geo !=\u0026quot;SE\u0026quot;) %\u0026gt;%\rselect(geo, TIME_PERIOD, OBS_VALUE, frequenc) %\u0026gt;%\rrename(remote_perc=OBS_VALUE,\rcountry=geo)\r\rdf_european_data_filtered %\u0026gt;%\rfilter(frequenc ==\u0026quot;NVR\u0026quot;) %\u0026gt;%\rmutate(remote_perc=if_else(frequenc ==\u0026quot;NVR\u0026quot;,\rround(1-remote_perc/100, 3)*100,\rround(remote_perc/100, 3)*100)) %\u0026gt;%\rselect(-frequenc) %\u0026gt;%\rarrange(country, TIME_PERIOD) %\u0026gt;%\rfilter(TIME_PERIOD ==\u0026quot;2020\u0026quot;) %\u0026gt;%\rslice_max(n=6, order_by=remote_perc) %\u0026gt;%\rkable()\r\r\r\rcountry\r\rTIME_PERIOD\r\rremote_perc\r\r\r\r\r\rLU\r\r2020\r\r47.8\r\r\r\rNL\r\r2020\r\r42.7\r\r\r\rCH\r\r2020\r\r41.5\r\r\r\rFI\r\r2020\r\r40.4\r\r\r\rIS\r\r2020\r\r39.8\r\r\r\rDK\r\r2020\r\r36.9\r\r\r\r\r\ndf_european_data_filtered_bar_plot \u0026lt;-df_european_data_filtered %\u0026gt;%\rfilter(frequenc ==\u0026quot;NVR\u0026quot; \u0026amp;TIME_PERIOD ==\u0026quot;2020\u0026quot;) %\u0026gt;%\rmutate(highlight = if_else(country ==\u0026quot;EU27_2020\u0026quot;,\u0026quot;t\u0026quot;,\u0026quot;f\u0026quot;),\rremote_perc = if_else(frequenc ==\u0026quot;NVR\u0026quot;,\rround(1-remote_perc/100,3),\rround(remote_perc/100,3))) %\u0026gt;%\rarrange(remote_perc) \rdf_european_data_filtered_bar_plot %\u0026gt;%\rggplot(aes(country, remote_perc, fill=highlight)) +\rgeom_bar(stat=\u0026quot;identity\u0026quot;, position=\u0026quot;dodge\u0026quot;) +\rgeom_text(aes(label=paste0(remote_perc*100,\u0026quot;%\u0026quot;)), size=2) +\rcoord_flip() +\rscale_x_discrete(limits=df_european_data_filtered_bar_plot$country) +\rscale_fill_manual(values=c( \u0026quot;t\u0026quot;=\u0026quot;tomato\u0026quot;, \u0026quot;f\u0026quot;=\u0026quot;paleturquoise3\u0026quot; ),\rguide=FALSE) +\rscale_y_continuous(labels=scales::percent) +\rlabs(title=\u0026quot;Porcentaje de empleados con alguna modalidad de teletrabajo por País\u0026quot;,\rcaption = \u0026quot;Fuente: Eurostat\u0026quot;)\r¿Y los 10 que mayor incremento han tenido?\ndf_european_data_filtered %\u0026gt;%\rfilter(frequenc ==\u0026quot;NVR\u0026quot;) %\u0026gt;%\rmutate( remote_perc = if_else(frequenc ==\u0026quot;NVR\u0026quot;,\rround(1-remote_perc/100,3)*100,\rround(remote_perc/100,3)*100)) %\u0026gt;%\rselect(-frequenc) %\u0026gt;%\rarrange(country, TIME_PERIOD) %\u0026gt;%\rgroup_by(country) %\u0026gt;%\rmutate(delta = (remote_perc -lag(remote_perc))/lag(remote_perc)*100) %\u0026gt;%\rungroup() %\u0026gt;%\rfilter(TIME_PERIOD==\u0026quot;2020\u0026quot;) %\u0026gt;%\rslice_max( n=10,order_by=delta) %\u0026gt;%\rkable()\r\r\r\rcountry\r\rTIME_PERIOD\r\rremote_perc\r\rdelta\r\r\r\r\r\rCY\r\r2020\r\r7.4\r\r196.00000\r\r\r\rIT\r\r2020\r\r13.7\r\r191.48936\r\r\r\rBG\r\r2020\r\r3.0\r\r172.72727\r\r\r\rHU\r\r2020\r\r11.0\r\r139.13043\r\r\r\rRO\r\r2020\r\r3.2\r\r128.57143\r\r\r\rMT\r\r2020\r\r26.0\r\r122.22222\r\r\r\rEL\r\r2020\r\r10.4\r\r100.00000\r\r\r\rLT\r\r2020\r\r8.4\r\r86.66667\r\r\r\rES\r\r2020\r\r15.2\r\r80.95238\r\r\r\rDE\r\r2020\r\r21.1\r\r63.56589\r\r\r\r\r\n\r2. Perfil del Teletrabajo alrededor de Europa\r(Normalmente vs En ocasiones vs Nunca)\rUna forma visual de hacernos una idea de la adopción de las diferentes modalidades de teletrabajo en cada uno de los mercados europeos de un solo vistazo puede ser esta donut plot. Si bien el cerebro humano y la visión no está preparado con una elevada facilidad de comparar áreas, sí que nos permitirá ver muchos perfiles de paises y poder comprender la estructura de su mercado laboral en cuanto a la adopción del remote working.\nlist_countries \u0026lt;-c(\u0026quot;AT\u0026quot;,\u0026quot;BE\u0026quot;,\u0026quot;CH\u0026quot;,\u0026quot;CY\u0026quot;,\u0026quot;CZ\u0026quot;,\r\u0026quot;DE\u0026quot;,\u0026quot;DK\u0026quot;,\u0026quot;ES\u0026quot;,\u0026quot;EU15\u0026quot;,\u0026quot;EU27_2020\u0026quot;,\u0026quot;FI\u0026quot;,\r\u0026quot;FR\u0026quot;,\u0026quot;IS\u0026quot;,\u0026quot;IT\u0026quot;,\u0026quot;LU\u0026quot;,\u0026quot;MK\u0026quot;,\r\u0026quot;NL\u0026quot;,\u0026quot;NO\u0026quot;,\u0026quot;PL\u0026quot;,\u0026quot;PT\u0026quot;,\u0026quot;SK\u0026quot;)\rggplot(df_european_data_filtered %\u0026gt;%\rfilter(TIME_PERIOD==\u0026quot;2020\u0026quot; \u0026amp;(country %in%list_countries )) %\u0026gt;%\rgroup_by(country) %\u0026gt;%\rmutate(ymax=cumsum(remote_perc),\rymin=if_else(row_number()==1,0,lag(ymax)),\rlabelPosition=(ymax+ymin)/2,\rlabel=paste0(remote_perc, \u0026quot; %\u0026quot;),\rfrequenc=if_else(frequenc==\u0026quot;NVR\u0026quot;,\u0026quot;NUNCA\u0026quot;,\rif_else(frequenc==\u0026quot;SMT\u0026quot;, \u0026quot;OCASIONAL\u0026quot;, \u0026quot;SIEMPRE\u0026quot;))) %\u0026gt;%\rrename(freq=frequenc),\raes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=freq)) +\rgeom_rect() +\rgeom_text(x=1.5,\raes(y=labelPosition, label=label, color=freq),\rsize=2.2,\rcheck_overlap = T)+\rscale_fill_brewer(palette=3) +# color del rosco\rscale_color_brewer(palette=3) +# color de las etiquetas\rfacet_wrap(~country) +\rcoord_polar(theta=\u0026quot;y\u0026quot;) +\rtheme_void() +\rxlim(c(-1, 4)) +\rlabs(title=\u0026quot;Composición teletrabajo por país\u0026quot;,\rsubtitle=\u0026quot; \u0026quot;,\rcaption = \u0026quot;Fuente: Eurostat\u0026quot;)\r\rEvolución temporal del trabajo remoto\rPara dar contexto, podemos ver la evolución temporal del porcentaje de trabajadores que en algún grado disfrutan de trabajo en remoto. Vemos que aquí también hay grupos de paises. En algunos de estos paises se aprecia una pendiente muy pronunciada, mientras que en otro grupo de ellos no han registrado una subida tan acelerada el último año.\ndf_european_data_filtered %\u0026gt;%\rfilter(frequenc ==\u0026quot;NVR\u0026quot; \u0026amp;(country %in%list_countries[list_countries !=\u0026quot;CY\u0026quot;])) %\u0026gt;%\rmutate( remote_perc = if_else( frequenc ==\u0026quot;NVR\u0026quot;,round(1-remote_perc/100,3),round(remote_perc/100,3))) %\u0026gt;%\rggplot(aes(TIME_PERIOD, remote_perc, colour=remote_perc, group=country)) +\rgeom_line() +\rfacet_wrap(~country) +\rscale_colour_gradient(low = \u0026quot;yellow\u0026quot;, high = \u0026quot;red\u0026quot;, na.value = NA)+\rscale_y_continuous(labels=scales::percent)\r\n\r3. Correlación Trabajo Remoto ~ PIB país\rComo reflexión final, parece evidente que atendiendo al PIB país, el porcentaje de teletrabajadores que al menos trabajan de manera ocasional en remoto en base al grueso de los empleados del mercado laboral tiene una correlación positiva grande.\nLa composición del tejido industrial y del tipo de empresas de cada uno de los paises, unido a las diferentes políticas y gobierno que hay en ellos, parecen los factores que determinan la gran heterogeneidad entre Estados.\nEn el siguiente artículo profundizaremos sobre esta relación entre el PIB y el modelo de trabajo remoto, disertando sobre casusas y efectos.\nVersión en inglés del artículo en UbiWork. Work remotely from Spain \u0026amp; Portugal\n¡Comparte el post! Aquí:\n\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r\r\r","date":1623628800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1623628800,"objectID":"7687068517738242d3a627e33d769a99","permalink":"/es/post/data-visualization-remote-workers-across-europe/","publishdate":"2021-06-14T00:00:00Z","relpermalink":"/es/post/data-visualization-remote-workers-across-europe/","section":"post","summary":"Analizamos datos de Eurostat sobre la expansión del teletrabajo en los diferentes paises europeos. Finlandia, Luxemburgo, Paises Bajos y Alemania tienen más del 30% del total de los trabajadores del pais en alguna modalidad remota. ¡Sorprende Noruega!","tags":[],"title":"¿Cómo de extendido está el Teletrabajo en los paises de Europeos?","type":"post"},{"authors":["Pablo Cánovas"],"categories":["AB Testing","Statistics"],"content":"\rVale, en qué consisten los test A/B?\rUn test A/B es una técnica muy utilizada hoy en día en Marketing digital que consiste en llevar a cabo dos acciones diferentes en paralelo y comparar sus resultados. Por ejemplo, estos resultados pueden ser la tasa de conversión de una campaña de marketing (ventas, subscripciones…) o el número de clicks en un enlace respecto a impresiones (Click Through Rate). También es ampliamente utilizado fuera del ámbito del marketing, típicamente en áreas como la farmacología o la psicología.\nSupongamos que queremos impulsar las ventas de un producto o servicio y para ello hemos decidido usar un nuevo diseño web.\rDiseñaremos un experimento, llamado test A/B, mediante el cual seremos capaces de medir la influencia de nuestro cambio. Para ello, dividiremos a nuestros usuarios aleatoriamente en un grupo de control que verá la página como hasta ahora y otro sobre el que probaremos la variante llamado grupo experimental. Una vez llevada a cabo la prueba, compararemos los resultados entre los dos grupos de cualquiera que sea la métrica que estemos midiendo para tomar una decisión sobre qué diseño web utilizar.\nEl concepto más importante a recordar aquí es que al realizar el experimento sobre una muestra en lugar de hacerlo sobre toda la población, cualquier medida que tomemos tendrá asociada una incertidumbre que tenemos que tener en cuenta a la hora de interpretar los resultados. En nuestro caso, para cada visita solo podemos obtener dos resultados: el cliente compra o no, el usuario se suscribe o no, el usuario se marcha o no…en resumen, éxito o fracaso. Una variable aleatoria de este tipo se dice que sigue una distribución binomial.\n\rTipos de errores\rDe cara a diseñar el experimento, necesitamos entender primero la diferencia entre los dos tipos de error en los que podemos incurrir al evaluar los resultados del test. Vamos a suponer que ya hemos realizado el test y hemos obtenido resultados: para cada diseño propuesto hemos medido una tasa de conversión.\nEn primer lugar, una posibilidad es que la diferencia que hemos medido sea producto del azar: Supongamos que en realidad el nuevo diseño no aporta nada nuevo y no supone ningún aumento en el número de ventas, pero hemos tenido “buena suerte” a la hora de distribuir a los potenciales clientes en grupos (recordemos que este proceso lo hemos hecho al azar) y por pura casualidad hemos vendido más entre los clientes que han visto nuestra nueva web. Esto es lo que se conoce como error tipo I (normalmente llamado \\(\\alpha\\)). Es la probabilidad de alucinar y creer que nuestra variante funciona mejor cuando en realidad no lo hace.\nPor otro lado, a la hora de diseñar un test A/B también tenemos que tener en cuenta que podríamos cometer otro tipo de error, esta vez por omisión. Imaginemos que el equipo de marketing propone un diseño que sí funciona (y cuando digo que funciona me refiero a que si tuviera una bola de cristal vería que en realidad sí que funciona. Dicho de manera menos esotérica: si pudiéramos conseguir millones de visitas veríamos sin lugar a dudas que efectivamente conseguimos aumentar las ventas). Sin embargo, como no podemos esperar tanto tiempo para evaluar los resultados tendremos que sacar las conclusiones basándonos únicamente en los resultados de una muestra. Pero como en toda muestra, los resultados que obtengamos están sujetos de alguna manera al azar, a la “suerte” que tengamos al elegir a las personas que conforman los grupos. Esto implica que, cuando damos por terminado el experimento, podríamos llegar a que a través de ambas webs conseguimos convertir exactamente la misma proporción de ventas.\rEntonces, la pregunta del millón: ¿Estos resultados son significativos? ¿Entonces, el nuevo diseño no tiene absolutamente ningún efecto? ¿O, análogamente al caso anterior, podría ser que hubiéramos tenido mala suerte en la elección de los grupos y no estuviéramos viendo los efectos del nuevo diseño? Esto es lo que se conoce como error tipo II (\\(\\beta\\)): la probabilidad de no obtener resultados significativos cuando en realidad sí que existe diferencia entre los ratios de conversión de cada grupo.\n\rImagen sacada de Clearswift\r\r\rLa estadística\rDicho de manera más técnica, en inferencia estadística llamamos contraste de hipótesis al procedimiento seguido para evaluar si una propiedad de una población es compatible con la medida en una muestra.\rDefinimos la hipótesis nula \\(H_0\\) como la hipótesis que queremos contrastar, aquella de la que partimos y la que mantendremos si no reunimos evidencia de lo contrario. En contraposición, frecuentemente definimos la hipótesis alternativa de manera implícita como “\\(H_0\\) es falsa”.\n\rEl nivel de significancia estadística o nivel \\(\\alpha\\) es la probabilidad de rechazar la hipótesis nula cuando es cierta. Un nivel de confianza del 95% significa que, si repetiéramos el experimento muchas veces, el 95% de las veces que obtengamos resultados significativos será porque efectivamente la propuesta alternativa mejora el ratio de la propuesta de control, y solo un 5% de las veces obtendremos un falso positivo significativo.\r\\(\\beta\\) es la probabilidad de no rechazar la hipótesis nula cuando es falsa, aunque normalmente se suele hablar de potencia estadística (definida como 1 - \\(\\beta\\)), que es la probabilidad de rechazar la hipótesis nula cuando es falsa. Por ejemplo, planificar un experimento para que tenga una potencia del 80% implica que, si repetimos muchas veces la comparación del grupo de control con una variante que en realidad sí que mejora el ratio de venta, obtendremos resultados significativos el 80% de las veces. Es la potencia de la lupa, nuestra capacidad para distinguir con precisión las diferentes tasas de conversión de los dos grupos.\r\rCon todo lo explicado arriba, es fácil ver que a la hora de evaluar los resultados del test podemos tener cuatro casos diferentes:\r* a) Verdadero positivo: que los resultados nos indiquen que la variante ha sido un éxito y realmente, si pudiéramos hacer el experimento con toda la población, veríamos que efectivamente el nuevo diseño lleva a una mejor tasa de conversión.\r* b) Verdadero negativo: que los resultados nos indiquen que la variante no produce ningún cambio y efectivamente sea así.\r* c) Falso positivo (error tipo I): que los resultados nos indiquen que la variante ha sido un éxito, pero en realidad este resultado se deba simplemente al azar.\r* d) Falso negativo (error tipo II): que los resultados nos indiquen que la variante no produce ningún cambio, pero en realidad sí que lo produce y lo que ocurre es que no hemos obtenido suficiente muestra.\n\rImagen de Wikipedia\r\r\rTamaño muestral\r¿Qué papel juega el tamaño muestral en un test A/B? Cuanta más muestra, menos incertidumbre.\rLa fórmula con la que podemos calcular la incertidumbre asociada a una medición es la siguiente:\n\\[ \\hat{p} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\]\nsiendo \\(\\hat{p}\\) la proporción observada, z el Z-Score y n el tamaño muestral. El Z-score de una medida nos indica dónde se ubica ésta en la distribución, es decir, cómo de lejos en número de desviaciones estándar está esa medida de la media.\nUna cuestión habitual a la hora de diseñar un test A/B es: ¿Qué tamaño muestral necesito?\rPara encontrar la muestra necesaria para nuestro experimento podemos usar la función de R power.prop.test que acepta como argumentos el tamaño muestral, las tasas de éxito de nuestros grupos, la significancia y la potencia estadística. De ellos, dados cuatro nos dará el quinto. De esta manera se convierte en la herramienta perfecta para diseñar un test estadístico de este tipo: Podemos encontrar qué tamaño muestral nos permitiría observar cierto efecto dadas unas tolerancias determinadas al error, o encontrar qué potencia estadística tendrá un test con una diferencia entre ratios y un tamaño muestral dados.\rCon esta herramienta llegamos a otro concepto importante: Definimos el MED (del inglés Minimum Detectable Effect) como el mínimo efecto significativo que podremos detectar dado un tamaño muestral y unas condiciones dadas de significancia. Este concepto deja intuir otra idea quizá implícita pero sencilla de entender: Para poder ser capaces de distinguir mejoras pequeñas de rendimiento deberemos tener una muestra suficientemente grande, pues si no, es fácil que cometamos un error de tipo II (que la mejora exista pero no seamos capaces de verla).\nDados los cuatro posibles escenarios anteriores, diseñaremos adecuadamente el test teniendo en cuenta las consecuencias de los distintos errores. ¿Cuáles son las consecuencias de concluir que la nueva campaña de marketing funciona mejor que la anterior? ¿Cuáles son las consecuencias de tomar la decisión de desechar la nueva y efectiva campaña porque no hemos obtenido resultados concluyentes debido al tamaño insuficiente de la muestra?\rEste tipo de preguntas son las que debemos de respondernos a la hora de calibrar la tolerancia que tenemos a los errores \\(\\alpha\\) y \\(\\beta\\). Y para esto no hay una única respuesta válida. Normalmente dependerá de los riesgos que estemos dispuestos a correr y las consecuencias de cada tipo de error: No es lo mismo vivir engañado pensando que tu nueva campaña de marketing aumentará las ventas un 10% que concluir y publicar en una revista científica que has encontrado la cura del cáncer cuando lo único que estás viendo en tus datos es ruído estadístico y has sido engañado por el azar. Por tanto, estos parámetros son específicos del dominio en el que trabajamos.\n\rSon mis resultados significativos?\rPor último, una vez establecida la confianza requerida, dimensionado adecuadamente el experimento y recogidos los datos, la pregunta que intentamos resolver ahora es: ¿Cómo de probable es que hayamos obtenido resultados positivos por pura casualidad, y que realmente los ratios de conversión de ambos grupos sea idéntica, pero hemos tenido malísima suerte en las medidas?\nPara saber si hemos obtenido un resultado estadísticamente significativo podemos realizar un test de hipótesis con la función de R prop.test.\rAdemás, desarrollé una shiny app que nos permite realizar ese cálculo sin usar R.\rEl concepto importante aquí es el p-valor. Supongamos que hemos obtenido que nuestra variante lleva el ratio de conversión del 5% al 8%. ¿Es una mejora significativa? Para responder a la pregunta nos apoyamos en un test estadístico llamado Z-test que, dados los ratios y los tamaños muestrales de cada grupo nos dará la probabilidad de haber obtenido un resultado tan extremo o más por puro azar, suponiendo que en realidad no hay ninguna diferencia entre nuestra variante y el grupo de control. Esa probabilidad es el p-valor.\rÚnicamente falta comparar el p-valor obtenido con nuestra tolerancia máxima al error de tipo I (\\(\\alpha\\)) del que hemos hablado antes: Si el p-valor es menor que \\(\\alpha\\) rechazaremos la hipótesis nula, esto es, daremos nuestro resultado por significativo. En el caso contrario (p-value \u0026gt; \\(\\alpha\\)) no concluiremos que la variante no mejora, únicamente podremos decir que no hemos conseguido encontrar evidencias de que sí lo haga. Análogamente, en los juicios, cuando no se han encontrado pruebas de que el acusado sea culpable se usa el término no culpable ya que eso no quiere decir que sea inocente. Absence of evidence is not evidence of absence.\nDada la incertidumbre asociada a la propia medición, podemos visualizar la distribución de probabilidad de la tasa de conversión de cada grupo con un gráfico como el siguiente: dos distribuciones binomiales centradas en los valores medidos y cómo se relacionan gráficamente los principales conceptos discutidos en este artículo: \\(\\alpha\\), \\(\\beta\\) y p-valor.\n\rTipos de error, potencia y tamaño del efecto\r\rAdemás, he desarrollado una pequeña aplicación para saber si nuestros resultados son significativos o no, y aprender cómo se relacionan estos conceptos (Potencia estadística, errores \\(\\alpha\\) y \\(\\beta\\), tamaño muestral y tamaño del efecto). Échale un ojo!\n\r","date":1593302400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1593302400,"objectID":"36efb3e5a14570c30e0c218917f1c3cf","permalink":"/es/post/ab-testing/","publishdate":"2020-06-28T00:00:00Z","relpermalink":"/es/post/ab-testing/","section":"post","summary":"Entendiendo el p-valor, los tipos de error y la potencia estadística","tags":[],"title":"A/B Testing","type":"post"},{"authors":["Carlos Vecina"],"categories":["R","Post"],"content":"\r\r1. Preparar nuestra Shiny APP\r2. Levantar la máquina EC2 en AWS\r2.1 Intro \u0026amp; Launch Instance\r2.2 Configuración de la Instancia\r2.3 Generar la key\r\r3. Conexión a nuestra instancia.\r3.1 Descargar Putty\r3.2 Transformar la clave con PuttyGen\r3.3 Configurar la conexión\r\r4. Instalar R y Shiny Server en la máquina EC2 AWS\r5. Desplegar nuestra Shiny App\r\r\r1. Preparar nuestra Shiny APP\rEn primer lugar prepararemos la app de Shiny. Vamos a dejar la aplicación lista y preparada para ser desplegada en AWS.\rPara ello recomendamos:\n\rminimizar el número de librerias a instalar,\rcomenzar la app con una función del estilo LoadOrInstallRequiredPackages\rdespliega tu app en Github/GitLab\r\rComo veremos en breve, no es totalmente necesario tener la app en un repositorio, aunque sí altamente recomendable. Explicaremos una alternativa de transferencia de ficheros a la máquina de AWS.\n\r2. Levantar la máquina EC2 en AWS\r2.1 Intro \u0026amp; Launch Instance\rComo pincelada, comentar qe el servicio de EC2 dentro de la cloud de Amazon nos facilita instanciar máquinas virtuales con imágenes preconfiguradas.\nPara ello, lo primero que debemos hacer es crearnos una cuenta en AWS, si no la tenemos ya. Amazon nos permite el acceso a un Tier Gratuito con acceso a la gama baja de diferentes servicios, sin incurrir en coste alguno. Aun así, en el registro deberemos introducir una tarjeta como requisito, pero todo lo que explicaremos a continuación no tendrá coste alguno.\nAbre en una nueva pestaña https://portal.aws.amazon.com y comienza el proceso de alta.\n\rPlanes AWS\r\rSeleccionamos el Basic Plan, ya que nos permite desplegar de manera gratuíta el tiempo equivalente a tener 1 máquina levantada al mes. Una vez hayamos completado el registro, nos llevará a un portal donde tendremos acceso a todos los productos de AWS (EC2, S3, Lambda…)\nEn la barra de búsqueda, buscamos el servicio EC2. Haremos click en él como se muestra a continuación.\n\rSeleccionamos el servicio EC2\r\rEsto nos lleva a la home de EC2, donde deberemos buscar el botón de Launch instance\n\rLanzamos la instancia de EC2\r\r\r2.2 Configuración de la Instancia\rAhora debemos configurar la máquina que vamos a levantar. En primer lugar la AMI (Amazon Machine Image), que como comentábamos antes, es una preconfiguración de la máquina que nos permite agilizar el set up.\rEn esta ocasión elegiremos un Ubuntu 18.04.\n\rUbuntu 18.04 x86\r\rA continuación, debemos elegir las características de la máquina a desplegar, el instance type.\rPara poder hacer todo el proceso de manera gratuíta, elegimos la t2.micro ya que es la única que podremos levantar sin coste.\n\rEl free tier incluye una máquina t2.micro\r\r\r2.3 Generar la key\rEl último paso para tener nuestra instancia levantada es guardarnos la private key usada para conectarnos a la instancia de manera segura. Descargaremos un arcivo con extensión .pem, que usaremos posteriormente en para conectarnos y que no debemos perder.\n\rCreamos el key pair (o utilizamos una existente)\r\r\r\r3. Conexión a nuestra instancia.\rHasta este punto, ya tenemos nuestra instancia lanzada y será cuestión de minutos que pase de estado inizialiting a running.\nCuando la tengamos corriendo, ya podremos conectarnos a ella. ¿Cómo? A contunuación os mostramos cómo hacerlo desde Windows.\n3.1 Descargar Putty\rPutty es un cliente SSH que nos permite conectarnos desde Windows a estas máquinas EC2.\nhttps://www.putty.org/\nCon esto descargamos PuttyGen (que usaremos en primer lugar para transformar la key descargada de AWS) y el propio Putty (que usaremos para conectarnos)\n\r3.2 Transformar la clave con PuttyGen\rUna vez abierto PuttyGen, lo único que debemos hacer es clikear en Load y seleccionar la clave con extensión .pem.\nEn cuanto al tipo de clave a generar, bastará con dejarlo en RSA. Por último, hacer click en Save private key, aceptar a no generar una passphrase y asignarle un nombre, que puede ser el mismo que le pusimos a la descargada de AWS (automáticamente asigna una extensión .ppk).\n\rPutty Gen. Transformando la key descargada de AWS\r\r\r3.3 Configurar la conexión\rCerramos PuttyGen y abrimos Putty. Iremos Conection -\u0026gt; SSH -\u0026gt; Auth y cargarmos la clave ppk que acabamos de generar.\rVolvemos a Session e introducimos la IP. Podemos ponerle un nombre y darle a Save.\n\rCargamos la private key para la autenticación\r\r\rSeteamos la IP, Save \u0026amp; Open\r\rCon esto, sólo queda darle a Open y login como user: ubuntu.\nGot it!\n\r\r4. Instalar R y Shiny Server en la máquina EC2 AWS\rUna vez dentro, ejecutamos los siguientes comandos. Estamos configurando la máquina, descargando R, sus dependencias, Shiny, los paquetes necesarios y Shiny Server.\nsudo add-apt-repository \u0026#39;deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/\u0026#39;\rsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\rsudo apt-get update\rsudo apt-get install r-base sudo add-apt-repository ppa:marutter/c2d4u3.5\rsudo apt-get update\rsudo apt-get install -y gfortran libreadline6-dev libx11-dev libxt-dev libcairo2-dev libbz2-dev liblzma-dev libcurl4-openssl-dev cmake libssl-dev libxml2 libxml2-dev r-cran-httpuv\rsudo su - \\\r-c \u0026quot;R -e \\\u0026quot;install.packages(\u0026#39;shiny\u0026#39;, repos=\u0026#39;https://cran.rstudio.com/\u0026#39;)\\\u0026quot;\u0026quot;\r$ sudo apt-get install gdebi-core\r$ wget https://download3.rstudio.org/ubuntu-14.04/x86_64/shiny-server-1.5.13.944-amd64.deb\r$ sudo gdebi shiny-server-1.5.13.944-amd64.deb\rEn caso de que tu aplicación no comience checkeando los paquetes que se va a usar, en este paso utilizaremos\nsudo su -c \u0026quot;R -e \\\u0026quot;install.packages(\u0026#39;shiny\u0026#39;, repos=\u0026#39;https://cran.rstudio.com/\u0026#39;)\\\u0026quot;\u0026quot;\rCon esto, ya tenemos el Shiny Server escuchando en el puerto 3838. Pero aun no podremos acceder a http://ip_de_la_maquina_de_ec2:3838 ya que como último paso debemos de abrir este puerto en el firewall.\nPara ello iremos nuestras instancias:\n\rDentro del panel de instancias, scroll lateral a la derecha\r\rInstanctias -\u0026gt; Security Group -\u0026gt; Actions -\u0026gt; Edit inbound rules\n\rAñadimos nueva regla TCP, al puerto 3838 y para todas las IPs de origen\r\r\r5. Desplegar nuestra Shiny App\rCómo comentábamos, lo ideóneo sería tener nuestra aplicación en un repositorio.\nSi dominamos git, símplemente debemos clonar el repo en la ruta /srv/shiny-server. También lo podemos hacer en el root y crear un link dentro de esa ruta.\nAclarar que en esa ruta debe estar la carpeta contenedora conel nombre de la app, y la propia app de Shiny, ya sea en formato app.R o server.R/ui.R\nUn ejemplo sería el siguiente:\ncd /srv/shiny-server\rgit clone https://github.com/CarlosVecina/Proyecto-Multivariate-Distribution.git\r\rCon esto, ya tenemos nuestra app junto con la app de demo. Si entramos en http://3.133.94.92:383 llegaremos al root con todas las aplicaciones. Para acceder (y linkear/meter en un iframe…) a una app específica deberemos utilizar la url completa http://3.133.94.92:3838/Proyecto-Multivariate-Distribution\nUna segunda opción menos recomendable sería usar Winscp para transferir los archivos.\n\nEn el próximo post trataremos cómo acceder a nuestra aplicación de Shiny en AWS con tu url personal, convertirlo en una conexión https, configurar los puertos…\nKeep you posted en TypeThePipe\n\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r\r","date":1591920000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1591920000,"objectID":"ff096e609e04e764688b18132c77857c","permalink":"/es/post/despliega-r-shiny-app-aws-gratis-5minutos/","publishdate":"2020-06-12T00:00:00Z","relpermalink":"/es/post/despliega-r-shiny-app-aws-gratis-5minutos/","section":"post","summary":"¿Quieres compartir tu aplicación Shiny R? ¿Quieres evitar instalaciones en local o subirla a servidores gestionados por 3ros? Levanta tu máquina EC2 en AWS y despliga tu App gratis. Te enseñamos como hacerlo en 5 minutos.","tags":[],"title":"¡Despliega tu R Shiny App en AWS gratis y en 5 minutos!","type":"post"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r¿Quieres guardar tu modelo de DL o un gran dataset? A continuación te mostramos la manera que hemos encontrado de optimizar la lectura, la escritura y almacenaje de data frames con el paquete FST. Si incorporar un paquete a tu environment no te supone un gran problema, te lo recomendamos.\nEn la repo del paquete hay un pequeño benchmark reliazado por sus autores. Queremos comprobarlo por nosotros mismos y vamos a comparar su rendimiento. Para ello compararemos su performance con el de las funciones que hasta hoy eran parte de nuestra caja de herramientas de R para la lectura y escritura de ficheros en proyectos de datos. Veamos:\nlibrary(tidyverse)\rbig_dataset %\u0026gt;%nrow() # 700k filas, 15 columnas(8 factor, 4int, 3 logi)\rlibrary(microbenchmark)\rlibrary(readr)\rlibrary(fst)\r\rmicrobenchmark(\rwrite.csv(big_dataset, paste0(path,\u0026quot;big_dataset.csv\u0026quot;),), # utils\rwrite_csv(big_dataset, paste0(path,\u0026quot;big_dataset.csv\u0026quot;)), # readr\rwrite_csv(big_dataset, paste0(path,\u0026quot;big_dataset.csv.gz\u0026quot;),), # readr GZ\rsaveRDS(big_dataset, paste0(path,\u0026quot;big_dataset.RDS\u0026quot;)), # utils\rwrite_rds(big_dataset, paste0(path,\u0026quot;big_dataset.RDS\u0026quot;)), # readr\rwrite_fst(big_dataset, paste0(path,\u0026quot;big_dataset.fst\u0026quot;)), # fst\rtimes = 10\r)\r## Unit: milliseconds\r## min mean median max neval file_size\r##utils 10943.1161 11232.20073 11098.66610 12011.1538 10 109 MB\r##readr 3140.4450 3442.92772 3388.14280 3768.4109 10 109 MB\r##readrGZ 6993.8850 7332.31976 7260.95040 7946.9233 10 23 MB\r##base 4800.3516 5122.22345 5024.69395 5833.9807 10 15 MB\r##readr 187.0765 210.74584 211.70760 246.6369 10 46 MB\r\u0026quot;fst 60.3065 87.30611 74.94375 154.7718 10 16 MB\u0026quot;\r\n¡Wow! Los resultados son impresionantes, incluso mejores que los expuestos en la web de los creadores.\nPodemos apreciar una mejora x3 y x50 en el performance comparado con las funciones readr::write_rds() y base R saveRDS()!\nUna incremento increible de un x100 performance entre fst y las funciones que trabajan con csv y que anteriormente utilizábamos, aunque realmente esta no es una comparación del todo justa al tratarse de dos extensiones completamente diferentes (csv y bin).\n\n¿Y tú? ¿Estás pensando en incluir FST al toolbox de tu proyecto en R también?\n\n\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1585526400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1585526400,"objectID":"47042577d83d1a66448bdb71a4e9ba2c","permalink":"/es/vizs-and-tips/aumenta-velocidad-scripts-r-lectura-escritura-fst-r/","publishdate":"2020-03-30T00:00:00Z","relpermalink":"/es/vizs-and-tips/aumenta-velocidad-scripts-r-lectura-escritura-fst-r/","section":"vizs-and-tips","summary":"Velocidad imbatida y almacenaje óptimo, Es FST! x100 más rápido que write.csv()","tags":[],"title":"¡Aumenta la velocidad de tus scripts de R!. Optimiza la lectura, escritura y almacenamiento de grandes datasets con el paquete FST","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rLos NAs pueden ser muy informativos, y estudiar cómo se distribuyen en base a una segunda variable suele ser una genial idea. Esto puede aportarnos un extra de información o mostrarnos un fenómeno que de otra manera(mediante imputación o descarte de observaciones) nos pasaría desapercibido.\nSin embargo, para un estudio preliminar o tras haber analizado los valores faltantes, nos encontramos casos en los que queremos quitarlos de manera automatizada basándonos en el porcentaje de NAs.\nEn este artículo hablamos y comparamos diferentes funciones de BaseR vs Tidy \u0026amp; Purrr para contar el número de NAs por columna.\n¿Cuanto cuesta no salir del pipeflow? Dependerá del número de variables, del porcentaje que elijas como frontera y la distribución de NAs a lo largo de las variables, pero no suele ser más que unos pocos nanosegundos.\n# library(microbenchmark) Puedes comparar su performance en diferentes datasets\rlibrary(tidyverse)\r\rairquality %\u0026gt;%select_if(~mean(is.na(.)) \u0026lt;0.2)\r\rairquality %\u0026gt;%select(which(colMeans(is.na(.)) \u0026lt;0.2))\r\rairquality[lapply(airquality, function(x) mean(is.na(x))) \u0026lt;0.2]\r¿Qué forma eliges tú?\n\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1584921600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1584921600,"objectID":"671bdec4cc134f7c78ea6c8e25a19607","permalink":"/es/vizs-and-tips/descartando-columnas-porcentaje-nas-r-tidyverse/","publishdate":"2020-03-23T00:00:00Z","relpermalink":"/es/vizs-and-tips/descartando-columnas-porcentaje-nas-r-tidyverse/","section":"vizs-and-tips","summary":"¿Qué manera utilizas tú?","tags":[],"title":"Descartando columnas basándonos en su porcentaje de NAs","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Post"],"content":"\r\r\r¿Qué es un Datathon?\r¿Qúe es Kaggle?\r1. Establece tu objetivo y revisa los recursos (habilidades, tiempo, acceso a máquinas…) con los que cuentas.\r2. Elección del tema o CdUso.\r3. Construye tu equipo de manera consciente. Usa herramientas para compartir código/archivos.\r4. Investigación previa y profunda sobre el caso de uso en concreto.\r5. Análisis exploratorio de los datos. Recuerda que (normalmente) no son los únicos que puedes usar.\r6. Establecer la estructura del proyecto y del código.\r7. Lanzar los primeros modelos.\r8. Validación cruzada, OOS y backtesting.\r9. Interpretabilidad de modelos. Evaluación de resultados desde el punto de vista práctico y/o negocio.\r10. Escribir una memoria con puntos fuertes y puntos a mejorar detectados, que te sirvan de partida en el próximo reto.\r\r\r¿Pensando en inscribirte en un Datathon o competición de datos? ¡En este post os traemos 10 consejos sobre los puntos clave para conseguir grandes resultados!\n¿Qué es un Datathon?\rEmpecemos por el principio, ¿sabes que es exactamente un Datahon? Un Datathon es una competición donde varias personas o equipos compiten para conseguir el mejor resultado a un reto propuesto. Suele ser basada en manejos de datos y algoritmia, y se suele tratar de minimizar una métrica de error\n¿Sabes cuál es la mayor plataforma para este tipo de competiciones de datos? Pues seguramente sea Kaggle.\n\r¿Qúe es Kaggle?\rKaggle es una plataforma en línea súper emocionante para entusiastas de la Ciencia de datos y el machine learning. En Kaggle, puedes participar en competiciones en las que se proponen desafíos interesantes. Para ello deberás usar tus habilidades de manejo de datos y algoritmia, colaborar con otros expertos en el campo y compartir tus propios proyectos con la comunidad. También puedes encontrar conjuntos de datos públicos con los que comenzar a explorar y practicar tus habilidades de análisis de datos. ¡Es como un parque de diversiones del Data Science!\n¡Vayamos a los consejos!\n\n\r1. Establece tu objetivo y revisa los recursos (habilidades, tiempo, acceso a máquinas…) con los que cuentas.\rComenzamos por un punto esencial. Dependiendo de tu perfil y de la competición, deberás plantearte a priori qué pretendes conseguir participando en el reto. Puede ser aprender y mejorar en un determinado campo o tecnología, conseguir el premio, quedar entre los 3 primeros para incluirlo en tu CV o simplemente por diversión. Cualquiera que sea está bien.\nLo que recomendamos es evaluarlo de manera sincera, ya que será bastante el tiempo invertido y tener tu objetivo presente te ayudará en los momentos de menor motivación.\nPor ejemplo, si tu objetivo no es ganar la competición (el caso de participar en tu primer Kaggle) seguramente prefieras no entrar en una espiral de ‘hiperoptimización’ de hiperparámetros para rascar mínimas mejoras en la métrica de error, sino que quizá prefieras estudiar y aplicar nuevas técnicas o algoritmos, aprender sobre desarrollo y estructuración de un proyecto de Data Science o integrar fuentes complementarias de datos.\n\n\r2. Elección del tema o CdUso.\rLigado con el anterior punto, dado que vamos a dedicar muchos esfuerzos en este proyecto, ¿cómo no elegir un tema, campo o caso de uso que nos motive? Afortunadamente, desde muchas organizaciones y plataformas se están lanzando diferentes e interesantes competiciones. Kaggle es uno de los máximos exponentes de estas plataformas, pero también existen otras, las cuales presentamos aquí.\n\n\r3. Construye tu equipo de manera consciente. Usa herramientas para compartir código/archivos.\rDependiendo de los dos puntos anteriores, especialmente del primero, según tu objetivo deberás elegir a tu equipo de manera consecuente. Este es un tema que no se suele comentar, pero consideramos importante prestarle la debida atención.\nElige un compañero o amigo con el que te lleves realmente bien y os motivéis mutuamente si tu objetivo es aprender sobre un tema o tecnología nueva. Prioriza a alguien que comparta tus intereses en el caso que desees dedicarle tiempo a profundizar y masterizar un tema, tecnología o algoritmo muy concreto.\nSi el proyecto lo requiere, y pretendes optar al premio o a posiciones altas, te recomendamos elegir un compañero que complemente tus habilidades. En el caso de que no se requiera multidisciplinariedad, opta por aquellos que tengan un nivel similar al tuyo. Si es posible, ligeramente superior.\nEligiendo tu equipo de manera consciente lograrás minimizar tiranteces y conflictos de objetivos, maximizando el retorno del tiempo invertido.\n\n\r4. Investigación previa y profunda sobre el caso de uso en concreto.\rUna vez formado el equipo, os recomendamos comenzar a investigar el negocio o el contexto en el que se enmarca vuestro proyecto. Esto permitirá plantear mejor el trabajo, extraer un valor muy superior a los datos y os evitará iteraciones en el proceso diseñar-implementar-evaluar al partir de premisas más claras. De esta manera dejareis al lado una mala interpretación de conceptos básicos, lo cual puede ser letal.\nUn ejemplo. Si la competición trata sobre predecir el número de visitas o el número de contrataciones de determinados productos en un comercio online, en base a la navegación recogida por Google Analytics, debéis controlar el comportamiento de esta fuente de datos. Conocer el significado de tasa de rebote, las mecánicas desde que un usuario se conecta por primera vez y se le asigna una cookie hasta que convierte, borrado de cookies, diferentes casuísticas de registros nulos, bots, que la source (para conocer la fuente de donde viene el visitante) puede ser ruidosa porque en caso de dudas se asigna como direct…\nSin esta serie de conocimientos será difícil craftear variables para conseguir un buen performance de los modelos, o lo que es más importante, cualquier resultado que obtengáis es posible que sea malinterpretado. Por lo tanto, todo este background no es imprescindible para llegar a algún resultado, pero sí lo será para llegar a resultados potentes y realizar una participación de la que acabes orgullosos.\n\n\r5. Análisis exploratorio de los datos. Recuerda que (normalmente) no son los únicos que puedes usar.\rComo todo proyecto de datos, consta de una serie de etapas iterativas. Después de investigar sobre el contexto, echareis un primer vistazo a los datos. Si surgen dudas, de nuevo tendréis que investigar para resolverlas.\nAl margen de este recordatorio, la fase exploratoria se centra en conocer cada una de las variables. Como consejo personal, entre otras cosas, nosotros comenzamos midiendo el porcentaje de NAs y la distribución y varianza de las variables. Aquellas que tengan un elevado porcentaje de NAs o una varianza muy pequeña, o bien las apartamos (podría replantearse su entrada en siguientes iteraciones) o bien las encodeamos de manera dicotómica Si_NA/No_NA o Mayoritaria/No_mayoritaria. Para otro tipo de encodings ver.\nEsta etapa exploratoria varía bastante dependiendo del número de variables que contenga vuestro dataset. En datasets con 75, 100 o más variables, resultará más complicado hacerse una idea general de las características de cada una de ellas. Enfrentarnos a este tipo de datasets puede resultar ciertamente abrumador, sin embargo tras una buen estudio, reducción dimensional / eleccion y transformación puede ser que acabéis dando las gracias de no tener sólo 5 o 10 variables(caso en el que se suele llegar a un plateau de desempeño de los modelos más rápido y mayor homogeneidad en los resultados expuestos por los diferentes equipos).\nAdemás de esto; análisis de correlaciones, detección de outliers univariante y multivariante, tests estadísticos preliminares… son análisis que os permitirán poner en contexto los datos y modelarlos mejor.\nPor último, recordar que normalmente no hay problema con utilizar fuentes de datos complementarias a las propios de la competición. En algunos casos como Kaggle, lo que se establece es la obligación de comentar y hacer público el uso de estos datos durante la competición.\nDatos demográficos que ayuden a poner en contexto las variables geográficas como código postal o provincia, recoger eventos para aportar explicabilidad a spikes o comportamientos pasados… son sólo algunos de los ejemplos de datos que se pueden incorporar al dataset original del reto. Obviamente tendréis que tener en cuenta cuales de estos datos vais a tener y cuales no a la hora de predecir.\n\n\r6. Establecer la estructura del proyecto y del código.\rA continuación os mostramos la estructura que suelen tener nuestros proyectos. La estructuración de los directorios dentro de un proyecto de Data Science dependerá de las características del entorno tanto de desarrollo como la posterior productivización, siguiendo principios generales como la modularización del código.\rUna estructura bastante generalizada sería la siguiente:\nProjecto:\n\rdata:\r\r1_raw:\r2_processed:\r\rmodels:\rnotebooks:\r\r1_eda:\r2_poc:\r3_modeling:\r4_evaluation:\r\rsrc:\r\r1_get_data:\r2_processing:\r3_modeling:\r4_evaluation:\r5_helpers:\r\r\rCreemos que esta estructura se podría simplificar un poco dadas las características de un Datathon, en la que no se suele necesitar automatizar la ingesta y el preprocesado de los datos, sino que será una tarea puntual. Además el análisis exploratorio aquí suele tener un papel protagonista, así como el modelado se suele simplificar en un main.exe que ejecute todo el programa llamando a los módulos de preprocesado, train, test y evaluación.\nProjecto_Datathon:\n\rdata:\rexploratory:\rhelpers:\rlog:\rmain.R / main.py\routputs:\r\rmodels:\rpreds:\rvalidation:\r\r\rEn cuanto a la estructura del main, solemos llevar a cabo una validación cruzada manual con el objetivo de ganar flexibilidad a la hora de usar modelos de diferente naturaleza y poder stackear sus predicciones y compararlos. Cierto es que soluciones paquetizadas como scikit-learn o H2O pueden hacer este trabajo en el caso de que el tiempo disponible y características de la competición indiquen su uso. Nuestra propuesta tendría este esqueleto:\n\rCarga de entorno (paquetes, módulos y funciones)\rDiferentes craft de variables\rSeparación en dataset y datasetOOSample\rSeparar el dataset en folds\rPor cada fold:\r\rEntrenar con el resto\rPredecir en el fold\rEvaluación\r(En el último fold, entrenar si se quiere modelos de stacking con las predicciones en trainSet de los anteriores modelos)\r\rPredicción OOSample (Comparación de modelos base y de stacking)\rEvaluación\rPredicción del conjunto de test a enviar.\r\r\n\r7. Lanzar los primeros modelos.\rEn primer lugar os aconsejamos centraros en una familia de algoritmos y función de coste que a priori mejor se adapten a los datos y a la variable a predecir. Incluso teniendo en cuenta la métrica de error por la que se os va a medir. Es importante sacar los primeros resultados, a ser posible dentro de una estructura similar a la propuesta anteriormente. Las primeras métricas de error os ayudaran en muchos aspectos. Por un lado os pueden dar pistas de bugs en el código (métricas de error no realistas). También os servirá como base a partir de la cual ir mejorando, y como estamos seguros de que lo haréis, esto será ademañs un boost de ánimo.\nOs invitamos a buscar en Google sobre las principales familias de algoritmos supervisados (suele ser el caso en estos Datathones) y de las principales funciones de coste a optimizar, dependiendo de si se trata de un problema de clasificación o de regresión.\nComentar que la participación en el foro y kernels de Kaggle, hilos de Reddit y videos en Youtube será un buen complemento a la lectura de papers.\n\n\r8. Validación cruzada, OOS y backtesting.\rEspecial mención a las métricas de error. Uno de los puntos a los que de manera personal más importancia le damos, es el conocer con la mayor precisión posible los intervalos de error (confianza o predicción) de nuestros modelos antes de enviar sus predicciones.\nConocer las precisión de nuestro modelo bajo diferentes escenarios, partes del dataset e incluso datos sintéticos nos hace sentir un especial orgullo. Quizá sea simplemente un objetivo que nos marcamos(tal y como comentamos en el punto 1), pero el hecho de tener la certeza de cuando se baja la métrica de error no se debe a algo espúreo, o lo peor de todo a un bug o leakage de información, nos permite desarrollar con tranquilidad. Además en el caso de existir un ranking público y otro privado, controlar tu métrica de evaluación te permite saber con mayor certeza en que percentil te encuentras.\nLa mayoría de competiciones suelen ir ligadas a una métrica de error por la cual se evalúa a los participantes. Será fundamental introducirla en la evaluación de modelos, pero no debe de ser la única. Tanto a la hora de fijar una función de coste como a la hora de evaluar los modelos, deberíais tener en cuenta métricas de error complementarias que os ayuden a interpretar el desempeño de los modelos. Calcular el error mediano o el MAPE, cuando la métrica con la que os evaluarán será el error medio, puede ayudar tanto a conocer el comportamiento de vuestro modelo como a decantaros entre algoritmos que difieren en sólo mínimo porcentaje en la métrica principal en el conjunto de datos, pero no en otras.\nCasos especiales serán aquellos en los cuales nuestros datos tienen un fuerte componente temporal, o directamente están estructurados en forma de serie temporal. Aquí en contramos discusiones específicas: variaciones de método de cross validation para evitar el leakage de información entre sets, la validación walk forward o utilización de datos del futuro para entrenar, el estudio del decay de la precisión, clustering de series temporales. Temas no triviales a los que dedicaremos otro post.\n\n\r9. Interpretabilidad de modelos. Evaluación de resultados desde el punto de vista práctico y/o negocio.\rinterpretabilidad shap xgboost\r\rEn el caso de que se trate de un Datathon organizado por alguna empresa de vuestra zona, seguramente los mejores proyectos serán llamados a un evento final en el que se expondrán vuestros trabajos. En otros, os pedirán una memoria presentando los resultados. Si bien es cierto, en el caso de Kaggle no suelen hacerlo.\nPor lo tanto, si la competición a la que te/os presentáis requiere de este tipo de resultado, será importante tenerlo presente no sólo al final, sino durante todo el proceso. Además, una vez que se ha “re-optimizado” los hiperparámetros con la última librería bayesiana y stackeado nuestros mejores modelos, quizá sea hora de trabajar en la interpretabilidad de los resultados e incorporación de nuevos datos. En definitiva, conclusiones que sean valiosas a la hora de poner en marcha el modelo y que no quede en una simple estructura de pesos optimizados o de reglas.\nPaquetes y módulos como SHAP o LIME incorporan métodos enfocados en la interpretabilidad de cada una de las predicciones. Esto supone un paso más allá a la hora de examinar y entender nuestros modelos, ya que además de la importancia global “media” de cada variable en el modelo, obtenida en los coeficientes o por métricas como la importancia de variables que suelen traer los algoritmos de árboles y bagging/boosting, podemos obtener el peso de cada variable en una determinada observación.\nPor ejemplo, en nuestra última competición a la que asistimos se nos pedía esta presentación final a los tres mejores proyectos. Una vez que modelamos la información estructurada y llevamos a cabo ciertas iteraciones sobre estos datos, pensamos que sería más enriquecedor tanto para nosotros como para las personas que proponían el concurso, la investigación sobre la extracción de información de las imágenes (información que en el caso de uso que nos ocupaba, a priori, iba a tener un impacto claro sobre la variable a predecir). Por lo tanto optamos por adentrarnos en el modelado de unas imágenes que se nos aportaban, haciendo uso del transfer learning, cosa que no se nos pedía explícitamente. Llegamos a bastantes insights interpretando los que las convoluciones de estos modelos preentrenados detectaban en nuestras imágenes, y lo que esmás importante, aprendimos mucho durante el proceso.\n\n\r10. Escribir una memoria con puntos fuertes y puntos a mejorar detectados, que te sirvan de partida en el próximo reto.\rUna vez finalizado el proyecto, un práctica que nos ha enriquecido y ha supuesto un antes y un después ha sido escribir algún tipo de memoria o documento para nosotros mismos. En él reflexionamos sobre la reciente participación. Analizamos los puntos fuertes y lo que debemos mejorar, tanto a nivel técnico como a nivel de equipo y por qué no a nivel emocional y de actitud. A ser posible nada más entregar y antes de saber el resultado. Sería genial si al tiempo de conocer el mismo se añadiera algún punto o reflexión más.\nTodas estas anotaciones os ayudarán, cada vez que os enfrentéis a un nuevo proyecto, a encararlo más preparados y no depender del ‘instinto’ ni de lo que la memoria selectiva os quiera recordar en momentos puntuales.\nUna mala predisposición personal, no investigar suficientemente y con cariño la distribución de los datos y sus valores extremos, una mala elección de equipo, seguir corriendo los modelos 30 minutos antes de que acabe el plazo de entrega, no preparar la exposición final con tiempo,… son situaciones que nos han pasado a muchos y no ocurre absolutamente nada por reflexionar sobre ello y dejarlo por escrito. Lo fundamental es, dentro de lo posible, ¡que no se repitan en la próxima competición para lograr conseguir aun mejores resultados! :)\n\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\rSuscribe for more Python tips!\r\r\r\r\r\r\r","date":1583884800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1583884800,"objectID":"53f51547ef8537ca28bdd889f7a0216f","permalink":"/es/post/10-consejos-datathon-kaggle-data-science/","publishdate":"2020-03-11T00:00:00Z","relpermalink":"/es/post/10-consejos-datathon-kaggle-data-science/","section":"post","summary":"En este post presentamos nuestra experiencia y mejores consejos para que consigas tus objetivos en tu próximo Kaggle, Datathon o competición de datos.","tags":[],"title":"¡10 consejos para triunfar en tu próximo Kaggle, Datathon o competición de datos!","type":"post"},{"authors":["Carlos Vecina"],"categories":["R","Post"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rAquí os mostramps el código de R. Como podeis ver, solo cargamos shiny, ggplot2 y tidyverse. Es un script en curso, ya que aun queda por desarrollar características básicas como:\n\rrefactorizar el código ;\n\rvisualización con GGanimate de los pasos recorridos por los algoritmos;\n\ry, por supuesto, implementar diferentes algoritmos pathfinding y evolutivos.\n\r\r¡Todas estas nuevos desarrollos y mucho más en siguientes posts! ¡Sigue informado!\nlibrary (shiny)\rlibrary (ggplot2)\rlibrary (tidyverse)\rsource(\u0026quot;helpers/ColourBorders.R\u0026quot;)\rsource(\u0026quot;helpers/PlotMapGrid.R\u0026quot;)\r\r\rui \u0026lt;-fluidPage(\rmainPanel(\rcolumn(12,offset = 5, \rtitlePanel(\u0026quot;Pathfinding Algorithm Visualization using R!\u0026quot;)),\rHTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\rcolumn(12,offset = 5,HTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\ractionButton(\u0026quot;go_search_actionButton\u0026quot;, \u0026quot;Go Search!\u0026quot;),\ractionButton(\u0026quot;clean_all_actionButton\u0026quot;, \u0026quot;Clean All\u0026quot;)),\rHTML(\u0026quot;\u0026amp;nbsp\u0026quot;),\rcolumn(12,offset=5, plotOutput(\u0026quot;map_grid_plotOutput\u0026quot;,\rclick=\u0026quot;map_grid_plotOutput_click\u0026quot;))\r))\r\r\rserver \u0026lt;-function(input, output){\r\r## Initial params\rmax_steps \u0026lt;-50\rmatrix_x_size \u0026lt;-20\rmatrix_y_size \u0026lt;-20\rgrid_map_reactive \u0026lt;-matrix(ncol = matrix_x_size,\rnrow = matrix_y_size,\rdata = 0) \r\r## Colours Dict (in progress)\r# 1- Wall\r# 2- Init\r# 3- Obj\r# 4- Step done\r# 5- Goal achieved\r\r# Initialize objts\rgrid_map_reactive[4,15] \u0026lt;-3 # obj\rgrid_map_reactive[17,3] \u0026lt;-2 # init\rinitial_step \u0026lt;-which(grid_map_reactive ==2,\rarr.ind = TRUE)\rgrid_map_reactive \u0026lt;-ColourBorders(grid_map_reactive, 1) # rounding walls\rreact_df \u0026lt;-reactiveValues(df = grid_map_reactive,\rorig = grid_map_reactive,\rwalls = grid_map_reactive)\r\robserve({\rif(!is.null(input$map_grid_plotOutput_click)){\rnew_x_value \u0026lt;-trunc(input$map_grid_plotOutput_click$x)\rnew_y_value \u0026lt;-trunc(input$map_grid_plotOutput_click$y)\r\rif(between(new_x_value,2,matrix_x_size-1) \u0026amp;between(new_y_value,2,matrix_y_size-1)){\risolate(react_df$df[new_y_value,new_x_value] \u0026lt;-if_else(react_df$df[new_y_value,new_x_value]==0,\r1,0))\risolate(react_df$df[4,15] \u0026lt;-3)\risolate(react_df$df[17,3] \u0026lt;-2)\risolate(react_df$df[17,3] \u0026lt;-2)\risolate(react_df$walls \u0026lt;-react_df$df)\r\routput$map_grid_plotOutput \u0026lt;-renderPlot({\r\rPlotMapGrid(react_df$df,\rmatrix_x_size,\rmatrix_y_size)\r\r}, width=600, height=600,position=\u0026quot;center\u0026quot;)\r}}\r}) \r\r# Go search! Pseudo-random pathfinding algortihm\robserveEvent(input$go_search_actionButton,{\r\rif(nrow(which(react_df$df ==4, arr.ind = TRUE))\u0026gt;=1) react_df$df \u0026lt;-react_df$walls # click search without clean\rcurrent_step \u0026lt;-initial_step \robj \u0026lt;-which(react_df$df ==3, arr.ind = TRUE)\rprevious_steps_with_opt \u0026lt;-current_step\r\rfor(i in 1:max_steps){\rnext_step_col \u0026lt;-tribble(~row, ~col,\rcurrent_step[1]+1,current_step[2]+0,\rcurrent_step[1]+0,current_step[2]+1,\rcurrent_step[1]-1,current_step[2]+0,\rcurrent_step[1]+0,current_step[2]-1)\rnext_values \u0026lt;-NULL\r\rfor(r in 1:nrow(next_step_col)){\rnext_values \u0026lt;-c(next_values,\rreact_df$df[next_step_col[[r,1]],\rnext_step_col[[r,2]]])\r}\rif(3 %in%next_values){\r\rcurrent_step \u0026lt;-next_step_col[next_values==3,] %\u0026gt;%\ras.matrix()\r\rreact_df$df[current_step] \u0026lt;-5\r\rbreak()\r\r} else if(0 %in%next_values){\r\rif(sum(next_values==0)\u0026gt;1){\r\rprevious_steps_with_opt \u0026lt;-current_step\r\r}\r\rcurrent_step \u0026lt;-next_step_col[next_values==0,] %\u0026gt;%\rsample_n(1) %\u0026gt;%\ras.matrix()\r\rreact_df$df[current_step] \u0026lt;-4\r\r} else {\r\rcurrent_step \u0026lt;-previous_steps_with_opt\r\r}\r}\r})\r\r# Reset all\robserveEvent(input$clean_all_actionButton,{\r\rreact_df$df \u0026lt;-react_df$orig\rreact_df$walls \u0026lt;-react_df$orig\r\r})\r\r# First panel\routput$map_grid_plotOutput \u0026lt;-renderPlot({\r\rPlotMapGrid(react_df$df,\rmatrix_x_size,\rmatrix_y_size)\r\r}, width=550, height=600,position=\u0026quot;center\u0026quot;)\r\r}\r\r\rshinyApp(ui=ui, server = server)\rPara acabar, las funciones helpers:\nColourBorders \u0026lt;-function(df, col_value){\r\r## Rounding walls \r# Params: df - Map grid\r# col_value - Colour to fill the rounding blocks\r# Return: df with the filled roundings\r\rdf[1,] \u0026lt;-col_value\rdf[,1] \u0026lt;-col_value\rdf[nrow(df),] \u0026lt;-col_value\rdf[,ncol(df)] \u0026lt;-col_value\r\rreturn(df)\r\r}\r\rPlotMapGrid \u0026lt;-function(df, matrix_x_size, matrix_y_size){\r\r## Plot the interactive grid \r# Params: df - Map grid\r# matrix_x_size - X_axis limit\r# matrix_y_size - Y_axis limit\r# Return: plot with the pathfinding\r\r\rplot \u0026lt;-rbind(\rwhich(df==1, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#623B17\u0026quot;),\rwhich(df ==2, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#13293D\u0026quot;),\rwhich(df ==3, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#ffff66\u0026quot;),\rwhich(df ==4, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#99ccff\u0026quot;),\rwhich(df ==5, arr.ind = TRUE) %\u0026gt;%cbind(fill_col=\u0026quot;#1B998B\u0026quot;)\r\r) %\u0026gt;%\rdata.frame(stringsAsFactors = F) %\u0026gt;%\rtransmute(y = as.numeric(row), x = as.numeric(col), fill_col=fill_col) %\u0026gt;%\rggplot(aes(x+0.5,y+0.5)) +\rgeom_tile(width = 1, height = 1, fill = df$fill_col, col=\u0026quot;black\u0026quot;) +\rscale_y_reverse() +\rscale_x_continuous(breaks = seq(0, matrix_x_size, 1),\rlimits = c(0+0.5, matrix_x_size+1.5), \rminor_breaks = NULL) +\rscale_y_continuous(breaks = seq(0, matrix_y_size, 1),\rlimits = c(0+0.5, matrix_y_size+1.5),\rminor_breaks = NULL) +\rtheme_linedraw()+\rtheme(axis.title.x=element_blank(),\raxis.title.y=element_blank(),\raxis.text.x=element_blank(),\raxis.text.y=element_blank(),\raxis.ticks.x=element_blank(),\raxis.ticks.y=element_blank())\r\rreturn(plot)\r\r}\r\rbody {\rtext-align: justify}\rp {\rword-spacing: 3px;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1579564800,"objectID":"6f570cd49e456db7a615cde779b4bf19","permalink":"/es/post/visualizador-interactivo-algoritmos-busqueda-caminos-en-r-shiny/","publishdate":"2020-01-21T00:00:00Z","relpermalink":"/es/post/visualizador-interactivo-algoritmos-busqueda-caminos-en-r-shiny/","section":"post","summary":"Diseñando el mapa interactivo para visualizar algoritmos evolutivos y de búsqueda de caminos.","tags":[],"title":"Visualizador de algoritmos en R! (I) Desarrollando el mapa dinámico","type":"post"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\r\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rImagina que estas analizando datos obtenidos en encuestas. Quizá no hace falta que imagines y es realmente tu caso. Cuando tratamos de sacar estadísiticos de la distribución que siguen las respuestas, como la media, solemos hacerlo de una manera representativa, es decir, ponderando las respuestas dependiendo del número de individuos pertenecientes a un segmento.\nEs cierto que en R se encuentra la función weigthed.mean() y puede ser util en determinados casos. Pero, ¿y qué pasa si aun no tienes calculados los pesos y almacenados como vector o columna? Incluso más importante, ¿qué pasa si quieres utilizar otra función de agregación que no sea la media?\nAquí ofrecemos nuestra versión donde conseguimos obtener tanto los pesos como la agregación(de manera flexible, media u otra función) de manera ponderada:\nlibrary(tidyverse)\r\rsurvey_data \u0026lt;-tribble( # Creamos el dataset\r~id, ~region1, ~region2, ~gender, ~q1, ~q2,\r1,\u0026quot;sp\u0026quot;,\u0026quot;mad\u0026quot;,\u0026quot;m\u0026quot;, 2,5,\r2,\u0026quot;it\u0026quot;, \u0026quot;bol\u0026quot;, \u0026quot;m\u0026quot;, 5, 10,\r3,\u0026quot;sp\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;f\u0026quot;, 2, 2,\r4,\u0026quot;sp\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;f\u0026quot;, 7, 7,\r5,\u0026quot;it\u0026quot;, \u0026quot;bol\u0026quot;, \u0026quot;m\u0026quot;, 2, 7) \rsurvey_data %\u0026gt;%\rgroup_by(region1, region2, gender) %\u0026gt;%# Elegimos nuestros segmentos\rmutate(weight = 1/n()) %\u0026gt;%# Calculamos los pesos\rungroup() %\u0026gt;%# Una vez calculados desagrupamos\rsummarise_at(vars(contains(\u0026quot;q\u0026quot;)), # Son preguntas columnas que empiezan por q\rfuns(weighted_mean = # Elegimos como funcion de agregación la media\rsum(. *weight)/sum(weight))) \r\r\rq1_weighted_mean\r\rq2_weighted_mean\r\r\r\r\r\r3.333333\r\r6\r\r\r\r\r","date":1579132800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1579132800,"objectID":"5308c07aa7c52877e555b6983cff206d","permalink":"/es/vizs-and-tips/summarise_at-media-ponderada-tidyverse-r/","publishdate":"2020-01-16T00:00:00Z","relpermalink":"/es/vizs-and-tips/summarise_at-media-ponderada-tidyverse-r/","section":"vizs-and-tips","summary":"Analizando datos de encuestas usando R.","tags":[],"title":"Dominando la función summarise_at(). Media ponderada con R en el ecosistema Tidyverse. ","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Python","Tips"],"content":"\r\rUna queja o comentario recurrente entre los usuarios que empiezan a usar los Jupyter Notebooks es la falta de informacion sobre las variables y funciones definidas en el entorno. Si te realizas esta pregunta, seguramente necesites informacion sobre el uso y el principal objetivo de estos notebooks, el cual es muy diferente al de IDEs como Spyder, Pycharm o RStudio.\nUna vez que confirmamos que este tipo de notebooks son lo que necesitamos, existen diferentes maneras de mostrar esta información. La primera y más facil de ellas es mediante el método mágico %whos\nOtras alternativas son, por un lado la extensión nbextension y dentro de Jupyter Lab el inspector de variables. Puedes encontrar más información aquí.\n\n#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\r#mc_embed_signup .button {\rbackground-color: #0294A5; /* Green */\rcolor: white;\rtransition-duration: 0.4s;\r}\r#mc_embed_signup .button:hover {\rbackground-color: #379392 !important; }\r\r¡Suscribete para más contenido sobre Python! \r\r\r\r\r\r\r","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1578960000,"objectID":"c7fdc880346a1c9e2fe7652016fb0b56","permalink":"/es/vizs-and-tips/magic-whos-metodo-jupyter-notebook/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/es/vizs-and-tips/magic-whos-metodo-jupyter-notebook/","section":"vizs-and-tips","summary":"Kind of magic","tags":[],"title":"Lista todas las variables definidas en Jupyter Notebooks","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Vizs"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rA la hora de presentar tus habilidades ya sea en una página web o en tu CV, una buena idea sueles ser sintetizarlas mediante una gráfica. Muchas plantillas de CVs incluyen una gráfica por defecto.\nEn este post queremos dar un template el cual poder personalizar con vuestras habilidades y evolucionar incorporando mejoras estéticas. ¡Estaremos encantados de ver tu versión!\nOs dejamos el código comentado en el siguiente chunk:\nlibrary(ggplot2)\r# library(plotly) Es simple transformarlo a plotly\rlibrary(tibble)\rlibrary(dplyr)\r\rskills \u0026lt;-tribble( # Creamos el dataset con las habilidades\r~Skill, ~Hours, ~Class,\r\u0026quot;AWS\u0026quot;, 500, \u0026quot;BigData\u0026quot;,\r\u0026quot;Python\u0026quot;, 8000, \u0026quot;Language\u0026quot;,\r\u0026quot;Spark\u0026quot;, 4000, \u0026quot;BigData\u0026quot;,\r\u0026quot;R\u0026quot;, 9000, \u0026quot;Language\u0026quot;,\r\u0026quot;Git\u0026quot;, 2000, \u0026quot;Tools\u0026quot;,\r\u0026quot;Jira\u0026quot;, 2000, \u0026quot;Tools\u0026quot;,\r\u0026quot;Forecasting\u0026quot;, 5000, \u0026quot;Objetive\u0026quot;,\r\u0026quot;Segmentation\u0026quot;, 2000, \u0026quot;Objetive\u0026quot;,\r\u0026quot;Computer Vision\u0026quot;, 600, \u0026quot;Objetive\u0026quot;,\r\u0026quot;SQL\u0026quot;, 4500, \u0026quot;Language\u0026quot;,\r\u0026quot;IBM Data Stage \u0026amp; SPSS\u0026quot;, 1200, \u0026quot;Tools\u0026quot;,\r\u0026quot;Shiny R\u0026quot;, 1500, \u0026quot;Visualization\u0026quot;,\r\u0026quot;Tableau\u0026quot;, 1000, \u0026quot;Visualization\u0026quot;,\r\u0026quot;Spotfire\u0026quot;, 500, \u0026quot;Visualization\u0026quot;\r) \r# plotly( \rggplot(data=skills,\raes(x=reorder(Skill,-desc(Hours)), # Ordenamos las habilidades según las horas dedicadas\ry= Hours, \rfill=Class, # Coloreamos según ek tipo de habilidad\rlabel=paste0(Hours,\u0026quot; h\u0026quot;))) +# Añadimos un label con las horas\rgeom_bar(stat = \u0026quot;identity\u0026quot;, colour=\u0026quot;black\u0026quot;) +# Stat identity para que pueda tener eje Y\rcoord_flip() +# Hacemos las barras horizontales\rlabs(x=\u0026quot; \u0026quot;, y=\u0026quot;Hours\u0026quot;, fill=\u0026quot; \u0026quot;) +# Definimos el nombre de los ejes\rtheme_minimal() +# Theme sin background\rscale_fill_brewer(palette = \u0026quot;YlOrBr\u0026quot;, # Paleta deseado\rdirection = -1) +\rgeom_label(show_guide = F, aes(y=400)) # Usar show_guide a pesar del warning\r","date":1578355200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1578355200,"objectID":"b4ba8aad06919f513b29950e247ae7fb","permalink":"/es/vizs-and-tips/skills-chart-curriculum-r-ggplot/","publishdate":"2020-01-07T00:00:00Z","relpermalink":"/es/vizs-and-tips/skills-chart-curriculum-r-ggplot/","section":"vizs-and-tips","summary":"Gráfico de habilidades en pocas lineas con R y ggplot.","tags":[],"title":"Muestra tus habilidades o skills mediante un gráfico en R y su paquete ggplot","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\nGGanimate es una libraría de R que está generando bastantes casos de uso, comentarios y posts debido al potencial que introduce en el aspecto de visualizaciones en el ecosistema R.\nNos encontramos usuarios preguntando la posibilidad de que las barras no solo aumenten y disminuyan a lo largo del tiempo(de la animación) sino que también el orden de las mismas se modificara en función de si eran mayores o menores y no permaneciesen en el orden del primer timestamp, en definitiva que se reordenaran.\nPor tanto, compartimos el siguiente código en el cual se consigue que las barras se reordenan a lo largo del tiempo. Es más, en este ejemplo, tenemos 5 ciudades que entran y salen del gráfico en función de su valor durante el tiempo y visualizando el top 4.\nOs dejamos el código para realizar la animación del gráfico de barras:\nlibrary(ggplot2)\rlibrary(gganimate)\rlibrary(tidyverse)\rdf_evolution_data \u0026lt;-data.frame(Name=rep(c(\u0026quot;Madrid\u0026quot;,\u0026quot;Barcelona\u0026quot;, # Creamos el dataset\r\u0026quot;Valencia\u0026quot;,\u0026quot;Alicante\u0026quot;,\r\u0026quot;Sevilla\u0026quot;),5),\rYear = factor(sort(rep(2001:2005, 5))),\rValue = runif(25,100,1000))\rdf_evolution_data_filtered \u0026lt;-df_evolution_data %\u0026gt;%\rgroup_by(Year) %\u0026gt;%\rmutate(Rank = rank(Value)) %\u0026gt;%# Añadimos la columna rank y\rfilter(Rank \u0026gt;=2) # descartamos el de menor valor\rggplot(df_evolution_data_filtered) +\rgeom_col(aes(x=Rank, # Creamos el gráfico de barras\ry=Value,\rgroup=Name, # Afrumando y filleando por ciudad\rfill=Name),\rwidth=0.4) +\rgeom_text(aes(x=Rank, # Etiquetamos las barras con los nombres\ry=0,\rlabel=Name,\rgroup=Name),\rhjust=1.25) +\rtheme_minimal() +# Elegimos un theme que no sea gris\rylab(\u0026#39;Value\u0026#39;) +\rtheme(axis.title.y = element_blank(), # Eliminamos los labels y titles \raxis.text.y = element_blank(),\raxis.ticks.y = element_blank(),\rplot.margin = unit(c(5,5,5,5), \u0026#39;lines\u0026#39;)) +# Escogemos el zoom\rscale_fill_brewer(palette=\u0026quot;Dark2\u0026quot;) +# Paleta de colores de las barras\rcoord_flip(clip=\u0026#39;off\u0026#39;) +# Hacemos las barras horizontales\rggtitle(\u0026#39;{closest_state}\u0026#39;) +# Tilulo == al valor de la columna que\rtransition_states(Year, # Animamos la columna Year\rtransition_length = 1, # Duración de la animación de transición\rstate_length = 1) +# Duración de cada Year\rexit_fly(x_loc = 0, y_loc = 0) +# Salida de la ciudad no top4\renter_fly(x_loc = 0, y_loc = 0) # Entrada de la ciudad al top4\r","date":1576454400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1576454400,"objectID":"a632e7e9d046753f1ce22e857d87624b","permalink":"/es/vizs-and-tips/reordenar-grafico-barras-r-ggplot-gganimate/","publishdate":"2019-12-16T00:00:00Z","relpermalink":"/es/vizs-and-tips/reordenar-grafico-barras-r-ggplot-gganimate/","section":"vizs-and-tips","summary":"Mostramos como reordenar las barras en las animaciones de ggplot realizadas con gganimate.","tags":[],"title":"Reordenando gráficos de barras en R con GGanimate","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r\nA continuación te mostramos el código:\nlibrary(tidyverse)\rhuron \u0026lt;-data.frame(year = 1875:1972, # Creamos el conjunto de datos\rvalue = LakeHuron,\rstd = runif(length(LakeHuron),0,1)) # Valores random para representar la desviación \r\rhuron %\u0026gt;%# Fijamos los ejes X e Y\rggplot(aes(year, value)) +\rgeom_line(color = \u0026quot;firebrick\u0026quot;, size = 1) +# Creamos la gráfica de linea \rgeom_ribbon(aes(ymin = value -std,\rymax = value +std), # Creamos los intervalos con valor +- std\rfill = \u0026quot;steelblue2\u0026quot;) \rPara un grafico con varias lineas, debemos incorporar el aesthetic de group de la siguiente manera:\nlibrary(tidyverse)\rhuron \u0026lt;-data.frame(year = rep(1875:1972,2), \rgroup = c(rep(\u0026quot;a\u0026quot;,98),rep(\u0026quot;b\u0026quot;,98)),\rvalue = c(LakeHuron, LakeHuron +5),\rstd = runif(length(LakeHuron)*2,0,1)) # Creamos el conjunto de datos con dos series\r\r# Seguimos la misma estructura para crear el plot, pero añadiendo fill=group y group=group para indicar que\r# coloree y trate las dos series de manera diferenciada.\rhuron %\u0026gt;%\rggplot(aes(year, value, fill = group)) +\rgeom_line(color = \u0026quot;firebrick\u0026quot;, size = 1) +\rgeom_ribbon(aes(ymin = value -std,\rymax = value +std,\rgroup=group),\rfill = \u0026quot;steelblue2\u0026quot;) \r","date":1574035200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1574035200,"objectID":"b646ac1b5a8a3ff740aae84f275d8eec","permalink":"/es/vizs-and-tips/ggplot_geom_ribbon_shadow/","publishdate":"2019-11-18T00:00:00Z","relpermalink":"/es/vizs-and-tips/ggplot_geom_ribbon_shadow/","section":"vizs-and-tips","summary":"¡Plotea tus intervalos de confianza de manera muy facil!","tags":[],"title":"Muestra los intervalos de confianza de tus predicciones mediante geom_ribbon() con R Ggplot","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["Tips","Datathon"],"content":"\r\nKaggle - https://www.kaggle.com\nDriven Data - https://www.drivendata.org/competitions/\nCodaLab - https://competitions.codalab.org/\nAlibaba Tianchi - https://tianchi.aliyun.com/competition/gameList/activeList\nAnalyticsvidhya - https://datahack.analyticsvidhya.com/contest/all\nhackerearth - https://www.hackerearth.com/challenges/competitive/\nAgorize - https://www.agorize.com/en/challenges\n\nTambién existen eventos concretos, que se celebran anualmente.\n\nIDA (international Data Analysis Olympiad) (Registro en Enero) - https://idao.world/\nIronViz - https://www.tableau.com/iron-viz\nTopCoder - https://tco19.topcoder.com/competition-overview/algorithm\nData Mining Cup - https://www.data-mining-cup.com/\n\nA nivel nacional y local están comenzando a organizarse todo tipos de eventos relativos al #opendata. Te invitamos a que investigues sobre ellos y te animes a colaborar en mejorar tu entorno a través de la explotación de los datos.\nPor ejemplo, en España a fecha de este artículo, los más importantes son:\n\nCajaMar - https://www.cajamardatalab.com/\nGobierno - https://datos.gob.es/es/event-tags/concurso\nJunta Castilla y Leon - https://datosabiertos.jcyl.es/web/es/datos-abiertos-castilla-leon.html\n\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1570406400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1570406400,"objectID":"baaafa42f4a48a4a7adcaae68ab2bd8c","permalink":"/es/vizs-and-tips/plataformas-competiciones-de-datos-kaggle-datathon/","publishdate":"2019-10-07T00:00:00Z","relpermalink":"/es/vizs-and-tips/plataformas-competiciones-de-datos-kaggle-datathon/","section":"vizs-and-tips","summary":"No todo es Kaggle","tags":[],"title":"Plataformas donde puedes participar en competiciones de datos","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Tips"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\r¿Estás comenzando tu etapa de exploración de datos? Una de las primeras cosas que solemos hacer es calcular el porcentaje de NAs por variable. Existen muchas maneras de llegar a este resultado, partiendo de R base con summary (obtenemos más estadísticos y con muchas variables puede no interesar todo de golpe)\nVamos a comprobar el performance de las funciones que más usamos para este conteo/porcentaje. Destacamos que el output de ellas no es exactamente igual, así que además de los tiempos, dependerá de la estructura de nuestro programa elegir una u otra.\nComenzamos definiendo la función de comparación para probar con datasets cos más filas y más columnas para ver como escalan:\nlibrary(microbenchmark)\rlibrary(tidyverse)\r\rbenchmark_count_na_by_column \u0026lt;-function(dataset){\rmicrobenchmark(\r# Summary table output\rdataset %\u0026gt;%summary(),\r# Numeric output\rcolSums(is.na(dataset)),\rsapply(dataset, function(x) sum(is.na(x))),\r# List output\rdataset %\u0026gt;%map(~sum(is.na(.))),\rlapply( dataset, function(x) sum(is.na(x))),\r# Df output\rdataset %\u0026gt;%\rselect(everything()) %\u0026gt;%\rsummarise_all(funs(sum(is.na(.)))),\rdataset %\u0026gt;%\rsummarise_each(funs(sum(is.na(.)))),\r# Tibble output\rdataset %\u0026gt;%map_df(~sum(is.na(.)))\r)\r}\rVeamos el rendimiento entre datasets:\nprint(airquality %\u0026gt;%nrow()) # 153 rows\rbenchmark_count_na_by_column(airquality)\r## Unit: microseconds\r##funct min lq mean median uq max neval class\r##summary() 1480.5 1582.60 1979.676 1897.30 2100.45 6403.2 100 table\r##colSums() 24.4 38.45 47.854 44.70 53.90 152.4 100 integer\r##sapply() 23.2 35.05 67.891 39.65 50.30 2494.8 100 integer\r##map() 140.2 182.60 214.092 200.75 238.50 549.6 100 list\r##lapply() 11.2 15.65 27.093 18.85 22.45 750.1 100 list\r##summarise_all() 1996.9 2147.80 2650.223 2382.90 2798.55 8133.7 100 data.frame\r##summarise_each() 2277.9 2497.05 2951.477 2898.40 3080.65 7977.2 100 data.frame\r##map_df() 190.0 249.00 331.368 275.40 326.05 383 100 tbl_df\rY para acaba, veamos como escala cada una de estas funciones a un dataset de 100000 filas:\nbig_dataset %\u0026gt;%nrow() # 100 000 rows\rbenchmark_count_na_by_column(big_dataset)\r## Unit: milliseconds\r##funct min lq mean median uq max neval class\r##summary() 113.7535 129.35070 138.716624 133.14050 143.45920 252.0149 100 table\r##colSums() 4.4280 5.31080 12.502741 5.65005 18.77570 124.8206 100 integer\r##sapply() 2.2452 3.03095 6.788395 3.15310 15.04010 18.6061 100 integer\r##map() 2.5950 3.28390 5.760602 3.38020 3.69445 19.4527 100 list\r##lapply() 2.2018 2.95700 6.219106 3.03605 3.62860 19.5514 100 list\r##summarise_all() 5.0982 5.85135 10.093431 6.05940 6.87070 127.5107 100 data.frame\r##summarise_each() 5.7251 6.16980 10.191426 6.33065 6.72210 125.2943 100 data.frame\r##map_df() 2.6913 3.42045 7.694863 3.56720 3.89715 122.2030 100 tbl_df\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1569974400,"objectID":"dadcd76509f09d433db2597b0b4684a7","permalink":"/es/vizs-and-tips/recuento-nas-por-columna-en-r-comparativa/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/es/vizs-and-tips/recuento-nas-por-columna-en-r-comparativa/","section":"vizs-and-tips","summary":"Comparando la manera tidy con base R","tags":[],"title":"La mejor manera de hacer recuento de NAs por columna","type":"vizs-and-tips"},{"authors":["Carlos Vecina"],"categories":["R","Post"],"content":"\ra.sourceLine { display: inline-block; line-height: 1.25; }\ra.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\ra.sourceLine:empty { height: 1.2em; }\r.sourceCode { overflow: visible; }\rcode.sourceCode { white-space: pre; position: relative; }\rdiv.sourceCode { margin: 1em 0; }\rpre.sourceCode { margin: 0; }\r@media screen {\rdiv.sourceCode { overflow: auto; }\r}\r@media print {\rcode.sourceCode { white-space: pre-wrap; }\ra.sourceLine { text-indent: -1em; padding-left: 1em; }\r}\rpre.numberSource a.sourceLine\r{ position: relative; left: -4em; }\rpre.numberSource a.sourceLine::before\r{ content: attr(title);\rposition: relative; left: -1em; text-align: right; vertical-align: baseline;\rborder: none; pointer-events: all; display: inline-block;\r-webkit-touch-callout: none; -webkit-user-select: none;\r-khtml-user-select: none; -moz-user-select: none;\r-ms-user-select: none; user-select: none;\rpadding: 0 4px; width: 4em;\rcolor: #aaaaaa;\r}\rpre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }\rdiv.sourceCode\r{ background-color: #f8f8f8; }\r@media screen {\ra.sourceLine::before { text-decoration: underline; }\r}\rcode span.al { color: #ef2929; } /* Alert */\rcode span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */\rcode span.at { color: #c4a000; } /* Attribute */\rcode span.bn { color: #0000cf; } /* BaseN */\rcode span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */\rcode span.ch { color: #4e9a06; } /* Char */\rcode span.cn { color: #000000; } /* Constant */\rcode span.co { color: #8f5902; font-style: italic; } /* Comment */\rcode span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */\rcode span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */\rcode span.dt { color: #204a87; } /* DataType */\rcode span.dv { color: #0000cf; } /* DecVal */\rcode span.er { color: #a40000; font-weight: bold; } /* Error */\rcode span.ex { } /* Extension */\rcode span.fl { color: #0000cf; } /* Float */\rcode span.fu { color: #000000; } /* Function */\rcode span.im { } /* Import */\rcode span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */\rcode span.kw { color: #204a87; font-weight: bold; } /* Keyword */\rcode span.op { color: #ce5c00; font-weight: bold; } /* Operator */\rcode span.ot { color: #8f5902; } /* Other */\rcode span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */\rcode span.sc { color: #000000; } /* SpecialChar */\rcode span.ss { color: #4e9a06; } /* SpecialString */\rcode span.st { color: #4e9a06; } /* String */\rcode span.va { color: #000000; } /* Variable */\rcode span.vs { color: #4e9a06; } /* VerbatimString */\rcode span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */\r\rEn 7 minutos, seremos capaces de convertir nuestras gráficas generadas con ggplot en espectaculares plots en 3D, ¡y ademas interactivos!\rPodrás embebernos en HTML/Rmarkdown, o incluso mejor, podras exportarlo como mp4 en una animacion rotatoria para sacarle todo el jugo a tus datos!\nComo caso de uso, vamos a visualizar la edad media de los municipios españoles cruzando datos del padrón con los datos GIS, para posteriormente visualizarlos en 3 dimensiones.\n\n1. Introducción\r\nEn las últimas semanas, un ‘nuevo’ paquete de R ha centrado el interés de cierta parte de la comunidad. Decimos ‘nuevo’ porque se ha incorporado recientemente al CRAN, aunque realmente el primer commit realizado por su autor su repo de Github data de hace más de un año. Su nombre es rayshader y en palabras de su propio creador:\n\n\r“rayshader uses elevation data in a base R matrix and a combination of raytracing, spherical texture mapping, overlays, and ambient occlusion to generate beautiful topographic 2D and 3D maps”\n\r\nBajo mi punto de vista, Tyler Morgan-Wall (el autor del paquete) dio con la tecla cuando incorporó al paquete dos nuevas funciones, plot_gg() y render_movie(). La primera de ellas nos permite convertir con 2 líneas de código nuestra visualización en ggplot a una figura 3D de una manera realmente facil y eficiente. La segunda de ellas renderiza esta figura y la anima, poniendo al alcance del usuario diversos parámetros para controlar el zoom, los fps, ángulo, inclinación…\n\n\nLas nuevas funcionalidades y planteamiento del experimento\rLa única condicion que debe cunplir tu gg-visualización es tener como aesthetic color o fill, y en algunos casos también puedes jugar con el size\nEn demasiadas ocasiones, la visualización de datos en 3D no es la mejor opción a elegir, tal y como hablaremos un un futuro post. Por este motivo, he intentado traer un ejemplo donde el uso de la tercera dimensión aporte valor al análisis.\nEste ejemplo práctico consistirá, como ya hemos avanzado, en la visualización en el mapa de España la edad media en cada municipio. ¿Chulo? Para ello necesitaremos:\n\rLos datos del censo sobre las estadísticas de la población (en este caso la edad media) por cada municipio. Estos datos los obtenemos de la web del INE.\n\rLos datos GIS con las coordenadas de cada uno de los municipios que componen España.\n\r\rUna vez que tengamos estas dos fuentes de datos combinados, los visualizaremos y posteriormente exploraremos su renderización en un clip 3D con la figura rotando tal y como se ve en la imagen que encabeza este post.\n¡Vayamos paso por paso!\n\n\r\r2. CdU: Visualizando la edad media de cada municipio en España\rUna vez hemos establecido el objetivo principal y las diferentes fuentes de los datos, podemos proceder a la descarga y tratamiento de los mismos.\n\n2.1- Descargando los datos del censo\rComo digimos, para llevar a cabo nuestro propósito, necesitamos acceder a dos fuentes diferentes de datos. Usaremos el portal de datos abiertos del INE para descargar la edad media en cada municipio español. Después de una búsqueda bastante ardua por su web, encontramos la información que buscábamos. Os dejo este link donde teneis acceso a lo que ellos llaman como estadísticas contínuas\nlink.\nCon el objetivo de no irnos por las ramas, descargaremos directamente el fichero del 2018. Sin embargo, sí que es interesante citar la iniciativa INEbase de facilitar el acceso y la navegación en esta fuente de datos de INE.\nComenzamos cargando (o descargando) los paquetes necesarios para nuestro análisis. En un futuro post o tip compartiremos una función nuestra para la carga (o descarga en caso necesario) múltiple de paquetes en una sola linea.\nlibrary(pxR)\rlibrary(RColorBrewer)\rlibrary(rgeos)\r#install.packages(\u0026quot;rgdal\u0026quot;, repos = \u0026quot;http://cran.us.r-project.org\u0026quot;) reinstall cause gpclib dependencie https://stackoverflow.com/questions/30790036/error-istruegpclibpermitstatus-is-not-true\rlibrary(rgdal)\rlibrary(rayshader)\rlibrary(knitr)\rlibrary(magrittr)\rlibrary(tidyverse)\r\ras.numeric.factor \u0026lt;-function(x) { # Custom function to convert fctr to num factor value\rreturn(suppressWarnings(as.numeric(levels(x))[x]))\r}\r\rif(!dir.exists(\u0026quot;data\u0026quot;)) dir.create(\u0026quot;data\u0026quot;) # Create the download directory\r\nDescargando el fichero del INE 2018:\nutils::download.file(url = \u0026quot;http://www.ine.es/pcaxisdl/t20/e245/p05/a2018/l0/00000006.px\u0026quot;,\rdestfile = \u0026quot;data/census_2018.px\u0026quot;)\r\ntbl_census_2018 \u0026lt;-read.px(\u0026quot;data/census_2018.px\u0026quot;) %\u0026gt;%# Load \u0026amp; format\ras_tibble()\rParseamos los datos con el objetivo de conseguir un dataframe que consista en name, postal_code, average_age\ntbl_census_2018 %\u0026lt;\u0026gt;%\rset_names(c(\u0026quot;age\u0026quot;, \u0026quot;city\u0026quot;, \u0026quot;sex\u0026quot;, \u0026quot;population\u0026quot;)) %\u0026gt;%# Cambiamos los nombre\rna.omit() %\u0026gt;%# Na rmv\rfilter((city!=\u0026quot;Total\u0026quot;)\u0026amp;(age!=\u0026quot;Total\u0026quot;)\u0026amp;(sex==\u0026quot;Ambos sexos\u0026quot;)) %\u0026gt;%# Duplicate info rmv\rseparate(city, c(\u0026#39;postal_code\u0026#39;, \u0026#39;city_name\u0026#39;), sep=\u0026quot;-\u0026quot;) %\u0026gt;%# Sep City column\rmutate(age = as.numeric.factor(age)) %\u0026gt;%# Conv to numeric\rgroup_by(city_name, postal_code) %\u0026gt;%# Group to operate\rsummarise(avg_age = sum(population*age,na.rm = T)/sum(population,na.rm=T)) %\u0026gt;%# Avg age\rselect(city_name, postal_code, avg_age) # Discard columns\r\n\r2.2- Descargando datos GIS\rLa segunda fuente de datos que vamos a utilizar son los datos geográficos de los municipios españoles, los cuales cruzaremos con los censales anteriormente descargados para pintar la edad media en sus respectivas coordenadas.\nDescargando los daots GIS:\ntemp \u0026lt;-tempfile() # Create the tempfile\ru=\u0026quot;http://www.arcgis.com/sharing/rest/content/items/8e31c4c1a0b348f79058f212d0d807a1/data\u0026quot;\rutils::download.file(url = u, destfile = temp,\rmode=\u0026quot;wb\u0026quot;) # Binary mode for correct download\r\runzip(temp, exdir = \u0026quot;data/cities_gis\u0026quot;) # Unzip in data/cities_gis\runlink(temp) # Delete temp file\rTratamos estos datos para convertirlos de formato espacial a datos tabulares. Para este caso concreto de 3D, las Islas Canarias podrían deformarnos el gráfico, por lo que decidimos permanecer concentrados en nuestro objetivo didáctico y filtramos estas coordenadas. Por supuesto es posible mantenerlas sin perjudicar el gráfico, alterando sus coordenadas y acercándolas a la península. ¡Esto te queda como tarea para ti!\nPara llevar a cabo este procesado de los datos, usamos la función fortify para no depender de más paquetes. No obstante esta funcion nos lanza un warning sugiriendonos el uso de la función tidy() del paquete broom.\ntlb_cities_gis \u0026lt;-readOGR(dsn = \u0026quot;data/cities_gis/Municipios_ETRS89_30N.shp\u0026quot;,\rverbose=FALSE) # Spatial data reading\rtlb_cities_gis %\u0026lt;\u0026gt;%\rfortify(region = \u0026quot;Codigo\u0026quot;) # %\u0026gt;% # Conv \u0026quot;spatial object\u0026quot; to data.frame\r# broom::tidy()\r\rplot_canarias \u0026lt;-F # Control param, initial app config\r\rif(plot_canarias==F){ # Should be moduled in a funct\rtlb_cities_gis %\u0026lt;\u0026gt;%\rfilter((long\u0026gt;0) \u0026amp;(lat\u0026gt;4000000)) # Filter peninsular data\r} \rPara terminar, joineamos los dos datasets creados para conformar el tablón final, el cual vamos a usar como base para crear las gráficas. Apuntar que usamos left join como forma de mantener los datos geos y no perder coordenadas en el plot.\ntbl_cities_avg_age \u0026lt;-tlb_cities_gis %\u0026gt;%\rleft_join(tbl_census_2018, by = c(\u0026quot;id\u0026quot; =\u0026quot;postal_code\u0026quot;)) \rComo buena práctica, comprobamos el número de NAs generados a partir de este left join. Estos NAs serán municipios de los que tenemos coordenadas pero no contamos con información sobre la edad media.\nVemos que los valores perdidos representan únicamente el 1% del total de filas, por lo que vamos a imputarlos con el dato del código postal previo. Es cierto que podemos mejorar esta imputación, pero para nuestro propósito será suficiente debido al pequeño porcetaje del total que representan. ¡Vuelve a quedar de tu mano mejorarlo y comentárnoslo!\ntbl_cities_avg_age %\u0026gt;%\rgroup_by(id) %\u0026gt;%\rsummarise(na = sum(is.na(avg_age))) %\u0026gt;%# NAs by city\rsummarise(missing_perc = sum(na\u0026gt;0)/length(na)*100) %\u0026gt;%# Perc cities with at least 1 na \rselect(missing_perc)\r\rtbl_cities_avg_age %\u0026lt;\u0026gt;%\rarrange(id) %\u0026gt;%\rfill(avg_age, .direction = \u0026quot;down\u0026quot;) # Fill with the previous pc data.\r\n\r2.3- Visualización con Ggplot\rInspirado en gran medida en http://blog.manugarri.com/making-a-beautiful-map-of-spain-in-ggplot2/\nCon este dataset final, plotearemos las variables que representan las coordenadas en el eje X e Y y en primer lugar representaremos la edad media mediante la paleta de color. Las tonalidades rojas son asignadas a edades superiores y las azules a las edades medias más jóvenes. Conseguimos esto mediante el aesthetic fill de Ggplot.\nmyPalette \u0026lt;-colorRampPalette(rev(brewer.pal(11, \u0026quot;Spectral\u0026quot;))) # Create reverse Spectral palette\r\rplot_cities \u0026lt;-ggplot() +\rgeom_polygon(data = tbl_cities_avg_age, aes(fill = avg_age, \rx = long, \ry = lat, \rgroup = id)) +# Dummy variable to correct fill by PCode.\rscale_fill_gradientn(colours=myPalette(4)) +# Choose palette colours.\rlabs(fill=\u0026quot;Avg age\u0026quot;)\rplot(plot_cities)\r\n\r2.4- Visualización en 3D con Rayshader!\rEl anterior gráfico estaba bastante bien. En el podemos facilmente distinguir los municipios con la edad media más alta y los municipios más jóvenes. Sin embargo, los ojos humanos no son capaces de distinguir fácilmente entre colores próximos ni distinguir la magnitud de las diferencias en esta escala. Por lo tanto, ¿qué tal complementarlo con un nuevo eje?\nVeamos como hacerlo y que tal queda\nplot_gg(plot_cities,multicore=TRUE,width=5,height=3,scale=310) # Plot_gg de rayshader\rrender_snapshot()\r\nHmm dijiste algo sobre render_movie()… Qué tal si lo animamos?\n\n\r2.5- Animación 3D con Rayshader\rEn el gráfico anterior, la variable edad media queda bastante más entendible por el ojo humano en la dimensión añadida. Aquí la elección del ángulo e inclinación correctos es un punto esencial. Pero, ¿y mejoramos la interpretabilidad rotando el gráfico?\nEsto es de lo que se encarga la siguiente función:\nrender_movie(\u0026quot;img/movie_spain.mp4\u0026quot;,frames = 720, fps=30,zoom=0.6,fov = 30)\r\rp {\rword-spacing: 3px;\rtext-indent: 20px;\rtext-align: justify;\r}\r.page-subtitle {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r.card-text {\rtext-align: left !important;\rtext-indent: 0px !important;\r}\r\r\rwindow.dojoRequire([\"mojo/signup-forms/Loader\"], function(L) { L.start({\"baseUrl\":\"mc.us4.list-manage.com\",\"uuid\":\"91551f7ed29389a0de4f47665\",\"lid\":\"d95c503a48\",\"uniqueMethods\":true}) })\r\r\r","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1564185600,"objectID":"a1871808330375983a52703b97f35358","permalink":"/es/post/de-ggplot-a-3d-en-r-con-rayshader/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/es/post/de-ggplot-a-3d-en-r-con-rayshader/","section":"post","summary":"¿Pensando en usar 3D en R? En este post te enseñamos a convertir tus gráficos R ggplot en gráficos 3D. ¡Lleva tus gráficos en R a otra dimensión!","tags":[],"title":"Convierte tu GGplot en una animación 3D con R y Rayshader","type":"post"}]