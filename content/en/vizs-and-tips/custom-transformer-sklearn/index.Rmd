---
title: "Customize your Label and Independent transformer inside a Scikit Learn Pipeline"
author: "Carlos Vecina Tebar"
date: "2021-01-05"
slug: "custom-transformer-sklearn"
translationKey: "custom-transformer-sklearn"
output:
  blogdown::html_page:
    highlight: tango
categories:
- Python
- Tips
tags: []
subtitle: "Label transformer in SKlearn"
summary: "Label transformer in SKlearn"
authors: [carlos-vecina]
featured: true
draft: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

```{python}
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
from sklearn.metrics import mean_squared_error

from sklearn.preprocessing import StandardScaler, PowerTransformer
from sklearn.compose import TransformedTargetRegressor
from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
url = ('https://raw.githubusercontent.com/CarlosVecina/nft_market_arbitrage_regression/master/df_axie_full.csv')
data = pd.read_csv(url, sep=',')

## Check NAs
null_count_ser = pd.isnull(data).sum()
is_null_ser = null_count_ser > 0
null_count_ser[is_null_ser]
data.dropna(inplace=True)
```


```{python}
## Train/Test
TEST_PCT = 0.2
X = data.loc[:,['axie_breed','hp','speed','skill','morale']]
y = data.price_eth_parsed.tolist()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_PCT)

```

```{python}
class LogTransformerX(BaseEstimator, TransformerMixin):
  # add another additional parameter, just for fun, while we are at it
  def __init__(self, feature_name, additional_param = ""):
    print('\n>>>>>>>init() called.\n')
    self.feature_name = feature_name
    self.additional_param = additional_param

  def fit(self, X, y = None):
    print('\n>>>>>>>fit() called.\n')
    print(f'\nadditional param ~~~~~ {self.additional_param}\n')
    return self

  def transform(self, X, y = None):
    print('\n>>>>>>>transform() called.\n')
    X_ = X.copy() # creating a copy to avoid changes to original dataset
    X_[self.feature_name] = 2 * np.sqrt(X_[self.feature_name])
    return X_

```

```{python}
class LogTransformerY(BaseEstimator, TransformerMixin):
    # no need to implement __init__ in this particular case

    def fit(self, target):
        return self

    def transform(self, target):
        print('\n%%%%%%%%%%%%%%%custom_target_transform() called.\n')
        target_ = target.copy()
        target_ = np.log(target_)
        return target_

    # need to implement this too
    def inverse_transform(self, target):
        print('\n%%%%%%%%%%%%%%%custom_inverse_target_transform() called.\n')
        target_ = target.copy()
        target_ = np.exp(target)
        return target_

```


```{python}

## Create de model
print("create pipeline 3.1")
# no change in input pipeline
pipe = Pipeline(steps=[
                       ('experimental_trans', LogTransformerX('skill')),
                       ('linear_model', LinearRegression())
])

# create a TargetTransformer
# By default, the provided functions are checked at each fit to be the inverse of each other. However, it is
# possible to bypass this checking by setting check_inverse to False.
model = TransformedTargetRegressor(regressor=pipe,
                                   transformer=LogTransformerY(),
                                   check_inverse=False) # avoid repeated calls

## Train the model

print("fit pipeline 3.1 [fit Model]")
model.fit(X_train.iloc[1:6,], y_train[1:6])
print("predict via pipeline 3.1 [Model]")
preds3_1 = model.predict(X_test)
print(f"\n{preds3_1}")  # should be [196. 289.]
print(f"RMSE: {np.sqrt(mean_squared_error(y_test, preds3_1))}\n")

```



[link](https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156)