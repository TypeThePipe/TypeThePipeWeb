---
title: "10 consejos para triunfar en tu próximo Datathon"
author: Carlos Vecina Tebar
date: "2020-02-24"
slug: "10-consejos-datathon"
translationKey: "10-advices-datathon"
output:
  blogdown::html_page:
    highlight: tango
categories:
- Post
- Datathon
tags: []
subtitle: ""
summary:  "¿Quieres conseguir tus objetivos?"
authors: [carlos-vecina]
featured: false
draft: false
---



<p>¿Pensando en inscribirte en un Datathon o competición de datos? ¡En este post os traemos 10 consejos sobre los puntos clave para conseguir grandes resultados!</p>
<p><br></p>
<p><strong>1. Establece tu objetivo y revisa los recursos(habilidades, tiempo, acceso a máquinas…) con los que cuentas.</strong></p>
<p>Comenzamos por un punto esencial. Dependiendo de tu perfil y de la competición, deberás plantearte a priori qué pretendes conseguir participando en el reto. Puede ser aprender y mejorar en un determinado campo o tecnología, conseguir el premio, quedar entre los 3 primeros para incluirlo en tu CV o simplemente por diversión. Cualquiera que sea está bien.</p>
<p>Lo que recomendamos es evaluarlo de manera sincera, ya que será bastante el tiempo invertido y tener tu objetivo presente te ayudará en los momentos de menor motivación.</p>
<p><br></p>
<p><strong>2. Elección del tema/industria/CdUso.</strong></p>
<p>Ligado con esta última idea, dado que vamos a dedicar esfuerzos en este proyecto, ¿cómo no elegir un tema, campo o caso de uso que nos motive? Afortunadamente, desde muchas organizaciones y plataformas se están lanzando diferentes e interesantes competiciones. Kaggle es uno de lso máximos exponentes de estas plataformas, pero también existen otras, las cuales presentamos <a href="../../vizs-and-tips/plataformas-donde-participar-competiciones-de-datos">aquí</a>.</p>
<p><br></p>
<p><strong>3. Construye bien tu equipo. Usa herramientas para compartir codigo/archivos.</strong></p>
<p>Dependiendo de los dos puntos anteriores, especialmente del primero, según tu objetivo deberás elegir a tu equipo de manera consecuente. Este es un tema que no se suele omentar, pero consideramos importante prestarle la debida atención.</p>
<p>Elige un compañero o amigo con el que te lleves realmente bien y os motiveis mutuamente si tu objetivo es aprender sobre un tema o tecnología nueva. Prioriza a alguien que comparta tus intereses en el caso que desees dedicarle tiempo a profundizar y masterizar un tema, tecnología o algoritmo muy concreto.</p>
<p>Si el proyecto lo requiere, y pretendes optar al premio o a posiciones altas, te recomendamos elegir un compañero que complemente tus habilidades. En el caso de que no se requiera multidisciplinariedad, opta por aquellos que tenga un nivel similar al tuyo. Si es posible, ligeramente superior.</p>
<p>De esta forma lograrás minimizar tiranteces y conflictos de objetivos, maximizando el retorno del tiempo invertido.</p>
<p><br></p>
<p><strong>4. Investigación previa y profunda sobre el caso en concreto.</strong></p>
<p>Una vez formado el equipo, os recomendamos comenzar a investigar el negocio o el contexto en la que se enmarca vuestro proyecto. Esto permitirá plantear mejor el trabajo, extraer un valor muy superior a los datos y os evitará iteraciones en el proceso diseñar-implementar-evaluar al partir de premisas más claras, dejando al lado una mala interpretación de conceptos básicos, lo cual puede ser letal.</p>
<p>Un ejemplo. Si la competición trata sobre predecir el número de visitas o el número de contrataciones de determinados productos en un comercio online, en base a su navegación recogida por Google Analytics, debemos controlar el comportamiento de esta fuente de datos. Conocer el significado de tasa de rebote, las mecánicas desde que un usuario se conecta y se le asigna una cookie hasta que convierte, diferentes casuísticas de registros nulos, bots, que la <em>source</em>(para conocer la fuente de donde viene el visitante) en caso de dudas se asigna como <em>direct</em>…</p>
<p>Sin esta serie de conocimientos sería dificil <em>craftear</em> variables para conseguir un buen <em>performance</em> de los modelos, pero más importate, cualquier resultado que obtengas será malinterpretado. Por lo tanto, todo este <em>background</em> no es imprescindible para llegar a algún resultado, pero sí lo será para llegar a resultados potentes y realizar una participación de la que acabes orgulloso.</p>
<p><br></p>
<p><strong>5. Análisis exploratorio de los datos. Recuerda que (usualmente) no son los únicos que puedes usar.</strong></p>
<p>Como todo proyecto de datos, consta de una serie de etapas iterativas. Después de investigar sobre el contexto, echarás un primer vistazo a los datos. Si surgen dudas, de nuevo habrá que investigar para resolverlas.</p>
<p>Al margen de este recordatorio, la fase exploratoria se centra en conocer cada una de las variables. Como consejo personal, entre otras cosas, nosotros comenzamos midiendo el porcentaje de NAs y la varianza de las variables. Aquellas que tengan un elevado porcentaje de NAs o una varianza muy pequeña, o bien las apartamos (podría replantearse su entrada en siguientes iteraciones) o bien las <em>encodeamos</em> de manera dicotómica Si_NA/No_NA o Mayoritaria/No_mayoritaria. Para otro tipo de encodings <a href="https://www.kaggle.com/waydeherman/tutorial-categorical-encoding">ver</a>.</p>
<p>Esta etapa exploratoria varía bastante dependiendo del número de variables que contenga tu dataset. En <em>datasets</em> con 75, 100 o más variables, resultará más complicado hacerse una idea general de las características de cada una de ellas. Enfrentarnos a este tipo de <em>datasets</em> puede resultar ciertamente abrumador, sin embargo tras una buen estudio, eleccion y transformación puede ser que acabes dando las gracias de no tener sólo 5 o 10 variables(caso en el que se suele llegar a un <em>plateau</em> de desempeño de los modelos más rápido y mayor homogeneidad en los resultados expuestos por los diferentes equipos).</p>
<p>Por último, recordar que normalmente no hay problema con utilizar datos complementarios a los propios de la competición. En algunos casos como Kaggle, lo que se establece es la obligación de comentar y hacer público el uso de estos datos durante la competición.</p>
<p>Datos demográficos que ayuden a poner en contexto las variables geográficas como código postal o provincia, aportar explicabilidad a <em>spikes</em> o eventos pasados… son sólo algunos de los ejemplos de los datos que se pueden incorporar al <em>dataset</em> original del reto, obviamente teniendo en cuenta cuales de estos datos vamos a tener y cuales no a la hora de predecir.</p>
<p><br></p>
<p><strong>6. Establecer la estructura del código.</strong></p>
<p>A continuación os mostramos la estructura que suelen tener nuestros proyectos. Llevamos a cabo una validación cruzada manual con el objetivo de ganar flexibilidad a la hora de usar modelos de diferente naturaleza y poder compararlos y combinarlos. Cierto es que soluciones paquetizadas como scikit-learn o H2O pueden hacer este trabajo en el caso de que el tiempo disponible y características de la competición indiquen su uso.</p>
<p>Carga de entorno (paquetes y funciones)
Diferentes craft de variables
Seperación en dataset y datasetOOSample
Separar el dataset en <em>folds</em>
Por cada fold:
Entrenar con el resto
Predecir en el fold
Evaluación
Predicción OOSample
Evaluación
Predicción del conjunto de test a enviar.</p>
<p><br></p>
<p><strong>7. Lanzar los primeros modelos.</strong></p>
<p>En primer lugar centrate en la familia de algoritmos que a priori mejor se adapten a tus datos, al objetivo a predecir, incluso a la métrica de error por la que se te va a medir. Es importante sacar los primeros resultados, a ser posible dentro de una estructura similar a la propuesta anteriormente. Las primeras métricas de error te ayudaran en muchos aspectos. Por un lado te pueden dar pistas de que <em>bugs</em> en el código(metricas de error irrealistas). También te servirá de base la cual ir mejorando, y como estamos seguros de que lo harás, esto será ademañs un <em>boost</em> de ánimo.</p>
<p>Como principales familias XXXXXX</p>
<p><br></p>
<p><strong>8. Validación cruzada, OOS y backtesting.</strong></p>
<p>Especial mención a las métricas de error. Una de las características a la que de manera personal más importancia le damos, se tratata de conocer los intervalos de error de nuestros modelos antes de enviarlos. Conocer las precisión de nuestro modelo bajo diferentes escenarios, partes del dataset e incluso datos sintéticos nos hace sentir un especial orgullo. Quizá sea simplemente un objetivo que nos marcamos(tal y como comentamos en el punto 1), pero el hecho de tener la certeza de cuando bajaos la métrica de error no se debe a algo espúreo, o lo peor de todo a un <em>bug</em>, nos permite desarrollar con tranquilidad. Además en el caso de existir un ranking público, controlar tu métrica de evaluación te permite saber con mayor certeza en que percentil te encuentras.</p>
<p>Estas competiciones suelen ir ligadas a una métrica de error por la cual se evalua a cada participante. Será fundamental introducirla en nuestra evaluación de modelos, pero no debe de ser la única. Tanto a la hora de fijar una función objetivo como a la hora de evaluar los modelos, debemos tener en cuenta métricas de error complementarias que nos ayuden a interpretar el desempeño de los modelos. Tener en cuenta el error mediano o el MAPE, cuando la métrica con la que nos evaluarán será el error medio, nos puede ayudar a detectar elegir entre modelos que difieren en sólo un x% en esta métrica pero no en otras, en un determinado conjunto de datos.</p>
<p><br></p>
<p><strong>9. Interpretación y evaluación de resultados desde el punto de vista práctico y/o negocio.</strong></p>
<p>En el caso de que se trate de un Datathon organizado por alguna empresa de tu zona, seguramente los mejores proyectos serán llamados a un evento final de presentación de los trabajos. En otros, te pedirán una memoria presentando los resultados. En el caso de Kaggle, no suelen hacerlo.</p>
<p>Por lo tanto, si la competición a la que te presentas requiere de este tipo de resultado, será importante tenerlo presente no sólo al final, sino durante todo el proceso. Una vez que hemos re-optimizado los hiperparámetros con lo última librería bayesiana, que hemos <em>stackeado</em> nuestros mejores modelos, quizá sea hora de trabajar en la interpretabilidad de los resultados, incorporación de nuevos datos, en definitiva, conclusiones que sean valiosas a la hora de poner en marcha el modelo y que no quede en una simple matriz de pesos.</p>
<p>En la última competición a la que asistimos donde se nos pedía esta presentación final a los tres mejores proyectos, e incluso aunque no se hubiese pedido, optamos por adentrarnos en el modelado de las imagenes mediante <em>transfer learning</em>, cosa que no se nos pedía. Una vez que modelamos la información estructurada y llevamos a cabo ciertas iteraciones sobre estos datos, pensamos que sería más enriquecedor tanto para nosotros como para las personas que proponían el concurso, la investigación sobre la extracción de información de las imagenes (información que en el caso de uso que nos ocupaba, a priori, debería tener un impacto claro sobre la variable a predecir).</p>
<p><br></p>
<p><strong>10. (Personal) Escribir una memoria con puntos fuertes y puntos a mejorar detectados, que te sirvan de partida en el próximo reto.</strong></p>
<p>Una vez finalizado el proyecto, un práctica que nos ha enriquecido y ha supuesto un antes y un después ha sido escribir algún tipo de memoria o documento, reflexionando sobre la reciente participación. Analizando los puntos fuertes, lo que debimos mejorar, tanto a nivel técnico como a nivel de equipo y por qué no a nivel emocional y de actutid. A ser posible nada más entregar y antes de saber el resultado. Sería genial si al tiempo de conocer el mismo se añadiera algún punto o reflexión más.</p>
<p>Todas estas anotaciones nos ayudan cada vez que nos enfrentamos a un proyecto a encararlo más preparados y no depender del ‘instinto’ ni de lo que la memoria selectiva nos quiera recordar en momentos puntuales.</p>
<p>Una mala predisposición personal, una mala elección de equipo, no estudiar suficientemente y con cariño los valores extremos, no preparar la presentación con tiempo, correr los modelos 30 minutos antes de que acabe el plazo de entrega… son situaciones que nos han pasado a muchos y no ocurre absolutamente nada por reflexionar sore ellas y dejarlo por escrito. Lo fundamental es, dentro de lo posible, ¡que no se repitan en la próxima competición! :)</p>
<style>
body {
text-align: justify}
p {
  word-spacing: 3px;
}
</style>
<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script>
<script type="text/javascript">window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us4.list-manage.com","uuid":"91551f7ed29389a0de4f47665","lid":"d95c503a48","uniqueMethods":true}) })</script>
